% L2 Online Segmentation Visualization code

<<global_opts_l2, echo=TRUE, cache=FALSE>>=
library(knitr)
library(here)

knitr::opts_chunk$set(
  echo = FALSE
)
here::here()
set_parent(here('Asberry_Dissertation/Dissertation.Rnw'))
@


<<gen_l2_lib, echo = FALSE>>=
# Load Libraries
library(tidyverse)
library(ggplot2)
library(cowplot)
library(effsize)
library(xtable)

# Source Scripts containing functions
source('../../Scripts_Dissertation/diss_dataviz_script.R')
source('../../Scripts_Dissertation/analysis_functions.R')
@

<<l2_participants, echo = FALSE>>=
# Read in data file
my_l2_data <- 
  read_csv('analyze_data/output/55_online_learners_segmentation.csv')

# Read in raw file of all segmentation data
my_online_l2_raw_data <- 
  read_csv('analyze_data/output/online_L2_raw_data.csv') %>% 
  subset(., partNum %in% my_l2_data$partNum)

# Delete practice trial rows
online_l2_exper_trials <- drop_na(my_online_l2_raw_data, 
                                  any_of("corrAns"))
# Critical trials 
my_online_l2_critical_data <- 
  read_csv('analyze_data/output/online_L2_critical_data.csv') %>% 
  subset(., partNum %in% my_l2_data$partNum)

my_online_l2_critical_correct <- my_online_l2_critical_data %>% 
  subset(., segResp == 'b')

my_online_l2_under_200 <- my_online_l2_critical_correct %>% 
  subset(., segRespRTmsec > 200)

my_online_l2_over_1500 <- my_online_l2_under_200 %>% 
  subset(., segRespRTmsec < 1500)
@

<<l2_data, echo = FALSE>>=
# Transform data in long form with 1 row per participant per condition
# List columns to group by
online_l2_grouping <- c("partNum", 
                        "group", 
                        "word_status", 
                        "word_initial_syl", 
                        "target_syl_structure", 
                        "matching")

# Aggregaates and transforms data into long form
# Adds columns for median of RT in msec and log
online_learners <- trans_long(my_l2_data, online_l2_grouping)  

# Get summary stats for reporting 
# Columns that I want summary stats for
online_l2_stat_col <- c("segRespRTmsec",
                        "log_RT")

# Stats I want to run
online_l2_summary_stats <- quote(list(Median = median,
                            Mean = mean, 
                            Min = min, 
                            Max = max, 
                            SD = sd))

# Grouping by group and condition
online_l2_cond_grp <- c("group",
              "target_syl_structure",
              "word_initial_syl",
              "matching", 
              "word_status")

# grouped by participant and condition
online_l2_ind_sum <- my_stats(my_l2_data, 
              grp_col = online_l2_grouping, 
              sum_col = online_l2_stat_col,
              stats = online_l2_summary_stats)

# grouped by group and condition
online_l2_grp_sum <- my_stats(my_l2_data, 
              grp_col = online_l2_cond_grp, 
              sum_col = online_l2_stat_col,
              stats = online_l2_summary_stats) %>% 
  mutate(index = paste("English",
                       target_syl_structure,
                       word_initial_syl,
                       word_status, sep = "-")) %>%
  mutate_at(vars(ends_with("_Mean")), 
              list(~ round(., 2))) %>% 
  mutate_at(vars(ends_with("_SD")), 
              list(~ round(., 2))) %>% 
  mutate_at(vars(ends_with("_Median")), 
              list(~ round(., 2))) %>%
  mutate_at(vars(ends_with("_Min")), 
              list(~ round(., 2))) %>% 
  mutate_at(vars(ends_with("_Max")), 
              list(~ round(., 2))) %>% 
  column_to_rownames(., var = "index")

# Get some average RTs
online_l2_grp_sum %>% 
  select(., c(word_status, segRespRTmsec_Mean)) %>% 
  View()

online_l2_wd_av <- online_l2_grp_sum %>% 
  subset(., word_status == "word") %>% 
  select(., c(word_status, segRespRTmsec_Mean))

online_l2_nonwd_av <- online_l2_grp_sum %>% 
  subset(., word_status != "word") %>% 
  select(., c(word_status, segRespRTmsec_Mean))

# Summary statistics for reaction time
# Group data by target syllable structure, matching condition, and word status, 
online_l2_grouping_stats <- c("target_syl_structure", 
                              "matching", 
                              "word_status")

# Online learners
bxp_online_learners <- online_learners %>% 
  mutate(wd_new = factor(word_status, 
                         levels = c("word", "nonword"),
                         labels = c("Word", "Nonword")),
         mat_new = factor(matching, 
                          levels = c("match", "mismatch"),
                          labels = c("Matching", "Mismatching"))) %>% 
  ggplot(aes(x = target_syl_structure,
             y = median_RTmsec,
             color = mat_new)) +
  geom_boxplot(fill = NA, position = position_dodge(1)) +
  geom_violin(fill = NA, position = position_dodge(1)) +
  facet_grid(. ~ wd_new) +
  labs(title = "L2 Spanish by Target Syllable",
       x = "Target Syllable Structure",
       y = "Reaction Time (msec)") +
  scale_color_manual(name = "Condition", values = plt_color_2)
bxp_online_learners 


# Check for outliers
online_outlier_learner <- online_learners %>% 
  outlier_chk(., online_l2_grouping_stats, "median_RTmsec")

# Check for normality
online_normality_learner <- online_learners %>% 
  normality_chk(., online_l2_grouping_stats, "median_RTmsec")


# Create QQ plots
# learners by milliseconds
ggqqplot(
  online_learners, 
  "median_RTmsec", 
  ggtheme = theme_bw(), 
  title = "QQ Plot by Target Syllable in Milliseconds by L2 Spanish Speakers") +
  facet_grid(target_syl_structure + matching ~ word_status, 
             labeller = "label_both") 

# learners by log values
ggqqplot(
  online_learners, 
  "median_RTlog", 
  ggtheme = theme_bw(),
  title = "QQ Plot by Target Syllable in log by L2 Spanish Speakers") +
  facet_grid(target_syl_structure + matching ~ word_status, 
             labeller = "label_both")


# Run inferential statistics Native group
# Run 3 way repeated measures anova
aov_online_learners <- aov_ez("partNum", 
                       "median_RTlog", 
                       online_learners, 
                       within = c(online_l2_grouping_stats))
aov_online_learners
## no significant main effects, but matching is trending
## two way interaction between target syllable structure and matching condition
## two way interaction between target syllable structure and word status
## two way interaction trending between matching and word status

# Create Manuscript Version
online_grouping_pretty <- c("Target", "Matching", "Lexicality")
online_aov_learners_prt <- online_learners %>% 
  rename(., c(Target = target_syl_structure,
              Matching = matching,
              Lexicality = word_status)) %>% 
  aov_ez("partNum", 
         "median_RTlog", 
         ., 
         within = c(online_grouping_pretty))
online_aov_learners_prt

# Significant Main Effect Exploration
## none to explore (explore matching trend)
# Regroup to run paired t-test for matching/mismatching over all other conditions
online_l2_grouping_mat <- 
  online_l2_grouping[! online_l2_grouping %in% 
                       c("word_status", 
                         "word_initial_syl",
                         "target_syl_structure",
                         "group")]

# Aggregate data by matching condition
online_l2_mat_ag <- my_l2_data %>% 
  my_stats(., grp_col = online_l2_grouping_mat,
           sum_col = online_l2_stat_col,
           stats = online_l2_summary_stats)

# Significant Main Effect Exploration
# Learners t.test for matching condition
t_online_l2_mat_main <- t.test(
  online_l2_mat_ag$log_RT_Median ~ 
    online_l2_mat_ag$matching, 
  paired = TRUE,
  alternative = "less")
t_online_l2_mat_main
## is significant (difference in F and T statistics)

# Descriptives to check direction of effect
with(online_l2_mat_ag, 
     tapply(log_RT_Median, 
            matching, 
            FUN = mean))
## matching condition responded to faster than mismatching condition

# Create a table for referencing statistics with CIs
online_l2_mat_compare <- online_l2_mat_ag  %>% 
  group_by(matching) %>% 
  summarise(Mean = mean(log_RT_Median),
            SD = sd(log_RT_Median),
            N = n(),
            MOE_95 = qnorm(0.975)*SD/sqrt(N-1),
            LL = Mean - MOE_95,
            UL = Mean + MOE_95) %>% 
  column_to_rownames(., var = "matching")

# Calculate Cohen's D to estimate effect size
online_l2_mat_efsize <- 
  cohen.d(online_l2_mat_ag$log_RT_Median, 
          online_l2_mat_ag$matching, 
          na.rm = TRUE, 
          paired = TRUE)
online_l2_mat_efsize
## This will need a comment about the trend, but must be clear that it was not significant


# Online L2 Learner plots
# Main effect of matching condition
online_l2_mat_main <- 
  afex_plot(aov_online_learners, 
            x = "matching", 
            error = "within",
            factor_levels = list(
              matching = c(match = "Matching", 
                           mismatch = "Mismatching")),
            data_plot = FALSE,
            mapping = c("color", "shape")) +
  labs(title = "Estimated Marginal Means L2 Spanish",
       x = "Matching Condition",
       y = "Reaction Time (log)") +
  scale_color_manual(values = plt_color_2) +
  theme(legend.position = "none")
online_l2_mat_main


# Interaction breakdown
# Regroup for target syllable and matching 
online_tar_mat_learners <- my_l2_data %>% 
  my_stats(., grp_col = c("partNum", "target_syl_structure", "matching"), 
           sum_col = online_l2_stat_col,
           stats = online_l2_summary_stats)
online_tar_mat_learners

# Create a table for referencing statistics with CIs
online_tar_mat_compare <- online_tar_mat_learners %>% 
  group_by(target_syl_structure, matching) %>% 
  summarise(Mean = mean(log_RT_Median),
            SD = sd(log_RT_Median),
            N = n(),
            MOE_95 = qnorm(0.975)*SD/sqrt(N-1),
            LL = Mean - MOE_95,
            UL = Mean + MOE_95) %>%
  mutate(index = paste(target_syl_structure,matching,sep = '-')) %>% 
  column_to_rownames(., var = "index")

# Create CV subset
online_cv_learners <- my_l2_data %>% 
  subset(., target_syl_structure == "CV") %>% 
  my_stats(., grp_col = online_l2_grouping_mat, 
           sum_col = online_l2_stat_col,
           stats = online_l2_summary_stats)

# Create CVC subset
online_cvc_learners <- my_l2_data %>% 
  subset(., target_syl_structure == "CVC") %>% 
  my_stats(., grp_col = online_l2_grouping_mat, 
           sum_col = online_l2_stat_col,
           stats = online_l2_summary_stats)

# CV sylable t.test one-tailed
t_online_l2_cv_mat_int <-
  t.test(online_cv_learners$log_RT_Median ~ 
           online_cv_learners$matching,
         paired = TRUE,
         alternative = "less")
t_online_l2_cv_mat_int
##is significant t = -4.9582, df = 54, p-value = 3.716e-06

# Descriptives to check direction of effect
with(online_cv_learners,
     tapply(log_RT_Median,
            matching,
            FUN = mean))
## CV target syllables matching the word inital syllable are responded to faster than mismatching

# Get effect size
online_l2_cv_mat_efsize <-
  cohen.d(online_cv_learners$log_RT_Median,
          online_cv_learners$matching,
          na.rm = TRUE,
          paired = TRUE)
online_l2_cv_mat_efsize
## small effect size d = -0.3604633


# CVC sylable t.test one-tailed
t_online_l2_cvc_mat_int <-
  t.test(online_cvc_learners$log_RT_Median ~ 
           online_cvc_learners$matching,
         paired = TRUE,
         alternative = "less")
t_online_l2_cvc_mat_int
## not significant in hypothesized direction 
## t = 2.3086, df = 54, p-value = 0.9876

# Descriptives to check direction of effect
with(online_cvc_learners,
     tapply(log_RT_Median,
            matching,
            FUN = mean))
## CVC target syllables matching the word inital syllable are responded to slower than mismatching

# Get effect size
online_l2_cvc_mat_efsize <-
  cohen.d(online_cvc_learners$log_RT_Median,
          online_cvc_learners$matching,
          na.rm = TRUE,
          paired = TRUE)
online_l2_cvc_mat_efsize
## negligible effects size as well


# Create subsets to explore interaction between target syllable structure and word status
online_l2_grouping_tarsyl <- 
  online_l2_grouping[! online_l2_grouping %in% 
                       c("word_status", 
                         "word_initial_syl",
                         "matching", 
                         "group")]

# Regroup for target syllable and matching 
online_tar_lex_learners <- my_l2_data %>% 
  my_stats(., grp_col = c("partNum", 
                          "target_syl_structure", 
                          "word_status"), 
           sum_col = online_l2_stat_col,
           stats = online_l2_summary_stats)
online_tar_lex_learners

# Create a table for referencing statistics with CIs
online_tar_lex_compare <- online_tar_lex_learners %>% 
  group_by(target_syl_structure, word_status) %>% 
  summarise(Mean = mean(log_RT_Median),
            SD = sd(log_RT_Median),
            N = n(),
            MOE_95 = qnorm(0.975)*SD/sqrt(N-1),
            LL = Mean - MOE_95,
            UL = Mean + MOE_95) %>%
  mutate(index = paste(target_syl_structure,word_status,sep = '-')) %>% 
  column_to_rownames(., var = "index")

# Nonword subset
online_nonwords_learners <- my_l2_data %>% 
  subset(., word_status == "nonword") %>% 
  my_stats(., grp_col = online_l2_grouping_tarsyl, 
           sum_col = online_l2_stat_col,
           stats = online_l2_summary_stats)

# Create real word subset
online_words_learners <- my_l2_data %>% 
  subset(., word_status == "word") %>% 
  my_stats(., grp_col = online_l2_grouping_tarsyl, 
           sum_col = online_l2_stat_col,
           stats = online_l2_summary_stats)

# Nonwords t.test
t_online_l2_nonwd_tarsyl_int <-
  t.test(online_nonwords_learners$log_RT_Median ~
           online_nonwords_learners$target_syl_structure,
         paired = TRUE)
t_online_l2_nonwd_tarsyl_int
## not significant t = 0.44483, df = 54, p-value = 0.6582

# Descriptives to check direction of effect
with(online_nonwords_learners,
     tapply(log_RT_Median, 
            target_syl_structure,
            FUN = mean))
## CVC faster than CV target syllable for nonwords, but not signficantly so

# Get effect size
online_l2_nonwd_tarsyl_efsize <-
  cohen.d(online_nonwords_learners$log_RT_Median,
          online_nonwords_learners$target_syl_structure,
          na.rm = TRUE,
          paired = TRUE)
online_l2_nonwd_tarsyl_efsize

# Real words t.test
t_online_l2_wd_tarsyl_int <-
  t.test(online_words_learners$log_RT_Median ~
           online_words_learners$target_syl_structure,
         paired = TRUE)
t_online_l2_wd_tarsyl_int
## not significant t = -1.5419, df = 54, p-value = 0.1289

# Descriptives to check direction of effect
with(online_words_learners,
     tapply(log_RT_Median, 
            target_syl_structure,
            FUN = mean))
## CV faster than CVC target syllable for words, but not significantly so

# Get effect size
online_l2_wd_tarsyl_efsize <-
  cohen.d(online_words_learners$log_RT_Median,
          online_words_learners$target_syl_structure,
          na.rm = TRUE,
          paired = TRUE)
online_l2_wd_tarsyl_efsize

# Regroup to run paired t-test for word status over all other conditions 
online_l2_grouping_lex <- 
  online_l2_grouping[! online_l2_grouping %in% 
                       c("target_syl_structure", 
                         "word_initial_syl",
                         "matching", 
                         "group")]

# Create subsets to explore interaction between target syllable and word status
# Flipping variables to look at it from a different direction (Same as above interaction stats)
# CV subset
online_cv_learners_lex <- my_l2_data %>% 
  subset(., target_syl_structure == "CV") %>% 
  my_stats(., grp_col = online_l2_grouping_lex, 
           sum_col = online_l2_stat_col,
           stats = online_l2_summary_stats)

# CVC subset
online_cvc_learners_lex <- my_l2_data %>% 
  subset(., target_syl_structure == "CVC") %>% 
  my_stats(., grp_col = online_l2_grouping_lex, 
           sum_col = online_l2_stat_col,
           stats = online_l2_summary_stats)

# CV syllable t.test
t_online_l2_cv_lex_int <-
  t.test(online_cv_learners_lex$log_RT_Median ~
           online_cv_learners_lex$word_status,
         paired = TRUE)
t_online_l2_cv_lex_int
## not significant

# Descriptives to check direction of effect
with(online_cv_learners_lex,
     tapply(log_RT_Median,
            word_status,
            FUN = mean))
## CV target syllables are responded to faster for words than nonwords, but not significantly so

# Get effect size
online_l2_cv_lex_efsize <-
  cohen.d(online_cv_learners_lex$log_RT_Median,
          online_cv_learners_lex$word_status,
          na.rm = TRUE,
          paired = TRUE)
online_l2_cv_lex_efsize
## negligible


# CVC sylable t.test
t_online_l2_cvc_lex_int <-
  t.test(online_cvc_learners_lex$log_RT_Median ~
           online_cvc_learners_lex$word_status,
         paired = TRUE)
t_online_l2_cvc_lex_int
## not significant t = -0.6827, df = 54, p-value = 0.4977

# Descriptives to check direction of effect
with(online_cvc_learners_lex,
     tapply(log_RT_Median,
            word_status,
            FUN = mean))
## CVC target syllables are responded to faster for nonwords than words, but not significantly so

# Get effect size
online_l2_cvc_lex_efsize <-
  cohen.d(online_cvc_learners_lex$log_RT_Median,
          online_cvc_learners_lex$word_status,
          na.rm = TRUE,
          paired = TRUE)
online_l2_cvc_lex_efsize
## negligible


# Create subsets to explore interaction between matching and word status (trending)
online_mat_lex_learners <- my_l2_data %>% 
  my_stats(., grp_col = c("partNum", "word_status", "matching"), 
           sum_col = online_l2_stat_col,
           stats = online_l2_summary_stats)
online_mat_lex_learners

# Create a table for referencing statistics with CIs
online_mat_lex_compare <- online_mat_lex_learners %>% 
  group_by(word_status, matching) %>% 
  summarise(Mean = mean(log_RT_Median),
            SD = sd(log_RT_Median),
            N = n(),
            MOE_95 = qnorm(0.975)*SD/sqrt(N-1),
            LL = Mean - MOE_95,
            UL = Mean + MOE_95) %>%
  mutate(index = paste(word_status,matching,sep = '-')) %>% 
  column_to_rownames(., var = "index")

# Nonword subset
online_nonwd_learners_mat <- my_l2_data %>% 
  subset(., word_status == "nonword") %>% 
  my_stats(., grp_col = online_l2_grouping_mat, 
           sum_col = online_l2_stat_col,
           stats = online_l2_summary_stats)

# Create real word subset
online_wd_learners_mat <- my_l2_data %>% 
  subset(., word_status == "word") %>% 
  my_stats(., grp_col = online_l2_grouping_mat, 
           sum_col = online_l2_stat_col,
           stats = online_l2_summary_stats)

# Nonwords t.test one-tailed for matching
t_online_l2_nonwd_mat_int <-
  t.test(online_nonwd_learners_mat$log_RT_Median ~
           online_nonwd_learners_mat$matching,
         paired = TRUE,
         alternative = "less")
t_online_l2_nonwd_mat_int
## is significant (difference between F and t statistics)

# Descriptives to check direction of effect
with(online_nonwd_learners_mat,
     tapply(log_RT_Median,
            matching,
            FUN = mean))
## nonwords in matching condition are responded to faster than mismatching condition

# Get effect size
online_l2_nonwd_mat_efsize <-
  cohen.d(online_nonwd_learners_mat$log_RT_Median,
          online_nonwd_learners_mat$matching,
          na.rm = TRUE,
          paired = TRUE)
online_l2_nonwd_mat_efsize
## negligible effect size


# Real words t.test ont-tailed for matching
t_online_l2_wd_mat_int <-
  t.test(online_wd_learners_mat$log_RT_Median ~
           online_wd_learners_mat$matching,
         paired = TRUE,
         alternative = "less")
t_online_l2_wd_mat_int
## not significant

# Descriptives to check direction of effect
with(online_wd_learners_mat,
     tapply(log_RT_Median,
            matching,
            FUN = mean))
## Words in the matching condition repsonded to faster than nonmatching, but not significantly so

# Get effect size
online_l2_wd_mat_efsize <-
  cohen.d(online_wd_learners_mat$log_RT_Median,
          online_wd_learners_mat$matching,
          na.rm = TRUE,
          paired = TRUE)
online_l2_wd_mat_efsize

# Learner plots 
# Interaction between matching condition and target syllable with matching condition on x-axis
online_l2_tarsyl_mat_int <- afex_plot(
  aov_online_learners, 
  x = "matching", 
  trace = "target_syl_structure",
  error = "within",
  mapping = c("shape", "color", "linetype"),
  factor_levels = list(
    matching = c("Matching", "Mismatching")),
  legend_title = "Target Syllable",
  data_plot = FALSE) +
  labs(title = "Estimated Marginal Means L2 Spanish",
       x = "Matching Condition",
       y = "Reaction Time (log)") +
  scale_color_manual(values = plt_color_2)
online_l2_tarsyl_mat_int

# Interaction between matching condition and target syllable with target syllable conditions on x-axis
online_l2_mat_tarsyl_int <- afex_plot(
  aov_online_learners, 
  x = "target_syl_structure", 
  trace = "matching",
  error = "within",
  mapping = c("shape", "color", "linetype"),
  factor_levels = list(
    matching = c("Matching", "Mismatching")),
  legend_title = "Condition",
  data_plot = FALSE) +
  labs(title = "Estimated Marginal Means L2 Spanish",
       x = "Target Syllable",
       y = "Reaction Time (log)") +
  scale_color_manual(values = plt_color_2)
online_l2_mat_tarsyl_int

# Plot side by side to determine which one is easier to understand data
plot_grid(online_l2_tarsyl_mat_int, online_l2_mat_tarsyl_int)


# Interaction between target syllable and lexicality with target syllable on x-axis
online_l2_tarsyl_lex_int <- afex_plot(
  aov_online_learners, 
  x = "target_syl_structure", 
  trace = "word_status",
  error = "within",
  mapping = c("shape", "color", "linetype"),
  factor_levels = list(
    word_status = c(word = "Word", nonword = "Noword")),
  legend_title = "Lexicality",
  data_plot = FALSE) +
  labs(title = "Estimated Marginal Means L2 Spanish",
       x = "Target Syllable",
       y = "Reaction Time (log)") +
  scale_color_manual(values = plt_color_2)
online_l2_tarsyl_lex_int

# Interaction between target syllable and lexicality with lexicality conditions on x-axis
online_l2_lex_tarsyl_int <- afex_plot(
  aov_online_learners, 
  x = "word_status", 
  trace = "target_syl_structure",
  error = "within",
  mapping = c("shape", "color", "linetype"),
  factor_levels = list(
    word_status = c(word = "Word", nonword = "Noword")),
  legend_title = "Target Syllable",
  data_plot = FALSE) +
  labs(title = "Estimated Marginal Means L2 Spanish",
       x = "Lexicality",
       y = "Reaction Time (log)") +
  scale_color_manual(values = plt_color_2)
online_l2_lex_tarsyl_int

# Plot side by side to determine which one is easier to understand data
plot_grid(online_l2_tarsyl_lex_int, online_l2_lex_tarsyl_int)

# Interaction between matching condition and lexicality with matching condition on x-axis
online_l2_mat_lex_int <- afex_plot(
  aov_online_learners, 
  x = "matching", 
  trace = "word_status",
  error = "within",
  mapping = c("shape", "color", "linetype"),
  factor_levels = list(
    word_status = c(word = "Word", nonword = "Noword"),
    matching = c("Matching", "Mismatching")),
  legend_title = "Lexicality",
  data_plot = FALSE) +
  labs(title = "Estimated Marginal Means L2 Spanish",
       x = "Matching Condition",
       y = "Reaction Time (log)") +
  scale_color_manual(values = plt_color_2)
online_l2_mat_lex_int

# Interaction between matching condition and lexicality with lexicality conditions on x-axis
online_l2_lex_mat_int <- afex_plot(
  aov_online_learners, 
  x = "word_status", 
  trace = "matching",
  error = "within",
  mapping = c("shape", "color", "linetype"),
  factor_levels = list(
    word_status = c(word = "Word", nonword = "Noword"),
    matching = c("Matching", "Mismatching")),
  legend_title = "Condition",
  data_plot = FALSE) +
  labs(title = "Estimated Marginal Means L2 Spanish",
       x = "Lexicality",
       y = "Reaction Time (log)") +
  scale_color_manual(values = plt_color_2)
online_l2_lex_mat_int

# Plot side by side to determine which one is easier to understand data
plot_grid(online_l2_mat_lex_int, online_l2_lex_mat_int)


# Remove temporary data variables in environment
# Remove dataframes following analysis
rm(online_cv_learners_lex, 
   online_cvc_learners_lex)

# Remove checks and unused plots
rm(online_normality_learner, 
   online_outlier_learner)

# Run stats per previous study analysis
# Interaction breakdown Words and Nonwords
historic_grouping_pretty <- c("Target", "Carrier", "Lexicality")
historic_aov_learners_prt <- online_learners %>% 
  rename(., c(Target = target_syl_structure,
              Carrier = word_initial_syl,
              Lexicality = word_status)) %>% 
  aov_ez("partNum", 
         "median_RTlog", 
         ., 
         within = c(historic_grouping_pretty))
historic_aov_learners_prt

# plot words and nonwords interaction
# comment panel arg for combined plot
# uncomment panel arg for separate Word/Nonword panels 
historic_l2_tar_car_int <- afex_plot(
  historic_aov_learners_prt, 
  x = "Target", 
  trace = "Carrier",
  panel = "Lexicality",
  error = "within",
  mapping = c("shape", "color", "linetype"),
  factor_levels = list(
    Lexicality = c(word = "Word", nonword = "Noword"),
    Carrier = c("CV", "CVC")),
  legend_title = "Carrier Syllable Structure",
  data_plot = FALSE) +
  labs(title = "Estimated Marginal Means L2 Spanish",
       x = "Target Syllable Structure",
       y = "Reaction Time (log)") +
  scale_color_manual(values = plt_color_2)
historic_l2_tar_car_int

# Interaction breakdown Words only
online_learners_wd <- online_learners %>% 
  subset(., word_status == "word")
historic_grouping_pretty_wd <- c("Target", "Carrier")
historic_aov_natives_prt_wd <- online_learners_wd %>% 
  rename(., c(Target = target_syl_structure,
              Carrier = word_initial_syl)) %>% 
  aov_ez("partNum", 
         "median_RTlog", 
         ., 
         within = c(historic_grouping_pretty_wd))
historic_aov_natives_prt_wd

# plot the word data interaction
historic_l2_tar_car_int_wd <- afex_plot(
  historic_aov_natives_prt_wd, 
  x = "Target", 
  trace = "Carrier",
  error = "within",
  mapping = c("shape", "color", "linetype"),
  factor_levels = list(
    Carrier = c("CV", "CVC")),
  legend_title = "Carrier Syllable Structure",
  data_plot = FALSE) +
  labs(title = "Estimated Marginal Means L2 Spanish",
       x = "Target Syllable Structure",
       y = "Reaction Time (log)") +
  scale_color_manual(values = plt_color_2)
historic_l2_tar_car_int_wd


# Save tabled data
# https://tex.stackexchange.com/questions/481802/reporting-r-results-in-latex

# Save all analyses
#out_dir = 'analyze_data/output/figures/by_target/'

# Save plots
#ggsave('learners_descriptive_data.png', bxp_learners, 'png', out_dir)
#ggsave('learners_mat_tarsyl_int.png', l2_mat_tarsyl_int, 'png', out_dir)
#ggsave('learners_tarsyl_lex_int.png', l2_tarsyl_lex_int, 'png', out_dir)
@