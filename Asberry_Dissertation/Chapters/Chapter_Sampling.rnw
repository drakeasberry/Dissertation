% Sampling and Methods Chapter with LaTeX code only

%----------------------------------------------------------------------------------------
<<global_opts_sampling, echo=FALSE, cache=FALSE, include=FALSE>>=
library(knitr)
library(here)

knitr::opts_chunk$set(
  echo = FALSE
)
here::here()
set_parent(here('Asberry_Dissertation/Dissertation.Rnw'))
@
%----------------------------------------------------------------------------------------

\chapter{Sampling Methods and Population} % Main chapter title
\label{ch-sampling} % for referencing this chapter elsewhere, use \ref{sampling}
In order to better understand the role of the Spanish syllable in segmenting words of Spanish, two distinct groups of speakers were recruited for this dissertation. When the project was originally designed, the hope was to move past the traditional approach of comparing second language learners against monolingual speakers of the target language. Instead, the original intent was to compare bilingual groups against one another where both bilingual populations only shared the same two languages---English and Spanish. The initial design of this project planned to recruit one control group and two separate target groups to investigate the research questions revolving around the processing of Spanish. The control group was to be native Spanish speakers who were adult learners of English. The first target group was to be native English speakers who were adult learners of Spanish while the second target group was to consist of people who had spoken both English and Spanish since early childhood. However, COVID-19 broke out during the data collection process for this study. This world-wide pandemic brought unforeseen restrictions to travel and the ability to bring people together in social spaces, which prevented further in-person data collection. 

This interruption caused by COVID-19 resulted in several intermediate processes of the project design to be reexamined. Firstly, the data that had been collected up to that point was analyzed. This revealed smaller than desired sample sizes with the early childhood English--Spanish bilingual speakers having too few analyze. The data for the remaining two groups were continued to analysis stage, but the outcomes related to the syllable and its affect on Spanish processing were null across the board. Therefore, the experimental design was reevaluated at the same time the transition from in-person to online data collection was being implemented. The original experimental design used a Latin-Square design, which pooled the results across all of the participants for the various experimental conditions needed to address the research questions and balance the design. However, previous literature was not clear as to whether or not a Latin-square design had been implemented. Therefore,it was decided against using a Latin-square design and submit all experimental conditions to each participant rather than balancing the design across participants during the online data collection phase. Lastly, the recruitment of online participants made participant screening a much more difficult task. This also made it hard to obtain the number of required participants needed for statistical power. As a result the early learners English--Spanish group was dropped from the project design entirely. This also resulted in the inclusion of monolingual Spanish speakers to represent the native Spanish speaker control group. This chapter serves to describe how these participants were recruited, the characteristics making these groups distinct from one another, inclusion criteria and study conditions for them during their participation---both online and in person.

\section{Recruitment}
\label{sec-recruit}
Participant recruitment took on two separate forms for the experiments included in this dissertation. Prior to the COVID-19 pandemic, recruitment of participants was targeted at those who could participate in person. For this phase of recruitment, traditional means of advertising such as email, flyers, word of mouth, etc. were used. Following the restrictions imposed by social distancing guidelines, the recruitment of online participants transitioned to online participant pools regulated by third party entities. These companies maintained participants pools and charged researchers a fee to access their databases in order to recruit participants with specific attributes that help to control or limit variables that could influence the outcomes of their research questions.

\subsection{In-person Experiments} 
\label{ssec-recruit-person}
In an effort to recruit participants for in-person data collection, flyers were distributed on the campuses of the University of Arizona in Tucson, Arizona and the University of Sonora in Hermosillo, Mexico. Emails were also sent to instructors of the Spanish and Portuguese department at the University of Arizona and the faculty of the University of Sonora to forward along to their students, friends and colleagues. All emails and flyers contained a brief description of the study, the type of participants that were needed and contact information for those who were interested in participating. The emails and flyers were written in the language of the country where recruitment was taking place. All participants in the native Spanish speaker control group were recruited in Hermosillo while the participants in the native English--L2 Spanish target group were recruited in Tucson. 

Previous studies that investigated speech processing used sample sizes between 20 and 42 participants. Prior to beginning data collection, a recruitment target of 40 participants for both the control and target groups was set. Setting the recruitment target at the higher end the previous research sample size range was done purposefully. This ensured that even if participants would have to be removed for some reason, a comparable sample size would remain for the analysis of the current study and that of previous literature. In the end, only \Sexpr{eligible_grp_desc["Spanish","n"]} native Spanish control participants and \Sexpr{eligible_grp_desc["English","n"]} native English L2 Spanish participants were recruited and able to complete the experiments in person before social distancing measures were put into place. 

\subsection{Online Experiments} 
\label{ssec-recruit-online}
Following the outbreak of COVID-19 and social distancing guideline, it was decided that the remainder of the recruitment and experiments would have to be done in online asynchronously. After redesigning the experiments to work through an online platform, traditional methods of recruitment such as email and word of mouth were used in an attempt to test the functionality and stability of the online experiment. After several weeks with very low response, it was decided that a new method of recruitment was required in order to obtain the data needed in a timely fashion. 

The recruitment for this dissertation turned to an online participant pool managed by Prolific \parencite{noauthor_2020-xx}. Prolific is a participant recruiting site based in the UK that maintains a pool of participants who would like to participate in research studies. Prolific charges the researcher a small fee and requires a fair monetary sum, set by the researcher, be give to research participants in exchange for their volunteer involvement in research. The company does not allow identifiable information to be collected on participants---names, emails, phone numbers, etc. This identifiable information collection is avoidable because every participant is assigned a unique ID string consisting of 24 random numbers and letters when they register for the site and become part of Prolific's participant pool. This ID is used for tracking completion and payment through Prolific. Researchers can also use this ID to ensure participants do not complete multiple submissions to any one experiment during data collection. It can also be used to prevent participants from completing a follow up experiment in the event their participation would not provide valid data or restrict participant access to only those who have previously participated, which is necessary for many longitudinal studies. Prolific requires that participants be screened according to any inclusion criteria before being asked to participate and is done through the filters provided by their site. As a result, the researcher simply sets up the filters that describe their groups of interest and Prolific advertises it to its registered applicant pool based on their self reported answers when they created their Prolific accounts. People who have answered questions that would eliminate their eligibility to certain group demographics or attributes are never presented the opportunity to complete the experiment. This allowed for a large sample of participants to be gathered in a short amount of time with minimal effort given to the screening process from the researcher.

Due to the fact that this second wave of recruitment occurred in response changing conditions related to COVID-19 and results from the first experiments produce unexpected results, a statistical power test run prior to beginning data collection using Jamovi---a program built on top of R \parencite{The_Jamovi_Project2020-lw,R_Core_Team2020-ib}. This decision was made to found the number of participants in a data driven decision rather than loosely following arbitrary numbers used in previous literature. The power analysis was run with the following parameters to determine needed sample size. The minimally interesting effect size was set to 0.5 or a medium effect size. The minimum desired power was set to 0.90 and $\alpha$ equal to 0.05. The results of the statistical power analysis revealed the necessity of 44 participants for both the target and control groups for a total of 88 needed participants. During the online data collection phase, the demographic information of submissions was reviewed periodically to ensure there were no discrepancies that would place a participant outside the intended group for which they were recruited. There were several participants who had discrepancies in fields such as known languages other than Spanish or English, which placed them outside our intended recruitment groups. The data of participants who did not fit the demographics of the recruitment groups were discarded and were replaced by other participants who did meet predefined requirements to ensure the minimum of 44 eligible participants would be available for statistical analysis. This check was repeated until the number of participants needed had been reached at which time the study on Prolific's site was closed.

\section{Participants}
\label{sec-participants}
This dissertation only utilized two groups of participants for its design and analysis. The control group always consisted of native Spanish speakers while the target groups was always made up of native English speakers. The control group participants were native Spanish speakers who were L2 learners of English (LE) and monolingual Spanish speakers (MS). The LE group data was collected in person while the MS group data was collected online in accordance with social distancing guidelines, but both groups represented the native Spanish speaker control. The target group participants consisted of native English speakers who were L2 learners of Spanish (LS). Recruitment and data collection for this group was also done in person and online at separate times due to social distancing. In all cases, participants were chosen based on their language backgrounds according to the results of a survey. Their language proficiency was also considered and was determined by a vocabulary size test. In addition to their language-based characteristics, some general criteria also applied to eligibility requirements. All participants had to be 18 years of age or older. No participant was specifically sought after or excluded from participating based on their assigned or self-identified gender. All other group inclusion criteria was layered over the general specifications and differed between target and control groups. These difference are detailed below.

\subsection{Native Spanish Speakers}
\label{ssec-group-ns}
As stated above, due to COVID-19 restriction that were put into place during the course of this dissertation project, two separate recruitment periods were required. The first group of native Spanish speakers were recruited for in-person experiments and occurred prior to the restrictions. These participants were recruited because they were L2 learners of English (LE) and represented L1-Spanish--L2-English bilingual group. These LE participants were all born and raised in Mexico where Spanish was the only language spoken in the home. They all reported learning English as a second language during their school age years in Mexico and no fluency in any language other than English and Spanish. At the time of recruitment, all participants still resided in Mexico and were enrolled at the University of Sonora in Hermosillo, Mexico. All participation in experimental tasks were completed in person on the University of Sonora campus library. No participants in the LE group were recruited through Prolific or took part in an online experiment.  

For the current project, \Sexpr{eligible_grp_desc["Spanish","n"]} participants meeting all inclusion criteria completed an experiment. The participants ages ranged from \Sexpr{eligible_grp_desc["Spanish","age_Min"]} to \Sexpr{eligible_grp_desc["Spanish","age_Max"]} years old with a mean age of \Sexpr{eligible_grp_desc["Spanish","age_Mean"]} years. The average age that participants reported for the beginning to study English was \Sexpr{eligible_grp_desc["Spanish","eng_acq_age_Mean"]}. The data collected from the LE participants was used to represent the control group for syllabic intuitions, Chapter \ref{ch-intuition}, and syllabic segmentation experiments completed in person, Chapter \ref{ch-seg-lab}.

\begin{table}
\caption{Attributes of recruited L2 English in-person participants.}
\label{tab-demo-lab-esp}
\centering
\begin{tabular}{c c c c}
\toprule
\multicolumn{3}{c}{Age} & English Acquisition Age\\
\cmidrule(lr){1-3}\cmidrule(lr){4-4}
Min & Max & Mean & Mean\\
\midrule
\Sexpr{eligible_grp_desc["Spanish","age_Min"]} 
& \Sexpr{eligible_grp_desc["Spanish","age_Max"]} 
& \Sexpr{eligible_grp_desc["Spanish","age_Mean"]} 
& \Sexpr{eligible_grp_desc["Spanish","eng_acq_age_Mean"]}\\
\bottomrule
\multicolumn{4}{l}{Total participants: n = \Sexpr{eligible_grp_desc["Spanish","n"]}}\\
\end{tabular}
\end{table}

The second recruitment period for native Spanish speakers began after the implementation of the social distancing guidelines. Given that this group of participants were being recruited for a second round of experimentation and following up on previous null findings, monolingual Spanish speaking participants were the targeted demographic. This decision was made because given previous studies on syllable monitoring the monolingual groups were more consistent in their findings whereas bilingual populations of the those language pairings did not always behave as their monolingual counterparts \parencite{Bradley1993-qq, Cutler1986-zl, Cutler1992-qq, Mehler1981-vi, Sebastian-Galles1992-xd}. Like these previous studies, it was decided that monolingual Spanish speakers should be recruited since monolingual serve as the baseline behavior because they are unaffected by any subsequent language learning experience. This also allowed us to ensure that experimental items were not the root cause of the null findings in earlier experiment. Lastly, only monolingual Spanish speakers from Mexico were recruited in order to minimize differences between control groups across this project's experiments. In short, all participants that were recruited reported being monolingual Spanish speakers who were born, raised and continued to reside in Mexico. They reported not having any fluency in any other language, including English, even though most school systems required the study of English in order to graduate. 

No MS group participants were recruited for in-person data collection. These participants were recruited to participate in the online experiments and were recruited through Prolific \parencite{noauthor_2020-xx}. Unlike participants who were recruited for in-person experiments, online recruitment procedures differed due to the recruitment site regulations. Prolific required all screening, filtering based on inclusion criteria, to be done prior to the participants being given the opportunity to complete a research study. Therefore, the responsibility fell to the researcher to correctly set up filters provided by Prolific so that the experiment was advertised to only participants meeting the inclusion criteria of the desired control group demographics. In order to filter the participants recruited for the online MS control group, the four Prolific filters utilized are listed below:

\begin{singlespacing}
\begin{enumerate}
\item Country of Birth: Mexico 
\item Current Country of Residence: Mexico
\item First Language: Spanish
\item Bilingual: Only Native Language
\end{enumerate}
\end{singlespacing}

In total, \Sexpr{eligible_grp_desc["Monolingual Spanish","n"]} participants that met all inclusion criteria completed an experiment for this dissertation. The participants' ages ranged from \Sexpr{eligible_grp_desc["Monolingual Spanish","age_Min"]} years old to \Sexpr{eligible_grp_desc["Monolingual Spanish","age_Max"]} years old with an average age of \Sexpr{eligible_grp_desc["Monolingual Spanish","age_Mean"]}. The data collected from MS control group was used in the analysis conducted for Chapter \ref{ch-seg-online}.

\begin{table}
\caption{Attributes of recruited monolingual Spanish online participants.}
\label{tab-demo-online-esp}
\centering
\begin{tabular}{c c c c}
\toprule
\multicolumn{3}{c}{Age} & English Acquisition Age\\
\cmidrule(lr){1-3}\cmidrule(lr){4-4}
Min & Max & Mean & Mean\\
\midrule
\Sexpr{eligible_grp_desc["Monolingual Spanish","age_Min"]} 
& \Sexpr{eligible_grp_desc["Monolingual Spanish","age_Max"]} 
& \Sexpr{eligible_grp_desc["Monolingual Spanish","age_Mean"]} 
& \emph{NA}\\
\bottomrule
\multicolumn{4}{l}{Total participants: n = \Sexpr{eligible_grp_desc["Monolingual Spanish","n"]}}\\
\end{tabular}
\end{table}

\subsection{Native English Speakers}
\label{ssec-group-ls}
Similar to the native Spanish speaker control groups, recruitment and data collection for the native English speaker target groups also had separate phases. The first group of participants consisted of native English speakers who, again, were recruited and participated in person before social distancing restrictions forced online methods to be used. For those that completed in-person experiments, they were all recruited from the University of Arizona campus in Tucson, Arizona. All participants were born and currently resided in the US. They were all raised as English monolinguals where only English was spoken in the household. They all reported learning Spanish during their school age years while attending school in the United States. In addition, the majority of participants were recruited from Spanish classes where students were currently enrolled in the fifth semester of study or beyond. However, flyers were also distributed around campus,which brought participants that were not currently registered in Spanish classes, but self-reported being able to speak Spanish at an equivalent level.

In total, \Sexpr{eligible_grp_desc["English","n"]} participants made up this in-person experiment subgroup. The participants' ages for those completing in-person experiments ranged from \Sexpr{eligible_grp_desc["English","age_Min"]} to \Sexpr{eligible_grp_desc["English","age_Max"]} with an average of \Sexpr{eligible_grp_desc["English","age_Mean"]} years of age. The average age that participants reported for the beginning to study Spanish was \Sexpr{eligible_grp_desc["English","span_acq_age_Mean"]}. The data collected from the first groups of LS participants was used to represent the target group for syllabic intuitions, Chapter \ref{ch-intuition}, and syllabic segmentation experiments completed in person, Chapter \ref{ch-seg-lab}.

\begin{table}
\caption{Attributes of recruited L2 Spanish in-person participants.}
\label{tab-demo-lab-eng}
\centering
\begin{tabular}{c c c c}
\toprule
\multicolumn{3}{c}{Age} & Spanish Acquisition Age\\
\cmidrule(lr){1-3}\cmidrule(lr){4-4}
Min & Max & Mean & Mean\\
\midrule
\Sexpr{eligible_grp_desc["English","age_Min"]} 
& \Sexpr{eligible_grp_desc["English","age_Max"]} 
& \Sexpr{eligible_grp_desc["English","age_Mean"]} 
& \Sexpr{eligible_grp_desc["English","span_acq_age_Mean"]}\\
\bottomrule
\multicolumn{4}{l}{Total participants: n = \Sexpr{eligible_grp_desc["English","n"]}}\\
\end{tabular}
\end{table}

The second subgroup of L2 Spanish learners, \Sexpr{eligible_grp_desc["L2 Learner","n"]} participants, were recruited through Prolific in the same manner as the MS control group had been. Similar to the LS subgroup that completed in-person experiments, these participants self-reported being able to speak Spanish and being raised as monolingual English speakers who were born and still resided in the US. These participants also reported not having fluency in any language other than Spanish and English. They differed in that they were recruited online and they were not current students at the University of Arizona. 

In order to utilize the pre-built filters within the Prolific site for recruitment, a more complex and less transparent filter structure was required. The \emph{Fluent Languages} filter deserves a slightly deeper explanation as to why it was not English and Spanish. Due to conflicts with the Prolific filters, specifying \emph{Fluent Languages} as Spanish and English produced unexpected results. Therefore, the experiment was incorrectly advertised to all participants who listed English or Spanish as a fluent language. This failed to exclude other languages such as Tagalog, French or Italian that participants may have listed. Using the \emph{Bilingual} and the \emph{Fluent Languages} filters together produced the most correct demographic pool of participants for the study. This was confirmed by the data files of demographic information provided by Prolific for participants who had completed the experiment. While this did not perfectly define the desired group demographics, it did greatly reduce the number of potential participants who did not meet the inclusion criteria. At the time of writing this dissertation, Prolific had added a warning to this filter, but the underlying issue had not been addressed. I would recommend that other researchers studying English bilinguals to use English as the \emph{First Language} filter and their other language of interest as the value for the \emph{Fluent Languages} where possible. Since English is a more widely taught around the world, researchers are likely to recruit more unusable data from participants until Prolific resolves the issue giving the capability to select specific language pairings using an AND rather than an OR operator. For this project, it was possible to cross check this information with the response given to the \emph{Bilingual} filter. For example, it was easy to identify people who reported fluency in Spanish and Italian with English as their native language and had also incorrectly reported knowing only one language in addition to their native language. This was a minor inconvenience, but allowed for their removal before analyses were run and resulted in paying for very few unusable data points. The Prolific filters used to recruit the LS group for online experiments included the following 6 filters listed below:

\begin{singlespacing}
\begin{enumerate}
\item Country of Birth: United States
\item Current Country of Residence: United States
\item First Language: English
\item Were you raised monolingual?: I was raised with my native language only
\item Bilingual: Native Language + one other language
\item Fluent Languages: Spanish
\end{enumerate}
\end{singlespacing}

The participant ages for those completing in-person experiments ranged from \Sexpr{eligible_grp_desc["L2 Learner","age_Min"]} to \Sexpr{eligible_grp_desc["L2 Learner","age_Max"]} years old with an average age of \Sexpr{eligible_grp_desc["L2 Learner","age_Mean"]} years. The average age that participants reported for the beginning to study Spanish was \Sexpr{eligible_grp_desc["L2 Learner","span_acq_age_Mean"]}. The data collected from the second LS target group recruited was used in the analysis conducted for Chapter \ref{ch-seg-online}.

\begin{table}
\caption{Attributes of recruited L2 Spanish online participants.}
\label{tab-demo-online-eng}
\centering
\begin{tabular}{c c c c}
\toprule
\multicolumn{3}{c}{Age} & Spanish Acquisition Age\\
\cmidrule(lr){1-3}\cmidrule(lr){4-4}
Min & Max & Mean & Mean\\
\midrule
\Sexpr{eligible_grp_desc["L2 Learner","age_Min"]} 
& \Sexpr{eligible_grp_desc["L2 Learner","age_Max"]} 
& \Sexpr{eligible_grp_desc["L2 Learner","age_Mean"]} 
& \Sexpr{eligible_grp_desc["L2 Learner","span_acq_age_Mean"]}\\
\bottomrule
\multicolumn{4}{l}{Total participants: n = \Sexpr{eligible_grp_desc["L2 Learner","n"]}}\\
\end{tabular}
\end{table}

For the entire dissertation project, \Sexpr{eligible_desc[1, "n"]} participants---\Sexpr{eligible_gen_desc["Female","n"]} females and \Sexpr{eligible_gen_desc["Male","n"]} males---were recruited that met all inclusion criteria. The participants' ages ranged from \Sexpr{eligible_desc[1, "age_Min"]} to \Sexpr{eligible_desc[1, "age_Max"]} years old with an average of \Sexpr{eligible_desc[1, "age_Mean"]} years. 

\begin{table}
\caption{Attributes of all recruited participants.}
\label{tab-demo-part}
\centering
\begin{tabular}{l c c c c c c}
\toprule
& & \multicolumn{3}{c}{Age} &  \multicolumn{2}{c}{Mean Age of Acquisition}\\
\cmidrule(lr){3-5}\cmidrule(lr){6-7}
& n & Min & Max & Mean & Spanish & English\\
\midrule
Female
& \Sexpr{eligible_gen_desc["Female","n"]}
& \Sexpr{eligible_gen_desc["Female","age_Min"]} 
& \Sexpr{eligible_gen_desc["Female","age_Max"]} 
& \Sexpr{eligible_gen_desc["Female","age_Mean"]} 
& \Sexpr{eligible_gen_desc["Female","span_acq_age_Mean"]}
& \Sexpr{eligible_gen_desc["Female","eng_acq_age_Mean"]}\\
Male
& \Sexpr{eligible_gen_desc["Male","n"]}
& \Sexpr{eligible_gen_desc["Male","age_Min"]} 
& \Sexpr{eligible_gen_desc["Male","age_Max"]} 
& \Sexpr{eligible_gen_desc["Male","age_Mean"]} 
& \Sexpr{eligible_gen_desc["Male","span_acq_age_Mean"]}
& \Sexpr{eligible_gen_desc["Male","eng_acq_age_Mean"]}\\
\bottomrule
\multicolumn{6}{l}{Total participants: n = \Sexpr{eligible_gen_desc["Female","n"]+ eligible_gen_desc["Male","n"]}}\\
\end{tabular}
\end{table}

\section{Instruments}
\label{sec-instruments}
In order to collect the data that has been reported throughout this dissertation, several specialized instruments were utilized. The first of which was a piece of hardware, a button box, that was used to capture reaction times of participant responses (Section \ref{ssec-button-box}). The second was the use of open source software to build the experiments, which has been widely used in previous linguistic and behavioral science studies (Section \ref{ssec-psychopy}). In addition to special hardware and software, three task based instruments were also used to collect additional data about the linguistic experience and proficiency of the participants. The first of these three instruments was a survey that collected information about language experience and use (Section \ref{ssec-blp}). The last two instruments were vocabulary tests used to collect information about vocabulary sizes in English and Spanish (Section \ref{ssec-lextale} and Section \ref{ssec-lextale-esp}).

\subsection{Button Box}
\label{ssec-button-box}
Many of the measures in this dissertations had a dependent variable based on reaction time. As a result of previous study findings, the difference in reaction times for different experimental conditions were expected to be small. In order to account for these small difference, a button box capable of capturing sub-millisecond measurements was used during all in-person experiments. Once the experiments had been redesigned to run online, the button box was no longer used. During the in-person experiments, the response box was used in all tasks except for the BLP where the internal keyboard and mouse were more efficient for data input and reaction time was not being measured. The response box utilized an arduino Adafruit Feather 32u4 Adalogger micro-controller. This micro-contoller was powered through the USB port on the researcher's computer. It was mounted inside of a laser cut acrylic box and wired to five 30mm arcade style buttons mounted in the top face of the box---white, green, blue, yellow and red moving from left to right. The white button was always used to progress to next screen and was offset at 2.25 inches on center from the remaining four colored buttons, which were evenly spaced at 1.75 inches on center. Before deploying the use of the button box, testing was done using a Raspberry Pi 3B+ following guidelines for building a LagBox \parencite{Bockes2018-mn}. The Raspberry Pi testing instrument was tested using other devices as well to ensure the readings being provided were in an acceptable tolerance. For full details on building and testing a button box such as the one used here, please refer to Appendix \ref{app-button-box}.

\subsection{PsychoPy}
\label{ssec-psychopy}
PsychoPy is an open source software package that was originally built on the python programming language \parencite{Peirce2019-dm}. As the program has evolved and become more widely used in online experiments, the use of JavaScript has become crucial to its continued use. Currently, the software still allows users to build their experiments in python and then translate their python code to JavaScript when they wish to deploy their experiments online. This program gives the user a graphical user interface (GUI) for which they can use to design their experiments without the need to understand how to program in python. Within the GUI, they give the user the ability to customize how their experiments run and display to participants through the use of \emph{code components}. When the experimenter decides to use this functionality, they must actually write the python or JavaScript code to achieve the functionality they desire. For the most advanced users, a script generated from the GUI can then be further modified outside of the scope that PsychoPy can do natively if desired. For this dissertation, the majority of the experiments were designed using the GUI. Then code components were used to modify and control the run time experience of the experiment. This included modifying the display order of stimuli, the feedback given to the user and the language displayed for instructions on certain sections of the experiment. While the experiments conducted in this dissertation only utilized text, PsychoPy is capable of handling visual imagery and auditory stimuli as well.

\subsection{Bilingual Language Profile}
\label{ssec-blp}
The first task based instrument used in this study was the Bilingual Language Profile (BLP), which is a survey based assessment tool for determining language dominance \parencite{Birdsong2012-wd}. Through its 19 questions, it assesses language history, use, proficiency and attitudes of participants in less than 10 minutes although it was administered as an untimed task. It is available in many languages, but given that all participants recruited for in-person experiments for this dissertation were bilinguals of only Spanish and English, these were the two language pairings used. This tool allowed for the collection of information about participants demographics---name, age, sex, place of residence and educational background. The collection of this demographic information took place at experiment start up screen through the use of text boxes and drop-down fields. All responses were required before the participant could continue to the next screen in the PsychoPy experiment. The BLP also allowed for participants to indicate their language history, use, proficiency and attitudes using point system scales. This information used sliding scales on the computer screen and was the last task completed. Since the BLP survey was completed after all experimental trials, the participants were able to choose whether they received Spanish or English instructions and questions for the survey. The language display of the BLP was done programmatically based off the participant's response to the preferred language question at the beginning of the experiment's setup. The placement of the BLP as the final task was done intentionally for several reasons. First, it was the only task participants completed where the use of the mouse and keyboard were easier to input responses. In addition, response times were not being analyzed making the sub-millisecond button box overkill for the task. Secondly, it generated the most questions for participants in how to respond during a pilot study, which led to the decision to allow this survey to be given in the preferred language of the participant. This allowed for the participant to ask clarification questions about the survey as it was taking place in their preferred language without compromising the integrity of the data of the experiments that focused on the processing of Spanish---a critical part of the project's design.

The BLP assessment tool has been used in numerous language studies with a focus on bilingualism and is available for free under the Creative Commons license. The BLP is available in a paper-based format and electronically through the use of Google Forms. However, in an effort to make the time in the lab and the feel of the experiment as seamless as possible, the participants in this dissertation took the BLP within PsychoPy as well. No modifications were made to the BLP questions or their ordering, but they were formatted in a .csv file that PsychoPy could read. During the survey, there were two or three versions of the same question where the first version asked about English, the second version asked about Spanish and the third version about any other language the participant knew. In order to make the change in language more salient, the language that the question was asking about was printed on the screen in different colors. English was always written in purple, Spanish in blue and other languages in red. To illustrate, a participant would see the following question three times, \emph{In an average week, what percentage of the time do you use the following languages with friends?}. The first time they saw the question, English was displayed in a purple font below the question and above the scale bar used to indicate their response. The second time, the English written in purple was replaced by Spanish in a blue font. The third and final time the question was displayed, the Spanish in blue was replaced by Other Languages in a red font.

The full BLP survey was completed by only participants recruited during in-person data collection while online participants only submitted submitted responses to the demographic questions at the beginning of the experiment in PsychoPy. For in-person participants, a language dominance score could be computed following the guidelines of the BLP survey. The language dominance score falls on a scale between -218 and 218 where -218 represents dominance in one language, Spanish in this project, and 218 represents dominance in the other language, English in this case. Therefore, a person that has a language dominance closer to zero would represent a more balanced bilingual.

\subparagraph{Module Scores.}
In order to calculate the language dominance score for a participant, a module score must be calculated for each of the four sections---Language History, Language Use, Language Proficiency and Language Attitudes---for both languages individually. In other words, participants receive two scores for each module. One is the sum of all answers in the module that asks about English while the second is the sum of all questions in the module asking about Spanish. The contents of each module, numbers of questions and scoring scales, are different for each of the four modules, which are explained below. 

The language history section contained six questions that asked about a participants language learning background, comfortability and language of living, working and family environments. All questions in the language history module were on a scale of 0 to 20 and was the most complicated section for scoring. The first two questions asked about the age of learning a language and being comfortable with a language, which have a reverse scoring. For example learning a language at the age of 1 is actually scored as 19. Similarly, starting to feel comfortable using the language at the age of 19 will score a 1 and 20+ will score a zero for the calculation. These first two questions also have phrasal responses where the zero was represented by the response \emph{Not yet} and a score of 20 represented phrasal responses \emph{Since birth} or \emph{For as long as I can remember}. The remaining four questions in this section asked about time frames measured in number of years, which have a 1 to 1 relationship with the scale and its value in the calculation. For example, living in a family speaking or a particular region for 1 year where English is spoken would score a value of 1 towards a participants English language history score. That same participant may select 20+ for their work environment in Spanish which would score a 20 towards their Spanish language history module score.

\begin{gather}
English_{History} = Q1a + Q2a + Q3a + Q4a + Q5a + Q6a\\
Spanish_{History} = Q1b + Q2b + Q3b + Q4b + Q5b + Q6b
\end{gather}
\begin{align*}
\intertext{where:}
a & = \text{questions asking about English language history}\\[-2ex]
b & = \text{questions asking about Spanish language history}\\[-2ex]
\end{align*}

Once the sum for each language has been computed, a general idea of the amount a language has been exposed to in the participant's past can be interpreted. The minimum score a participant could get for English or Spanish was zero while the maximum score possible was 120. The higher the score is in the language history module, the more exposure the participant has had to that language and vice versa. For example, a participant with an English history score of 100 and Spanish history score of 25 has had a lot more exposure to English than they have had to Spanish.

The second section, language use, asked five questions about a participant's language use of language 1, language 2 and other languages. For example, the survey would ask about the percentage of English, Spanish and other languages spoken with family, friends or at work/school during an average week for the participant. Other questions asked about the percentage of time they counted or spoke to themselves in English, Spanish or other languages. In the case of this project, language 1 was English while language 2 was Spanish. This section was the most confusing for participants because the sum of all languages had to equal 100 percent and participants had a difficult time tracking the percentages that they gave to each language. Due to technical limitations, the tick marks on the scale in PsychoPy were displayed as 0 to 10 where zero represented 0 percent and ten represented 100 percent, which added to the confusion. In this section, if a participant indicated that they spoke English with friends 80 percent of the time during an average week, they would only have 20 percent left to allocate towards Spanish and other languages. For the calculations, the range of scores went from o to 10 where zero percent was valued at 0 and 100 percent was valued at 10. Since this project recruited participants who spoke Spanish and English, the other languages category was rarely more than zero percent. However, it was at this point that it came to light that some participants spoke languages other than Spanish and English. These participants were allowed to finish the experiment and received compensation, but their data was removed and not analyzed in any part of this dissertation because they fell outside the scope of the intended group demographics. At the start of this section in the questionnaire, each participant was walked through the instructions and checked for understanding before they proceeded. Many times the researcher had to offer a personal example in order to try to minimize the confusion which could have led to participants submitting inaccurate percentage data for this section. 

\begin{gather}
English_{Use} = Q7a + Q8a + Q9a + Q10a + Q11a\\
Spanish_{Use} = Q7b + Q8b + Q9b + Q10b + Q11b
\end{gather}
\begin{align*}
\intertext{where:}
a & = \text{questions asking about English language use}\\[-2ex]
b & = \text{questions asking about Spanish language use}\\[-2ex]
\end{align*}

The sums for each language gave a general idea of the amount of each language that the participant typically has used. The minimum score a participant could get for English or Spanish was zero while the maximum score possible was 50. Again, a higher score in the language use module indicated more use of a language. To illustrate with a hypothetical participant who scored a 40 in English and Spanish use score of 10 would typically have a strong tendency to use English rather than Spanish in their daily lives. If a participant scored a 50 in Spanish then they would also score a 0 in English and a 0 in other languages because the score is calculating the proportions of each language used. This would indicate that this participant uses Spanish exclusively during their daily lives.

Language proficiency was the third language module in the BLP survey. This module included four questions, which asked about the four language skills---speaking, listening, reading and writing. The survey asked, \emph{How well do you speak the following languages?}. The first time the participant saw this question, English was printed on the screen in a purple font directly below the question. The second version was shown immediately following the first version, but the English in purple font had been replaced by Spanish printed on the screen in a blue font. All questions were asked for English and then Spanish. Each question was based on a 0 to 6 Likert scale, where the Likert scale value chosen matched the value used in the calculation. The low end of the language proficiency scale, a zero, represented \emph{not well at all} while the high end, a six, represented \emph{very well}. 

\begin{gather}
English_{Proficiency} = Q12a + Q13a + Q14a + Q15a\\
Spanish_{Proficiency} = Q12b + Q13b + Q14b + Q15b
\end{gather}
\begin{align*}
\intertext{where:}
a & = \text{questions asking about English proficiency}\\[-2ex]
b & = \text{questions asking about Spanish proficiency}\\[-2ex]
\end{align*}

In this module it was possible to score between 0 and 24 for both English or Spanish. The higher the score for a language, the higher proficiency was expected to be for that participant. Unlike the previous language module, language use, it was possible for participants to score high in proficiency for both Spanish and English. For example, a participant who scored a 20 in English and a 24 in Spanish would be indicative of a highly proficient user of both English and Spanish. However, a participant scoring 20 in English and a 5 in Spanish would indicate the participant is more proficient in English than they are in Spanish.

The last of the language module scores, language attitude, included four questions that asked about a participant's identity and perception of themselves as a language user of English and Spanish. An example question from the survey asked, \emph{I feel like myself when I speak English.} and this question was immediately followed by a second question, \emph{I feel like myself when I speak Spanish}. Like the language proficiency module, each question was based on a 0 to 6 Likert scale, where the Likert scale value chosen matched the value used in the calculation. The scale ranged from \emph{disagree} on the lower end, a zero, to \emph{agree} on the upper end, a six.

\begin{gather}
English_{Attitudes} = Q16a + Q17a + Q18a + Q19a\\
Spanish_{Attitudes} = Q16b + Q17b + Q18b + Q19b
\end{gather}
\begin{align*}
\intertext{where:}
a & = \text{questions asking about language attitude towards English}\\[-2ex]
b & = \text{questions asking about language attitude towards Spanish}\\[-2ex]
\end{align*}

The scoring of language attitudes was similar to the scoring of the language proficiency module. It was possible to score between 0 and 24 for both English or Spanish. A higher score for a language indicated a higher degree of connection to that language. Again, it was possible for participants to score high in language attitude for both Spanish and English. A participant who scored a 24 in English and a 24 in Spanish would be indicative of a strong connection between the participant and their identity as a user of both English and Spanish. However, a participant scoring 24 in Spanish and a 10 in English would indicate the participant's tendency to connect with Spanish as opposed to English.

\subparagraph{Global Language Scores.}
Once all four module scores had been calculated for both language 1 and language 2, English and Spanish respectively, the global language score could be calculated for each of the two languages individually. The questionnaire weighted each module score differently for the computation of the global language scores (see Table \ref{tab-blp-weights}). Since the global language score was computed for each language independent of the other, the minimum score for each language is 0 and the maximum score achievable is 218.

\begin{table}
\caption{Module score weights used to calculate each language's global score.}
\label{tab-blp-weights}
\centering
\begin{tabular}{c c}
\toprule
Module Score & Weight\\
\midrule
Language History & 0.454\\
Language Use & 1.09\\
Language Proficiency & 2.27\\
Language Attitudes & 2.27\\
\bottomrule\\
\end{tabular}
\end{table}
\begin{equation}
\begin{split}
Global Score_{Language} & = (History_{Language} * 0.454) + (Use_{Language} * 1.09)\\ 
& + (Proficiency_{Language} * 2.27) + (Attitudes_{Language} * 2.27)
\end{split}
\end{equation}
\begin{align*}
\intertext{where:}
Language & = \text{English or Spanish}\\[-2ex]
\end{align*}

\subparagraph{Language Dominance Score.}
Finally, the language dominance score was calculated by subtracting the global English score for language 1 from the global Spanish score for language 2. As previously mentioned, this score can range from -218 to 218. A negative number indicates that the participant has a stronger preference for language 2 whereas a positive number shows a participant's stronger preference for language 1. In the current project, a negative language dominance score indicated a stronger dominance for Spanish while a positive score indicated English as the more dominant language of the participant. For a detailed walk through of these calculations using real participant data as an example and the materials for the full BLP questionnaire actually used during the current project, see Appendix \ref{app-blp}.

\begin{equation}
Language Dominance = Global Score_{English} - Global Score_{Spanish}
\end{equation}

The language dominance score originally was thought to be a very important factor in determining group differences because the design needed to be able to tease apart differences early and late learners of Spanish. However, with the restriction put into place for COVID-19 and the data that had been collected prior to them indicating that insufficient sample size for early learners of Spanish had been collected, language dominance was less of a concern. This was due to the fact that the control group being native Spanish speakers would be dominant in Spanish while the native English speakers would be dominant in English. Therefore, participants who completed experiments online saw modified versions of BLP questions at the beginning of the experiment setup process screen. The questions at the startup screen included all the basic demographic questions that in-person participants saw---name, age, sex, place of birth, resident country, preferred language and educational background. For the monolingual Spanish group, the only additional question asked at startup was, \emph{Idioma usado en casa.} 'Language used at home.', which was also asked of the L2 learners of Spanish who participated online. Since the BLP survey was inherently designed to capture the language attributes of bilinguals, it did not make sense to ask any additional modified questions of the BLP survey to the monolingual Spanish speakers. Monolinguals only have knowledge of one language so all responses would be 100 percent towards their native language and zero percent for the second language that the BLP survey was inquiring about. However, it was decided that additional information would need to be collected on the L2 learners of Spanish in order to better understand their backgrounds as second language learners. This was necessary to ensure the LS groups that participated online and in-person were comparable in that their Spanish level was equivalent or higher than the fifth semester Spanish course offered at the University of Arizona. Therefore, six additional questions were asked in Spanish to all LS group participants at the experiment startup screen. They are listed below followed by their English translations.

\begin{singlespacing}
\begin{enumerate}
\item ¿A qué edad empezó a aprender español?\newline \emph{'What age did you start learning Spanish?'}
\vspace{.1in}
\item ¿Cómo habla en español?\newline \emph{'How well do you speak Spanish?'}
\vspace{.1in}
\item ¿Cómo entiende en español?\newline \emph{'How well do you understand Spanish?'}
\vspace{.1in}
\item ¿Cómo lee en español?\newline \emph{'How well do you read in Spanish?'}
\vspace{.1in}
\item ¿Cómo escribe en español?\newline \emph{'How well do you write in Spanish?'}
\vspace{.1in}
\item ¿Cuándo fue la última vez que tomó una clase de español?\newline \emph{'When was the last time you took a Spanish class?'}
\end{enumerate}
\end{singlespacing}

Due to the fact that the full BLP was not completed by these participants, it was not possible to calculate the language dominance of speakers that were computed for in-person participants. For online participants, these modified versions of the BLP questions served as a check to verify the responses that they had responded to when creating their Prolific profiles. For example, some participants responded with conflicting information to critical inclusion criteria such as language use at home, preferred language, birth place, current residence, etc. Prolific provided communication abilities between researchers and participants who had completed their studies. It was through this method that the conflicting answers were attempted to be resolved. In most cases, the participant verified that the information entered into the experiment was more accurate than their Prolific profiles. In the majority of cases, the changes did not make them ineligible according to the group attributes for which they were recruited. These participants remained in the applicant pool, their data was analyzed and they were advised to update their Prolific profile to match. However, in some cases the answers provided in the experiment were more accurate, which made them ineligible to participate. To illustrate a common possibility with language research studies, that arose in during the current project was that a participant had learned a new language since registering with Prolific. In these cases, the participants were asked to update their profiles to match their current conditions and excluded from data downloads and analysis. Researchers were able to pass this information along to Prolific who would follow-up with them to ensure the problems were resolved and maintain integrity of the participant pool.

\subsection{English Vocabulary Size}
\label{ssec-lextale}
In order to better understand the English language proficiency of participants, the Lexical Test for Advanced Learners of English (LexTALE) was used \parencite{Lemhofer2012-hz}. The LexTALE is a English vocabulary based proficiency test widely used in second language research. The LexTALE test contained 60 vocabulary items presented as an untimed visual lexical decision task. In addition, it included three additional practice items that always appeared as the first three items. The LexTALE task is used to correlate vocabulary knowledge and language proficiency in English. According to the findings of Lemhöfer \& Broersma \parencite*{Lemhofer2012-hz}, self-ratings such as writing, reading, listening and speaking proficiency, while significant in some cases, did not have the same predicative power as the LexTALE for translation accuracy and overall proficiency. For example, the LexTALE vocabulary test was able to distinguish between lower intermediate (up to 59 percent), upper intermediate (60–80 percent) and advanced (above 80 percent) levels of proficiency based on the average percent of correct responses. In terms of word recognition experiments, the LexTALE remained a significant predictor of success while self-ratings were not \parencite{Lemhofer2012-hz}. The LexTALE task is publicly available online at www.lextale.com and has been designed to run in PRAAT, Matlab and Presentation. For data collection purposes in this dissertation project, participants completed the LexTALE using PsychoPy in order to create the feel of a single, connected experimental session.

Similar to the BLP, all participants that completed experiments in-person took the LexTALE. Also like the BLP task, the LexTALE task also followed all tasks where Spanish and reaction times in relation to processing Spanish were recorded. This allowed the allowed the instructions for the task to be presented to participants in English or Spanish based off of their response to the \emph{preferred language} field in the experiment's startup dialog box. For the online experiments, the control group was monolingual Spanish speakers and the target group was native English speakers. Therefore, English ability was not a concern and the online participants did not complete the LexTALE task.

For the participants completing the LexTALE, they were instructed that they were going to see strings of letters appear on the screen. They were instructed to respond \emph{yes} if they thought the letters were actually a real word in English and to respond \emph{no} if they believed the word to not exist in English. The instructions also clearly indicated that the task was untimed and that they could take as much time as they needed to respond. The participant pressed the white button on the provided button box to begin the task and the first word appeared in the center of the screen along with \emph{sí} below the word and to the left of center screen while \emph{no} appeared below the word and to the right of center screen. PsychoPy kept the screen constant until the participant entered the response through the button box. When PsychoPy registered a response, it displayed the next word in the task until the participant had responded to all 60 items and then displayed the instructions for the next section. All participants saw the 60 items in the same order as designed by the LexTALE task.

The scoring of the LexTALE task is reported as a percentage of correct responses. The first step was to remove the first three items as they were practice items and should not count towards the participant's score. This left the 60 experimental items remaining, where 40 of them were real English words and 20 were nonwords. Equation \ref{eqn-lextale} was used in accordance with the documentation provided by the LexTALE creators. This equation also corrected for the proportion inequality of words versus nonwords used in the task. The range of scores for the LexTALE task fell between 0 and 100 percent. A higher percentage earned by the participant indicated a larger English vocabulary size. A full list of items and materials used in this project can be found in Appendix \ref{app-lextale}.

\begin{equation}
Score_{LexTALE} = \frac{(\frac{n_{Word}}{40}*100) + (\frac{n_{Nonword}}{20}*100)}{2} 
\label{eqn-lextale}
\end{equation}
\begin{align*}
\intertext{where:}
Score_{LexTALE} & = \text{reported as percentage correct}\\[-2ex]
n_{Word} & = \text{number of correct responses to real words}\\[-2ex]
n_{Nonword} & = \text{number of correct responses to nonwords}\\[-2ex]
\end{align*}
\vspace{-0.5in} % modified manually because equation fell at end of section causing too much whitespace

\subsection{Spanish Vocabulary Size}
\label{ssec-lextale-esp}
The LexTALE and the LexTALE-Esp are tasks used to correlate vocabulary knowledge and language proficiency in English and Spanish respectively \parencite{Izura2014-yw,Lemhofer2012-hz}. While the LexTALE was originally available for English, Dutch and German, there was not version of the available for Spanish. The LexTALE-Esp was created as an adaption of the original LexTALE to provide a similar objective vocabulary test for Spanish that could serve as a predictor of language proficiency \parencite{Izura2014-yw}. While the original intent produced the expected results, the LexTALE-Esp has also been shown to discriminate well between highly proficient Spanish speaking participants with different language dominance \parencite{Ferre2017-jq}. The LexTALE-Esp contained 90 items rather than the 60 items found in the original LexTALE version. The increase in item number did not create additional time constraints as it could still be completed in approximately five minutes. 

Similar to the LexTALE, the materials and instructions for the LexTALE-Esp were publicly available online at crr.ugent.be. However, researchers must design their own method of administering the test electronically. In order to remain consistent with previous two instruments---BLP and LexTALE---participants completed the LexTALE-Esp using PsychoPy to avoid having to switch platforms during the experimental session. Even though the number of items increased to 90, it is important to note that the proportion of words to nonwords were kept the same as the proportions of words to nonwords found in the LexTALE. In other words, Twice as many Spanish words appeared in the task as nonwords, 60 and 30 respectively. It also important to note that the LexTALE-Esp did not provide practice items for the task. Therefore, the current study added three practice items and attempted to match the practice items as closely as possible to the practice items used in the LexTALE task. The first word was a nonword while the last two practice items were indeed real words. In addition, the initial three phonemes matched in item 1 pairings, the initial two phonemes matched in item 2 while only the initial phoneme matched in item 3 (see Table \ref{tab-prac-lextale-esp}). In total, participants actually responded to 93 items. 

\begin{table}
\caption{Practice items for the LexTALE and LexTALE-Esp.}
\label{tab-prac-lextale-esp}
\centering
\begin{tabular}{l l l l}
\toprule
Order & LexTALE & LexTALE-ESP & Word Status\\
\midrule
Item 1 & platery & pladeno \emph{'NW'} & Nonword\\
Item 2 & denial & delantera \emph{'lead position'} &  Word\\
Item 3 & generic & garbardina \emph{'trench coat'} &  Word\\
\bottomrule\\
\end{tabular}
\end{table}

All participants reported in this dissertation project regardless of whether they were recruited for in-person or online data collection completed the LexTALE-Esp. Every participant completed the LexTALE-Esp as the initial task of the experiment. This was done intentionally to serve as a buffer of language mode activation, which could have affected reaction times in the Spanish processing tasks. This was necessary since many of the LS group participants were very likely to speak in English with the researcher throughout process of obtaining consent. As with the LexTALE task, participants were instructed that they were going to see strings of letters appear on the screen. They were told to respond \emph{sí} if they thought the letters represented a real Spanish word and to respond \emph{no} if they believed the word did not exist in Spanish. The instructions clearly indicated that they could take as much time as they needed to respond as the task was untimed. Participants pressed the continue button on the provided button box to begin the task which brought up the initial trial screen. The first word appeared in the center of the screen along with available responses also displaying below the word and off of screen center. The \emph{sí} response always appeared to the left of center screen while the \emph{no} response appeared to the right of center screen. All information remained on the screen until the participant had entered a response. PsychoPy waited until it registered a response and then it displayed the next word in the task. This cycle repeated until the participant had responded to all practice and experimental items. At the completion the LexTALE-Esp, the instructions for the next section were displayed on the screen. No randomization of item presentation order was utilized as in the LexTALE task. Like the LexTALE, this was a feature of the LexTALE-Esp as designed by the creators of the task.

The scoring of the LexTALE-Esp task was documented in Izura, Cuetos and Brysbaert \parencite*{Izura2014-yw}. While it differs from the LexTALE calculation, equation \ref{eqn-lextale-esp} used in the LexTALE-Esp remains quite simple. It does not report the score as a percentage of correct responses. Rather it gives one point for each correctly responded to real word and penalized the participant by subtracting two points for each incorrect response to nonwords. There it was possible to receive a negative score on this task. The minimum score on this task was -60 where a participant would answer all trials incorrectly. The maximum score of 60 could be achieved by responding correctly to all trials. Therefore, a larger Spanish vocabulary size was indicated by a high score in this task. Since, the current project added three practice trials, the first step was to remove them because they should not count towards the participant's score. This left the 60 real Spanish words and 30 Spanish conforming nonwords which were used in the computation of each participant's Spanish vocabulary score. This score is referred to as the \emph{Izura score} throughout the remainder of this dissertation.

\begin{equation}
Score_{LexTALE-Esp} = n_{Word} - 2 * n_{Nonword}
\label{eqn-lextale-esp}
\end{equation}
\begin{align*}
\intertext{where:}
n_{Word} & = \text{number of yes responses to real words}\\[-2ex]
n_{Nonword} & = \text{number of yes responses to nonwords}\\[-2ex]
\end{align*}

In case other researchers preferred the percentage score, Izura, Cuetos and Brysbaert \parencite*{Izura2014-yw} provided equation \ref{eqn-lextale-esp-percent} as a footnote in their documentation. However, all LexTALE-Esp scores reported in the current project were calculated using equation \ref{eqn-lextale-esp}. The complete list of materials used for the LexTALE-Esp are included in Appendix \ref{app-lextale-esp}.

\begin{equation}
Score_{LexTALE-Esp} = \frac{n_{Word}}{60} - \frac{n_{Nonword}}{30}
\label{eqn-lextale-esp-percent}
\end{equation}
\begin{align*}
\intertext{where:}
Score_{LexTALE-Esp} & = \text{reported as percentage correct}\\[-2ex]
n_{Word} & = \text{number of yes responses to real words}\\[-2ex]
n_{Nonword} & = \text{number of yes responses to nonwords}\\[-2ex]
\end{align*}
\vspace{-0.5in} % modified manually because equation fell at end of section causing too much whitespace

In total, there were \Sexpr{eligible_desc[1, "n"]} unique participants that were used in the analysis of this dissertation. Of these \Sexpr{eligible_desc[1, "n"]} participants, \Sexpr{eligible_grp_desc["Spanish", "n"] + eligible_grp_desc["Monolingual Spanish", "n"]} were Spanish native speakers and \Sexpr{eligible_grp_desc["English", "n"] + eligible_grp_desc["L2 Learner", "n"]} were native English speakers. For the Spanish control group, the average Izura score, 
M= \Sexpr{round(lang_stat_compare["L1 Spanish", "Mean"],2)}, 
SD= \Sexpr{round(lang_stat_compare["L1 Spanish", "SD"],2)} 
at 95\% CI 
[\Sexpr{round(lang_stat_compare["L1 Spanish", "LL"],3)}, 
\Sexpr{round(lang_stat_compare["L1 Spanish", "UL"],3)}], 
was larger than the English speaking experimental group, 
M= \Sexpr{round(lang_stat_compare["L1 English", "Mean"],2)}, 
SD= \Sexpr{round(lang_stat_compare["L1 English", "SD"],2)} 
[\Sexpr{round(lang_stat_compare["L1 English", "LL"],3)}, 
\Sexpr{round(lang_stat_compare["L1 English", "UL"],3)}]. 
The mean difference, 
M= \Sexpr{round(lang_stat_compare["L1 Spanish", "Mean"] - 
lang_stat_compare["L1 English", "Mean"],2)}, 
is a statistically significant difference between the two groups' Spanish vocabulary size, 
\emph{t}(\Sexpr{round(lang_compare$parameter,2)})= 
\Sexpr{round(lang_compare$statistic,4)}, 
p < 0.0001 %\Sexpr{round(lang_compare$p.value,4)}
[\Sexpr{round(lang_compare$conf.int[1],3)}, 
\Sexpr{round(lang_compare$conf.int[2],3)}]. 
In terms of Spanish vocabulary size, the bimodal distribution reflected by the Izura scores reveals the two distinct groups targeted for recruitment were obtained. Figure \ref{plt-hist-eligible-part} shows the distribution of Spanish vocabulary size based on the native language of the participants.

\begin{figure}[h]
\begin{center}
<<elig_part_hist, fig.width= 5, fig.height= 2>>=
hist_eligible_grouped
@      
\caption[Histogram: Eligible Participants]{Shows the Spanish vocabulary size for all participants meeting the inclusion criteria distributed by native language calculated through the equation provided by \parencite{Izura2014-yw}}
\label{plt-hist-eligible-part}
\end{center}
\end{figure}

When the groups are broken down individually according to native language, it is possible to look at differences in Spanish vocabulary size between groups who participated online and those who participants in person. For the native Spanish speaking groups---monolinguals and the L2 learners of English---Figure \ref{plt-hist-eligible-esp-part} shows that no statistical difference was found using the Izura score as the measure of Spanish vocabulary size. The monolingual Spanish group recruited online had average Izura score, 
M= \Sexpr{round(esp_stat_compare["Online", "Mean"],2)}, 
SD= \Sexpr{round(esp_stat_compare["Online", "SD"],2)} 
at 95\% CI 
[\Sexpr{round(esp_stat_compare["Online","LL"],3)}, 
\Sexpr{round(esp_stat_compare["Online","UL"],3)}], 
while the L2 English group recruited in-person averaged, 
M= \Sexpr{round(esp_stat_compare["In-person", "Mean"],2)}, 
SD= \Sexpr{round(esp_stat_compare["In-person", "SD"],2)} 
[\Sexpr{round(esp_stat_compare["In-person","LL"],3)}, 
\Sexpr{round(esp_stat_compare["In-person","UL"],3)}]. 
The mean difference in Spanish vocabulary size, 
M= \Sexpr{round(abs(esp_stat_compare["Online", "Mean"] - 
esp_stat_compare["In-person", "Mean"]),2)}, 
was not significant, 
\emph{t}(\Sexpr{round(esp_compare$parameter,2)})= 
\Sexpr{round(esp_compare$statistic,4)}, 
p < \Sexpr{round(esp_compare$p.value,4)} 
[\Sexpr{round(esp_compare$conf.int[1],3)}, 
\Sexpr{round(esp_compare$conf.int[2],3)}]. 
This is not surprising given that both recruitment groups were native Spanish speakers. It would not be expected that learning a second language, English in this case, would cause a decrease in the L1 vocabulary size.

\begin{figure}[h]
\begin{center}
<<elig_esp_part_hist, fig.width= 5, fig.height= 2>>=
hist_eligible_esp_grouped
@      
\caption[Histogram: Eligible Spanish Participants]{Shows the Spanish vocabulary size for Spanish native speaker participants distributed by recruitment method calculated through the equation provided by \parencite{Izura2014-yw}.}
\label{plt-hist-eligible-esp-part}
\end{center}
\end{figure}

For the English native speakers, Figure \ref{plt-hist-eligible-ls-part} shows the overlap between the two distribution, which differ from one another in Spanish vocabulary size. The L2 Spanish group recruited online had larger Spanish vocabulary size, 
M= \Sexpr{round(eng_stat_compare["Online", "Mean"],2)}, 
SD= \Sexpr{round(eng_stat_compare["Online", "SD"],2)} 
at 95\% CI 
[\Sexpr{round(eng_stat_compare["Online", "LL"],3)}, 
\Sexpr{round(eng_stat_compare["Online", "UL"],3)}], 
than the L2 Spanish group recruited in-person 
M= \Sexpr{round(eng_stat_compare["In-person", "Mean"],2)}, 
SD= \Sexpr{round(eng_stat_compare["In-person", "SD"],2)} 
[\Sexpr{round(eng_stat_compare["In-person", "LL"],3)}, 
\Sexpr{round(eng_stat_compare["In-person", "UL"],3)}]. 
The mean difference, 
M= \Sexpr{round(abs(eng_stat_compare["Online", "Mean"] - 
eng_stat_compare["In-person", "Mean"]),2)}, 
reveals a statistical difference in Spanish vocabulary size between the native groups by recruitment method, 
\emph{t}(\Sexpr{round(eng_compare$parameter,2)})= 
\Sexpr{round(eng_compare$statistic,4)}, 
p < 0.0001 %\Sexpr{round(eng_compare$p.value,4)}
[\Sexpr{round(eng_compare$conf.int[1],3)}, 
\Sexpr{round(eng_compare$conf.int[2],3)}]. 
While this may seem surprising initially, it is important to note that the in-person recruitment took place on the University of Arizona campus while the online recruitment was not held to the same restriction. As a result, age differences, which also likely plays a role in the average length of time since the onset of Spanish acquisition may be responsible for the larger vocabulary size in the participants recruited online. Indeed, the average age was higher in the online group, 
M= \Sexpr{round(eng_stat_compare["Online", "Mean_age"],2)}, 
SD= \Sexpr{round(eng_stat_compare["Online", "SD_age"],2)} 
at 95\% CI 
[\Sexpr{round(eng_stat_compare["Online", "LL_age"],3)}, 
\Sexpr{round(eng_stat_compare["Online", "UL_age"],3)}], 
than the L2 Spanish group recruited in-person, 
M= \Sexpr{round(eng_stat_compare["In-person", "Mean_age"],2)}, 
SD= \Sexpr{round(eng_stat_compare["In-person", "SD_age"],2)} 
[\Sexpr{round(eng_stat_compare["In-person", "LL_age"],3)}, 
\Sexpr{round(eng_stat_compare["In-person", "UL_age"],3)}]. 
The mean difference, 
M= \Sexpr{round(abs(eng_stat_compare["Online", "Mean_age"] - 
eng_stat_compare["In-person", "Mean_age"]),2)}, 
revealed a statistical difference in age between the native English groups by recruitment method, 
\emph{t}(\Sexpr{round(eng_age_compare$parameter,2)})= 
\Sexpr{round(eng_age_compare$statistic,4)}, 
p < 0.0001 %\Sexpr{round(eng_compare$p.value,4)}
[\Sexpr{round(eng_age_compare$conf.int[1],3)}, 
\Sexpr{round(eng_age_compare$conf.int[2],3)}]. 
Given the difference in average age, it is not surprising that the average length of time from the onset of Spanish acquisition was also higher in the online group, 
M= \Sexpr{round(eng_stat_compare["Online", "Mean_len_acq"],2)}, 
SD= \Sexpr{round(eng_stat_compare["Online", "SD_len_acq"],2)} 
at 95\% CI 
[\Sexpr{round(eng_stat_compare["Online", "LL_len_acq"],3)}, 
\Sexpr{round(eng_stat_compare["Online", "UL_len_acq"],3)}], 
than the L2 Spanish group recruited in-person, 
M= \Sexpr{round(eng_stat_compare["In-person", "Mean_len_acq"],2)}, 
SD= \Sexpr{round(eng_stat_compare["In-person", "SD_len_acq"],2)} 
[\Sexpr{round(eng_stat_compare["In-person", "LL_len_acq"],3)}, 
\Sexpr{round(eng_stat_compare["In-person", "UL_len_acq"],3)}]. 
The mean difference, 
M= \Sexpr{round(abs(eng_stat_compare["Online", "Mean_len_acq"] - 
eng_stat_compare["In-person", "Mean_len_acq"]),2)}, 
revealed the differences in length of time since Spanish acquisition age began to be significant, 
\emph{t}(\Sexpr{round(eng_len_acq_compare$parameter,2)})= 
\Sexpr{round(eng_len_acq_compare$statistic,4)}, 
p < 0.0001 %\Sexpr{round(eng_compare$p.value,4)}
[\Sexpr{round(eng_len_acq_compare$conf.int[1],3)}, 
\Sexpr{round(eng_len_acq_compare$conf.int[2],3)}]. 
These data seem quite plausible in that the participants recruited for the study likely continued to use Spanish to some degree in their lives, which would make learning or being exposed to new vocabulary over time a common experience. 

However, language acquisition age would be a much more likely variable to influence the results of this study as it revolves around phonological acquisition processes rather than acquiring new lexical items. As such, a Welch two-sample t-test was used to look at the difference in average age of acquisition for Spanish. The age of Spanish acquisition in the online group, 
M= \Sexpr{round(eng_stat_compare["Online", "Mean_esp_age"],2)}, 
SD= \Sexpr{round(eng_stat_compare["Online", "SD_esp_age"],2)} 
at 95\% CI 
[\Sexpr{round(eng_stat_compare["Online", "LL_esp_age"],3)}, 
\Sexpr{round(eng_stat_compare["Online", "UL_esp_age"],3)}], 
was not significantly different than the L2 Spanish group recruited in-person,
M= \Sexpr{round(eng_stat_compare["In-person", "Mean_esp_age"],2)}, 
SD= \Sexpr{round(eng_stat_compare["In-person", "SD_esp_age"],2)} 
[\Sexpr{round(eng_stat_compare["In-person", "LL_esp_age"],3)}, 
\Sexpr{round(eng_stat_compare["In-person", "UL_esp_age"],3)}]. 
The mean difference, 
M= \Sexpr{round(abs(eng_stat_compare["Online", "Mean_esp_age"] - 
eng_stat_compare["In-person", "Mean_esp_age"]),2)}, 
revealed the differences in age of Spanish acquisition between groups failed to reach significance, 
\emph{t}(\Sexpr{round(eng_esp_age_compare$parameter,2)})= 
\Sexpr{round(eng_esp_age_compare$statistic,4)}, 
p < \Sexpr{round(eng_esp_age_compare$p.value,4)} 
[\Sexpr{round(eng_esp_age_compare$conf.int[1],3)}, 
\Sexpr{round(eng_esp_age_compare$conf.int[2],3)}].


\begin{figure}[h]
\begin{center}
<<elig_ls_part_hist, fig.width= 5, fig.height= 2>>=
hist_eligible_eng_grouped
@      
\caption[Histogram: Eligible English Participants]{Shows the Spanish vocabulary size for English native speaker participants distributed by recruitment method calculated through the equation provided by \parencite{Izura2014-yw}.}
\label{plt-hist-eligible-ls-part}
\end{center}
\end{figure}

\section{Study Conditions}
\label{sec-conditions}
The data collection locations for the entire dissertation were conducted in the United States and Mexico. Throughout the project, data collection methods changed from laboratory conditions for in-person data collection to online data collection methods as a necessity in response to the COVID-19 social distancing requirements. Below are detailed descriptions of both data collection methods and site locations.

\subsection{In-person Data Collection}
\label{ssec-conditions-person}
Participants recruited in Tucson, AZ came to a quiet location in the main library on the University of Arizona campus. The room was only big enough for the researcher and one participant at a time. It provided a quiet environment as it was located on one of the study floors, i.e. a quiet floor, and had its own locking door which had a sign posted on it stating "Experiment in progress, do not knock". While the door had a window that could not be covered, the participant was sitting facing away from the window so that motion outside the room was not visually distracting. While the participant was actively completing the experiment, all walls and whiteboards in the room were bare and clean and the researcher sat behind and to the left of the participant. 

Participants recruited in Hermosillo, Mexico came to a quiet location in the library on the University of Sonora campus. Unlike the library in Tucson, AZ, rooms were not available to reserve in which to conduct the experiment. However, it was was able to secure a quiet corner in the back of the library near a service desk to conduct the experiments. The librarians assisted in directing other patrons around the area to minimize foot traffic around the participants taking part in the experiments. To further minimize visual distractions to the participant, they were sat facing the wall away from the center of the library and adjacent to a plain wall on their left. The researcher sat slightly behind and to the right of the participant the entire time the experiment took place.  

In both in-person data collection locations, initial contact was all conducted through email. A participant wrote the initial email to the researcher after receiving information from a flyer, class announcement or word of mouth from previous participants to express interest. Once interest was expressed, the potential participant was sent an invite to calendar where they could register for available 1 hour time-slots through Google Appointments. Once they had registered for a time-slot, they received the details of the location of the experiment and procedures via e-mail. Participants in Tucson, AZ were greeted at the main entrance of the library, where they were briefed on the experiment and gave consent before being escorted to the fourth floor experimental room. Participants in Hermosillo, MX were given explicit instructions to table in the back of the library and description of the researcher and the visible button box they could identify on the table. They were briefed on the experiment and gave consent before beginning. The experimental variables related to hardware and software were completely controlled for in-person experiments. This level of control was available because the researcher provided all equipment used during the experiment. All participants used the 13-inch Mid 2012 MacBook Pro with a 2.9 GHz Intel Core i7 processor running 16 GB 1600 MHz DDR3 of memory. The operating system during experimentation was macOS Mojave version 10.14.6 and PsychoPy version 3.0.7 was responsible for running all experiments. During the experiment, the computer was disconnected from the wifi and ethernet connections. In addition, all programs, including cloud syncing software, were closed or disabled for the entirety of the experiment run time. All participants also used the same button box which was connected to the laptop via a USB cable to enter responses to all experimental tasks except the BLP questionnaire where everyone used the built-in keyboard and track pad to respond.

\subsection{Online Data Collection}
\label{ssec-conditions-online}
In the online data collection experiments conducted as part of the dissertation, participants completed all tasks using their own personal equipment. As a result, the same level of control over software and hardware variables that were instituted in the in-person experiments was not obtainable. Variables that were unable to be controlled included the computer used including operating systems, input controls, and internet connections. For online experiments, the version of PsychoPy was upgraded from version 3.0.7 to 2020.1.2, which was the most current stable version at the time of data collection. The PsychoPy version upgrade was required in order to host the experiments on Pavlovia which ran off of JavaScript. The python 3 code written for the in-person experiments was converted to JavaScript using a translation tool within PsychoPy with slight modifications to translated code to reproduce the same experimental behavior. PsychoPy version 2020.1.2 was kept consistent across all participants---monolingual Spanish speakers and L2 learners of English---during online data collection. 

Around the same time that this data was being collected, several new studies were becoming available comparing results of online experiments with regards to hardware and software differences available to users who were participating in them \parencite{Anwyl-Irvine2020-hv, Bridges2020-el, Pronk2020-qg}. Bridges et al. \parencite*{Bridges2020-el} released a new study comparing online experiment results that captured reaction times as a measured dependent variable across multiple programs and computer setups using the same high-precision button box as the input device in order to isolate any differences to software related issues. While they found differences between setups and types of experiments, all their results indicated that online data collection for behavioral and psychology based experiments were almost comparable to those historically collected in a lab-based environment in terms of precision timing. Specifically, PsychoPy achieved precision timing less than 4 ms across all web browsers. Since this study did not use auditory stimuli, it was not susceptible to the one area in need of improvement for online platforms. Pronk et al. \parencite{Pronk2020-qg} showed that visual stimuli presented for more than 100 ms were presented with little precision error across all browsers and hardware setup combinations. They noted in particular that MacOS 10.13.2 showed a bimodal distribution for reaction time precision with means differing around 30 ms. They suggested a 10 percent increase in number of participants to compensate for this error. Anwyl-Irvine et al. \parencite*{Anwyl-Irvine2020-hv} compared a larger dataset with more variation in the setups they tested. They noted that experimental designs that needed visual stimuli displays of less than 100 ms, e.g. masked priming experiments, are more likely to be affected the precision errors found in online studies. Nonetheless, all three studies point towards the viability of online studies for research utilizing reaction times as a collected measure. While online studies are not at the same level of accuracy and precision of lab-based setups, in most cases, there is not a reason to avoid online study designs on the basis of reaction timing precision.

This chapter has discussed the participants demographics, software, hardware and experimental settings used in the collection of data for this dissertation. The remainder of this dissertation presents experimental findings on Spanish syllabic intuition in Chapter \ref{ch-intuition}, word segmentation in lab-based experiments in Chapter \ref{ch-seg-lab} and word segmentation in online-based experiments in Chapter \ref{ch-seg-online}.
