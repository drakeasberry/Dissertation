% Introduction chapter with LaTeX code only

%----------------------------------------------------------------------------------------
<<global_opts_intro, echo=FALSE, cache=FALSE, include=FALSE>>=
library(knitr)
library(here)

knitr::opts_chunk$set(
  echo = FALSE
)
here::here()
set_parent(here('Asberry_Dissertation/Dissertation.Rnw'))
@
%----------------------------------------------------------------------------------------

%----------------------------------------------------------------------------------------
% Load statistics in memory from separate files
% Loading them here prevents a changing order messing up 
% reference calls if chapter are later rearranged
<<contentIntro, child=here('Statistics/Demographics/demographic_viz.rnw'), cache=FALSE, include=FALSE>>=
@

<<contentIntuition, child=here('Statistics/Intuition/intuition_viz.rnw'), include=FALSE>>=
@

<<contentLab, child=here('Statistics/Segmentation/target_syl_seg_viz.rnw'), include=FALSE>>=
@

<<contentPilot, child=here('Statistics/Pilot/Pilot.rnw'), include=FALSE>>=
@

<<contentLabDemo, child=here('Statistics/Demographics/lab_demo_viz.rnw'), include=FALSE>>=
@

<<contentIntuitionDemo, child=here('Statistics/Demographics/intuition_demo_viz.rnw'), include=FALSE>>=
@

<<contentOnlineDemo, child=here('Statistics/Demographics/online_demo_viz.rnw'), include=FALSE>>=
@

<<contentOnlinesegMono, child=here('Statistics/Monolingual_lemma/target_syl_mono_viz.rnw'), include=FALSE>>=
@

<<contentOnlinesegL2, child=here('Statistics/L2_lemma/target_syl_l2_viz.rnw'), include=FALSE>>=
@

%----------------------------------------------------------------------------------------

\chapter{Introduction} % Main chapter title
\label{ch-intro} % for referencing this chapter elsewhere, use \ref{ch-intro}
This dissertation was written in order to complete the degree requirements of the Second Language Acquisition and Teaching (SLAT) program at the University of Arizona. There are many facets of language acquisition, but this project will focus on adult second language learners of Spanish. Specifically, it continues to add to the research literature on how adult language learners approach and understand their second language at a subconscious level of processing.

Bilingualism is the acquisition of two languages and it is becoming increasingly more
common as a result of the political, business, and educational discourse that places a major emphasis on globalization and world citizenship. No longer are people only being classified as a citizen of the country they were born into by chance, but also by one’s ability to participate in a global, intercultural environment. As a result, the field of bilingual language research has received a lot more attention in the past few decades than it had previously. Given a quick survey of the current bilingual literature, it is evident that many changes in the areas of focus or methods of approach to bilingual research are evolving alongside technology. It is becoming increasingly more important to consider definitions of bilingualism as well as recognizing and distinguishing between different types of bilinguals. The route to a person's bilingual status can have major implications on the interpretations of experimental results where research questions revolve around bilingualism. The following sections give the definitions assumed in this project for both monolingualism and bilingualism as well as support for distinguishing these groups according to existing literature.

\section{Monolingualism}
Monolinguals are people who only have knowledge of their one native language. This means that they are capable of communicating in only one language. In general, most monolingual speakers live and work in an environment where their native language is spoken. Researchers have attempted describe languages in terms grammars, vocabulary and sounds. They have sought to understand how speakers acquire and process these different aspects of the language they know. Monolinguals have been crucial in understanding ways in which bilinguals agree or disagree with them. As such, they are often used as the control groups in experimental designs. In other instances, they have been used to test experimental items and stimuli in languages that they do not speak. For example, studies looking to distinguish between pre-lexical and post-lexical decisions may use monolingual speakers of a language other than the one being studied. This is an informative process for these studies because they are naïve participants meaning that all stimuli are nonwords to this control group. Therefore, if a naïve monolingual group of participants can complete the task as well as the experimental group who knows the language, then it can be assumed that the lexical knowledge of the language is not the cause of an effect \parencite{Cutler1986-zl}. With the increase in bilingualism and focus on English as a lingua franca, this project had to accept the fact that monolingual Spanish speakers had likely completed basic English courses in order to graduate from secondary school or university. However, participant recruitment targeted monolingual Spanish speakers who did not claim to use or prefer English or self-report fluency in any language other than Spanish.

\section{Bilingualism}
Bilingualism is a bit more complex than monolingualism. For some, bilinguals indicate persons who know exactly two languages and for others it suggests bilinguals are people who know two or more languages. This is further subdivided by the age of acquisition for which the second or subsequent languages were obtained. This section gives a brief overview of the differing viewpoints and defines the parameters for bilingualism used in the current study.

Children being raised with two languages in the household is not a new concept, but one of the major limitations had been obtaining reliable information from these young participants. In more recent years, there has been a focus on simultaneous bilinguals, those who learn two languages from birth. It is becoming more common to recruit infants as participants to get an insight of what is happening in the brains of these new language learners. Studies at the present time have sought to answer questions about language preference, phonetic development and contrasts. Several studies suggested that infants had already begun to learn about their native language prenatally \parencite{Gerhardt1990-pf,Pierson1997-es}. \textcite{Byers-Heinlein2010-fv} found that infants ranging from zero to five days old who were monolingual preferred to listen to their native language, English, which was spoken in the environment of the mother while bilingual infants showed no preference for either language present during their time in the womb of their mothers. Other research had already shown that newborns can discriminate between languages of different rhythmic classes \parencite{Nazzi1998-zc}. \textcite{Byers-Heinlein2010-fv} also found that both monolinguals and bilingual infants could discriminate between two languages before the end of their first week of life. This showed that despite the fact that the bilinguals showed no preference between the two languages of their prenatal environment, they also did not show a delay in discriminatory abilities between them. \textcite{Burns2007-ry} conducted a study on the phonetic representation and found that at six to eight months of age, even monolingual infants discriminate in the same manner that bilingual infants discriminate between the ambiguous stimuli. However, by 10-12 months, the monolingual infants can no longer make this discrimination while the bilingual infants retain the ability to do so. \textcite{Sundara2008-tc} extended these results to monolinguals and bilinguals of the language stimuli retaining the ability to discriminate phonetic contrasts, but monolinguals of a different language had lost the ability to discriminate between the ambiguous sounds.

Other advancements in technology allowed many different types of brain imaging which has assisted researchers in gaining a better understanding of development processes that take place in preverbal infants \parencite{Ferjan_Ramirez2017-lw,Garcia-Sierra2011-tw,Petitto2012-xv,Shafer2011-mv}. The preliminary findings of this \textcite{Shafer2011-mv} revealed for the first time that not only age, but also gender played a role in the development of language acquisition. The six month old female bilinguals already appeared to be aware of the two different languages to which they were exposed whereas their male counterparts did not. It also pointed out the differences in brain activity between monolinguals and bilinguals suggesting that the development of brain activity associated with language acquisition is slightly delayed in bilingual infants. \textcite{Kuhl2008-ob} showed that discrimination of sounds productive in the native language continued to improve after 7.5 month of age while non-native sound discriminations began to decline. They argued that this was suggestive of neural commitment to the native language prior to an infant's first birthday. The importance of this information lies in the fact that even before birth and the very early language development period of a potential participant, there are factors that could contribute to differences in their language acquisition and use later in life. This information should be considered when setting requirements for participant recruitment and inclusion. No participants that fell into this definition of simultaneous bilinguals---acquiring two languages from birth---were utilized in the current study.

Since no participants were targeted in the current project who spoke more than two languages, the other definition of bilinguals describes second language learners. A lot of bilingual research is focused on second language learners, those who became bilinguals after their first language had already been established \parencite{DeKeyser2000-fo,Vokic2010-io}. This point alone differentiates second language learner bilinguals from monolinguals and simultaneous bilinguals because in both of the latter cases, the language learner is beginning with a clean slate upon which to build. However, the second language learners already have a complex advanced language foundation in their native language before beginning to integrate the second language into the existing network of language pathways. A reasonable distinction between second language learners and monolinguals or simultaneous bilinguals is the source of information. For monolinguals and simultaneous bilinguals, the only input they receive is spoken. However, most second language learners have other relevant skills, including social and explicit learning skills in addition to extensive L1 vocabularies \parencite{Cutler2015-tj}. 

In terms of phonetic discrimination and L2 phonological development, second language learners are tasked with mastering sound discriminations that have likely been previously shown to be non-productive in the processing of their native language. There are numerous models that have attempted to tackle or predict these difficulties that second language learners face. \textcite{Lado1957-yg} introduced the Contrastive Analysis Hypothesis (CAH) to argue that an understanding of both the learner’s L1 and L2 would lead to a better prediction of the difficulties the speaker is likely to encounter. \textcite{Eckman1977-fb} attempted to fill in areas that CAH appeared unable to describe with the Markedness Differential Hypothesis (MDH) theory, which stated that the more marked something is in the L1, the harder it will be to acquire in the L2. \textcite{Flege1995-cy} suggested that L2 phonemes not represented in the L1 are more easily acquired than those that have a similar L1 phonetic representation in his Speech Learning Model (SLM). While these models and theories cover more ground than the scope of the current project, they are quite informative to researchers at the experimental design phase. For example, by comparing L1 and L2 sound systems, differences in phonemic inventories, phonological categories, and how sounds combine to make larger units such as syllables or words can inform the types of experimental stimuli selection a researcher uses or from where they recruit participants. 

As a result of the many complexities involved when multiple languages are being investigated, most research on bilingualism has taken monolingual standards as the level of achievement to which the bilingual's language use of the L2 is compared. While this helps control some variation found naturally in language development, this has often placed bilinguals in a negative light on the assumption that the bilinguals lack in some way when being compared to the monolingual model. The bilingual speaker is reported to have fallen short of native like norms in some area of language acquisition such as syntax, phonology, vocabulary size, appropriate social language usages, idiomatic expressions, etc. \parencite{Bond1991-dl,Flege1987-jh,Olmstead2013-oh}. However, there are a growing number of studies that have begun to combat stereotypes of bilingual deficiencies showing that bilinguals may not mimic monolingual behavior exactly or even follow the same learning trajectories at times. These behaviors are beginning to be described as learner differences rather than deficiencies. For example, \textcite{Byers-Heinlein2010-fv} found no difference in discrimination abilities between monolinguals and bilinguals and \textcite{Sundara2008-tc} found that bilinguals actually held on to discrimination abilities of ambiguous sounds longer than their non-native monolingual counterparts where the discrimination ability was productive in one of their two languages. In terms of learning trajectory, \textcite{Shafer2011-mv} found that simultaneous bilinguals deviate from the monolingual linear learning trajectory by losing the ability to discriminate sounds in one of their two languages, but have recuperated this ability in both language by the of age of three or four putting them right back on track with monolinguals. \textcite{Bosch2003-jm} were able to reproduce this U-shaped bilingual learning trajectory in Spanish--Catalan bilinguals in the first year of the infant's life. 

As a result of these studies, the current project set out to deviate from the bilingual monolingual comparison even though the project did eventually utilize monolingual speakers as well. The participant population for this dissertation consisted of two distinct groups: native Spanish speakers and native English speakers. The L1-English speakers were all adult second language learners of Spanish from the United States. The L1-Spanish speakers were all monolinguals or adult second language learners of English from Mexico. No simultaneous bilinguals were used in the current project. The dissertation investigated a linguistic unit, the syllable, by attempting to gain a better understanding of each group's Spanish syllabic intuition and it's effect on a language user's ability to use these intuitions when processing the Spanish language.

\section{Phonological Awareness}
\label{sec-phon-activation}
Up to this point, the previous literature discussed has been fairly concrete, but these items are tied to a more abstract level of sounds, the phonological system. This phonological system is used to describe phenomenon that can be seen through phonetic representation, but cannot directly be addressed. Therefore, researchers have to use their knowledge to design experiments which take advantage of the connection between phonetics, something that can directly measured, and phonology, which cannot. One example is phonological activation, which is how a person derives meaning from the words and its constituent parts, syllables and phonemes, when processing language. Researchers have studied phonological activation in order to gain knowledge about language development and strategies in both native and second language research since phonology is inherent to using and understanding any spoken language. 

Phonemic awareness is defined as a person's ability to identify and play with phonological segments that make up words. An example of this would be asking participants to manipulating letters in a word to create a different word. A participant that has phonemic awareness could successfully complete this task by changing the word \emph{end} to a different word \emph{den} by moving the word final \emph{d} to the word initial position. Since phonemes are the building blocks of syllables, this idea can be extended to syllable manipulation tasks. Here a participant could be asked to delete one syllable in a word that would allow the remaining letters to be a real word. In order to complete this task successfully, a participant would have to delete the syllable \emph{cil} from the word \emph{pen.cil} to leave the word \emph{pen} remaining. These are just two simple examples from a multitude of tasks that can help researchers gain a better understanding of a person's phonological awareness.

Many people associate phonology only within the confines of auditory language, but there is evidence that written language tasks such as reading and writing also involve phonology. Phonological awareness has been shown to be a helpful tool in learning the alphabetic writing system and tied to predictors of reading ability. Although, phonological awareness and reading are connected they cannot completely predict direction of effects. Based on the findings in \textcite{Landerl2019-mq}, phonemic awareness was a good predictor of later reading ability for French, but reading ability also affected phonemic awareness. This interactional pattern of reading supporting phonological awareness and vice versa also emerged between Grades 1 and 2 for English and German. Interestingly, reading ability predicted phonological awareness, but phonological awareness did not predict reading ability in Dutch or Greek. \textcite{Chetail2014-nm} also found that phonemic awareness facilitated growth in printed word recognition. \textcite{Haigh2007-mt} tested bilinguals with interlingual homophones while they read silently and found that bilinguals did activate to some degree both phonological systems when reading in their L2. However, when bilinguals were reading in their L1, the effect disappeared suggesting that participants either did not activate their L2 phonology or it was not activated to a level high enough to affect their L1 phonological activation processes. Understanding that a link exists between reading and phonology, the discussion now turns to previous word recognition studies that have taken advantage of this reading--phonology link.

Several studies have utilized visual word recognition to investigate the role of the syllable in accessing the mental lexicon---the storehouse of vocabulary and meaning in the brain. While these studies are not reading sentences or paragraph in a traditional sense of the term, participants in the following studies did have to read the stimuli on the screen in order to complete the task. This type of design differs from the many auditory based approaches to investigating phonology based questions. One such study investigated French native speakers’ ability to use the syllable to gain access to the mental lexicon with a lexical decision task under a masked priming paradigm \parencite{Ferrand1996-vu}. In the masked priming paradigm, participants are shown unknowingly text on the screen which researchers use to manipulate the experimental conditions underlying their investigation. It is presented unknowingly to the participant because of its short display time where participants do not consciously recognize the text on the screen to be read, but the brain nonetheless processes it as if it had been. Following the prime, participants are shown a series of pound signs, known as the mask, and then a word on the screen fo which they must make a decision. In this type of study, reaction times are collected in order to show whether the primes had a facilitatory (helpful) or inhibitory (hurtful) effect on participant's decision making ability. \textcite{Ferrand1996-vu} found no significant results with their French participants, but only used a 29 millisecond prime display followed by a 14 millisecond backwards mask for a total stimulus onset asynchrony (SOA). Following the suggestion of \textcite{Ferrand1996-vu} that the short SOA may have resulted in the inability of French speakers to use the syllable in lexical access, \textcite{Carreiras2002-mp} investigated syllable congruency as a means of measuring the facilitation or inhibition in the lexical access of Spanish words utilizing a longer SOA. While they found the a crossover effect using six letter disyllabic Spanish words (CV.CV.CV or CVC.CVC in syllabic structure), they also found a speed–accuracy trade-off effect with the two different SOAs—116 milliseconds versus 166 milliseconds. The participants responded faster to the lexical decision task when they had the additional 50 milliseconds of processing time in 166 millisecond SOA, but also made significantly more errors than participants who completed the same task with the 116 millisecond SOA.

The previous results had no way of disentangling the orthographic syllable from the phonological syllable. \textcite{Alvarez2004-nd} set out to investigate whether or not the phonological syllable was a unit used during visual word recognition. In their first experiment, they use disyllabic words with initial CV or CVC syllables allowing them to look at the differences between segmental and syllabic overlap by having the prime and targets share the first three segments, but vary in syllabic structure between CV and CVC—i.e. \emph{ju.nas-JU.NIO} and \emph{jun.tu-JU.NIO}, which appeared in separate lists for counterbalancing across participants. They found that CV targets were responded to faster when the prime had a CV initial structure as well when compared to the primes that had an initial CVC syllable structure. However, the same pattern was not found for CVC targets. Participants also made more errors on CVC target than for CV targets. These findings do support that fact that syllabic priming effects can be found in lexical decision tasks at short SOAs, 64 milliseconds in this study. It is important to note that only a 19 millisecond addition is added to the SOA used by \textcite{Ferrand1996-vu} who did not find effects of syllabic priming in a French lexical decision task—also a Romance language like Spanish that has clear syllable boundaries. This suggests that very small adjustments in experimental design could affect the results of the experiment and should be considered carefully. The second experiment focused more on the question of distinguishing between the phonological and orthographic syllable units \parencite{Alvarez2004-nd}. The researchers here utilized the clear and unambiguous phoneme–grapheme correspondence and the fact that several graphemes map onto the same phoneme. For example, 'b' and 'v' graphemes both map onto the phoneme /b/ in Spanish. This study used four conditions to capture the effects of phonological versus orthographic syllables—\emph{vi.rel-VI.RUS} is the same orthographic and phonological syllable; \emph{bi.rel-VI.RUS} is a different orthographic syllable, but the same phonological syllable; lastly, \emph{vir.ga-VI.RUS} and \emph{bir.ga-VI.RUS} were set as control primes that shared the first three phonemes, but differed in syllable structure. They found faster responses were elicited when overlap included both orthographic and phonological representations than when it only had phonological overlap. Given the speed–accuracy trade-off between the reaction times and error rates of the orthographic-phonological and phonological only conditions, it was suggested that phonological activation was occurring during the visual word recognition experiments. 

In addition to the syllable congruency effect, the final experiment of \textcite{Alvarez2004-nd} showed that the initial syllable was the logical key to lexical access---the lexical retrieval of meaning from the mental lexicon. Additional evidence for the syllable congruency effect and the initial syllable being an essential key to lexical access came from the event-related potential (ERP) experiments that presented words in two colors. One color represented the initial syllable or misrepresented it while the remainder of the word was printed in the second color \parencite{Carreiras2005-us}. They found syllable congruency effects in Spanish for low-frequency real words and pseudowords, but not for high-frequency words. This congruency effect found also interacted the lexicality judgments, but the time frames in which these two processes started differed in time. The syllable congruency effect was available much earlier than the actual lexicality judgement suggesting that segmentation and lexical access were different processes, but that they may work in conjunction with one another. Several years later, an interesting study introduced age and a medical condition, Alzheimer’s disease, into their experimental design to further investigate the syllable congruency effect \parencite{Carreiras2008-ar}. They replicated the fourth experiment of \textcite{Carreiras2002-mp} and were able to find the syllable congruency effect in the control group—elderly people without Alzheimer’s disease—as well as the Alzheimer patients despite large differences in latencies across groups. \textcite{Carreiras2008-ar} also tested syllable frequency effect in a second experiment. The syllable frequency effect was found in the young controls whereas the older age group appears to have a deterioration in the ability to inhibit lexical competitors.

\textcite{Chetail2013-er} studied French in visual segmentation experiment of French. They specifically looked at the difference between orthographic and phonological syllable sized units as well. They found in the majority of cases, the written segmentation syllabification aligned with the phonological syllabification, which had previously been obtained from spoken word recognition studies \parencite{Alvarez2004-nd}. The case where this alignment was not occurred in the case of the French schwa, or the silent 'e' \parencite{Chetail2013-er}. The French participants systematically indicated that there was one more syllable than could be accounted for via phonology. \textcite{Chetail2013-er} argued that this was evidence of the readers relying on the change from C to V as a vowel center to represent the syllable nucleus. They confirmed this reliance on the orthographic segmentation unit with a letter segmentation task where participants searched for /l, r/ in written words. Participants detected /r/ faster in \emph{bi.beron} 'baby bottle' than in \emph{nom.bril} 'navel', where the periods mark the phonological syllable boundary. They argued that this was the result of the orthographic segmentation resulting from the silent 'e' causing the written syllabification to be \emph{bi.be.ron} and making the letter 'r' the first letter of onset in \emph{biberon}, but the second letter of the onset in \emph{nombril}. Since French is not very transparent between its grapheme--phoneme relationship, \textcite{Chetail2014-nm} conducted a similar study in Italian, which has very few exceptions to one grapheme to one phoneme relationship and vice versa. They tested orthography versus phonology based units again by taking advantage of hiatus words such as \emph{te.a.tro} 'theater' syllabified here according to phonology based segmentation units. However, participants consistently responded to the written word that it only contained two syllables instead of three. Again, they found participants were more sensitive to CV syllable types as a default where the orthographic segmentation process seemed to look for vowel centers to mark syllable boundaries. Both of these studies suggest that item selection for visual word segmentation where conclusions about phonology are going to be drawn should be taken into careful consideration during the experimental design stage. 


\section{Visual and Auditory Research Designs}
Researchers must choose experimental designs and methodologies based on their expertise, their capabilities for implementation and what they anticipate will be the most valid and efficient way to address research questions. In terms of phonological processes, both auditory and visual designs have been utilized successfully to complete research producing quality data for analysis. 

Some of the advantages of a visual design include cost effectiveness, ability to be conducted in an online environment and reproducibility. While cost effectiveness may not be the top reason to decide on an experimental methodology, cost does often affect the feasibility of research to be conducted. A visual study design to approach phonological processing is cost effective in that it requires less money for recording equipment, payment to speakers who will record the experimental stimuli and amount of researcher time needed to get a visual research project design off the ground. A visual design saves a lot of time as pre- and post-processing of audio files necessary for quality stimuli and data analysis is not required. Another advantage of time is the ability to collect accurate latency data for visual designs whereas the technology available to date has not been able to produce the same quality data for auditory designs in an online environment \parencite{Bridges2020-el}. Lastly, reproducibility has been a topic of much debate in both psychology and linguistics as many linguistic studies share research paradigms with psychology \parencite{Grieve2021-qa}. While it is true that language is changing and it is nearly impossible to control for all factors that could contribute, the field of linguistics could benefit from following more reproducible research paradigms. In phonology based research, a visual design can help to accomplish part of this problem. Researchers can simply provide the word lists of experimental stimuli used in experiments from which other researchers could then use in their own replication studies. While the sharing of audiophiles is most definitely possible today, it comes at a cost of ensuring audiophiles remain available by hosting on some sort of cloud-based resource which require additional on-going maintenance funds to do so. The next closest alternative is to posting word lists for other researchers to record themselves, but this inherently adds variability to experimental stimuli through differences in low-level phonetic detail due to speaker differences and/or the quality of recording equipment. Due to the nature of a visual design, one disadvantage is the lack of ability to manipulate this low-level phonetic detail. Where these types of questions are being addressed, researchers may have to rely on a completely auditory design or minimally a combination of auditory and visual stimuli to appropriately address their research questions. It is also important to discuss briefly the effects of viewing phonology as an abstract concept versus an episodic memory process. If phonology was viewed from an episodic standpoint, simply using a visual methodology would not actually remove low-level phonetic detail because the /l/ in \emph{balada} 'ballad' and the /l/ in \emph{baldosa} 'tile' would be stored as different representations in the mind of the speaker. However, if phonology were to be viewed in the more abstract manner, the low-level phonetic detail would be removed from the design as the speaker would only have on representation of /l/ in their minds where the allophonic variants are determined by other processes such as orthographic constraints.

While many researchers conducted studies using auditory stimuli, many have also resorted to visual stimuli in their experimental methodologies. The current project assumes the abstract phonological representation of the phonemes---i.e only one representation of /l/ in the  Spanish mind. Given the support for phonological activation in previous visual word recognition studies and the advantages of a visual experimental design, the current project chose to utilize a visual rather than an auditory design.

\section{Syllabic Intuition}
\label{sec-intro-syllable-intuition}
A syllable is a pronounceable linguistic unit of a given language and can be thought of as a building block that speakers use to produce words. Syllables are generally discussed in terms of three parts---the onset, the nucleus and the coda. The onset is any of the consonant sound or sounds that occur before the nucleus while the coda is any consonant sound(s) that follows the nucleus. Syllables, generally contain a highly sonorant sound as its nucleus, which typically realized as a vowel. Another way that syllables are discussed is in terms of the onset and rime, where the rime is the sum of parts from the syllable's nucleus and coda. 

Many studies over the years have addressed syllabification, which has resulted in various methodologies to gain insight into the accepted syllabification rules of a given language. One common method is the repetition paradigm where participants may be asked to repeat the first syllable, second syllable, insert a pause or tap out the syllables in the word they have just encountered \parencite{Content2001-uh,Goslin2000-ul,Goslin2007-xf}. Another common method was a syllable reversal task where participants would have to repeat the syllables of a word they heard, but in the reverse order \parencite{Treiman1988-zl}. For example, the word, \emph{crawdad} would be repeated to the experimenter as \emph{dadcraw}. Sometimes a forced choice task was used where participants were given a set of options for the syllabification of the word to choose from \parencite{Treiman1990-fw}. Some researchers have used these paradigms to start gaining a better understanding of the roles of orthography and phonology in terms of syllabification by utilizing literate and illiterate participants \parencite{Goslin2007-xf,Treiman2002-im}. For more in-depth discussion of these tasks and principles as they relate to the current study, please refer to Chapter \ref{ch-intuition}.

All languages have a syllabic inventory, which consists of all the syllables that native speakers would consider acceptable in their language. Crosslinguistically, syllable inventories differ in many ways in terms of complexity and combinations of sounds that are permittable in different parts of the syllable. For example, /sp/ is acceptable in the syllable onset position in English, but not in Spanish. Orthographic representations support this argument when the word \emph{España} 'Spain' in the two languages is examined. In Spanish, it is a three syllable word \emph{Es.pa.ña} while \emph{Spain} is monosyllabic in English. Understanding this difference makes a common mistake made by L1 Spanish--L2 English speakers pronunciation of Spain as \emph{eS-pain} much easier to comprehend. The speaker is simply transferring their native Spanish syllable patterns to English in order to resolve the illegal /sp/ onset they have encountered. The same logic applies to L1 English--L2 Spanish speakers when they mispronounce the word \emph{es.truc.tu.ra} as \emph{e.struc.tu.ra} applying their native English syllabic patterns to Spanish. In this case, the syllable boundary is moved by the mistake because while an onset of /str/ is illegal in Spanish, it is a legal onset in English. As a result of these differences between languages in allowed syllable structures, it becomes quite evident that it is a variable that needs to be considered in interpreting many studies involving language processing.


\section{Language Segmentation}
\label{sec-intro-segmentation}
People break down spoken and written language on a daily basis. This process of breaking language down into smaller, more processable chunks of language is known as segmentation. For example, when someone is listening to someone speaking, they do not have to wait until the utterance is finished in order to understand individual words within the utterance. In other words, language segmentation is a continuous online task that is taking place at the subconscious level and leads the person to an understanding of the language being spoken. This also happens when people read language as well because we do not have to read an entire sentence in order to understand the words that make up that sentence. On a lower level of segmentation, the word level, these same types of processes occur when someone attempts to break down a word into smaller parts. This word level segmentation is overtly noticeable when a person encounters a new vocabulary word. When they try to pronounce the new word they have encountered in speech or text, they will most likely break down or segment the word into smaller chunks. In many cases the word will be broken down into syllables instead of attempting to pronounce the entire word at once. In some cases, especially in a second language, the syllable itself may be foreign and the person will segment the syllable into phonemes---the individual sound segments that make up the syllable. Teachers in a classroom will often employ these techniques in order to help beginning readers or second language learners pronounce the syllable and subsequently the word correctly. In the end, it seems that most proficient language users do not have a problem accomplishing these segmentation tasks and that it requires little effort even though segmenting language is actually quite complex. 

The investigation of how people segment language is not a new line of research and has been very well documented. Previous studies have investigated the underlying mechanisms in an attempt to better understand how these processes are handled in the brain. Word segmentation is thought to be a separate process from accessing the lexicon---also known as lexical access. Word segmentation does not need to make contact with the lexicon, the brain's storehouse of language items (phonemes, syllables, words, etc.), before segmentation processes can be kicked off. This is in direct contrast to making a lexical decision where you must search through the mental lexicon before deciding whether or not a word is valid in the language. In other words, segmentation processes are thought to be pre-lexical and often occur more quickly than post-lexical decisions because meaning does not have to be attached to the segmented chunks of sounds or letters. This means a speaker can segment language by isolating or detecting certain language units in languages for which they have no knowledge—a common practice in psycholinguistic research to ensure pre-lexical decisions are being made \parencite{Cutler1986-zl}. Understanding that people can successfully implement segmentation processes for an unknown language, researchers have asked naïve and native listeners to segment particular sequences of sounds or graphemes from language stimuli. This has allowed for comparisons of different languages and the testing of hypotheses about language segmentation strategies. Furthermore, it has given additional support the that effects found in previous literature were not due to experimental design or items. 

Several linguistic units were previously investigated for their roles in language processing which include the phoneme, syllable, word, and sentence. Early research sought to discover the \emph{minimal perceptual unit} and the syllable was a logical and testable linguistic unit. In spoken language processing, the syllable made its highlight when it was found that participants could detect syllables faster than they could detect individual phonemes of which the syllable was comprised \parencite{Savin1970-oy}. This finding spurred interest in researchers focus on the syllable as well as other linguistic units such as words, phrases and sentences. The findings of these additional studies revealed that the processes involved in parsing spoken language were complex and a minimal perceptual unit was unlikely to be found. Specifically, one linguistic unit---phoneme, syllable, word, etc.---could not be the sole mechanism in which listeners of a language break the speech stream into smaller, processable chunks. This conclusion was drawn because the culmination of these studies showed that words were detected faster than syllables and sentences faster than words \parencite{Foss1973-ll,Healy1976-js,McNeill1973-bo}.   

\textcite{Mehler1981-wp} captured the need for a change in the direction of this research regarding the syllable, "Traditionally, psycholinguistics research has invested the bulk of its efforts into uncovering the units used in speech processing. Although it is currently fashionable to claim that such work is pointless since it has no very clear outcome, many of the more meaningful advances in the field have come from projects whose framework included the problem of processing units.” They went on to delineate two different levels in which the research around the syllable could move forward: (1) The syllable as a phonological unit of the language which can efficiently explain the grammar of language and (2) The syllable as a unit which aides speech perception and language comprehension. As a result in the early 1980s, several researchers began refocusing their own investigations in accordance to this second vein of syllable research. Even as researchers conducted more pointed research on the syllable's role in language processing strategies, the results continued to suggest research questions needed further subdivision. Ultimately, two distinct subprocesses of language processing in which the syllable may play a role---segmentation and lexical access---were proposed. Segmentation processes were generally approached from the perspective that access to the mental lexicon was not required in order to be successful, while lexical access did. For more in-depth reading on segmentation studies the following articles may be of interest \parencite{Cutler1976-va,Cutler1987-xp,Cutler1988-kg,Finney1996-fw,Pallier1993-ar,Pitt1990-dm} and some additional reading for those interested in lexical access \parencite{Costa2004-cb,Costa2017-ck,Dumay2002-hx,Finkbeiner2006-wl,Sagarra2018-ty} as a starting point, but go beyond the scope of the current project.

\section{The Monitoring Paradigm}
\label{sec-intro-monitoring}
The most relevant linguistic unit to the current study on language segmentation is the syllable which was also the central focus of nearly three decades of research that fell into the second level of investigation of the syllable discussed by \textcite{Mehler1981-wp}---a unit which aides speech perception and language comprehension. Researchers abandoned the search for the minimal perceptual unit after many attempts to identify a single clear linguistic unit of perception and turned their focus towards the syllable’s role in speech perception despite the fact it was not likely to be a minimal perceptual unit for speech processing. In the syllable monitoring paradigm a target syllable such as \emph{pa, pal, ba, bal, ca} or \emph{car} is presented to the participant. Then a participant must identify the target syllable which is embedded in language---spoken or written. The language is presented as a list of words, carrier items, rather than connected and continuous speech. While the monitoring paradigm did not lead researchers to the discovery of a minimal perceptual unit, this methodology did serve them well in testing the syllable’s role in speech processing.

In order to understand the concept of the syllable monitoring task and the experience a participant has while completing it, \textcite{Mehler1981-vi} study of syllable monitoring in French is used to illustrate the process. They asked French subjects in a French syllable monitoring experiment to find CV or CVC, consonant-vowel or consonant-vowel-consonant, syllables in lists of bisyllabic words. All words also had initial syllable structures of CV or CVC where both the target and carrier items were presented auditorily. For example, each experimental trial started with the target presentation where the participant heard, “The target is pa”. Immediately following the target presentation, the participants heard a list of words that ranged from two to five words in length. Every word was spoken with a pause of two seconds between each word. Once the entire list had been heard, the next trial would start with the target presentation. In order to collect the reaction time data the researchers needed, participants were asked to press a response key as soon as they had heard their target sound fragment in the speech they were hearing. 

\textcite{Mehler1981-vi} created five critical word pairs \emph{PA.LA.CE--PAL.MIER} 'luxury hotel--palm tree' or \emph{CAR.TON--CA.ROTTE} 'box--carrot', where both words always shared the initial three phonemes, but they differed in their syllable structures. The syllable structure of the words is denoted by the period, which indicates the location of standard French syllabification. The experimental conditions varied based on the target syllable structure and initial syllable structure of the carrier word. The structures of the target and carrier item could match as in the following examples: "pa” in \emph{PA.LACE}, “pal” in \emph{PAL.MIER}, “ca” in \emph{CA.ROTTE} or “car” in \emph{CAR.TON}. However, they could also mismatch which is illustrated with the following examples: “pal” in \emph{PA.LACE}, “pa” in \emph{PAL.MIER}, “ca” in \emph{CAR.TON} or “car” in \emph{CA.ROTTE}. Their experimental design used 20 different sequences in two different lists, which could contain a critical item as the last word spoken in the sequence.

French speakers found the target syllable faster when the initial syllable structure of the carrier word matched the syllable structure of the target. To illustrate with the critical word pair, \emph{PALACE--PALMIER}, participants monitoring for the target \emph{pa} revealed faster detection times when \emph{PALACE} was the critical word when compared to detection times where \emph{PALMIER} was the critical word. Likewise, the target \emph{pal} was found faster when the critical word was \emph{PALMIER} rather than \emph{PALACE} \parencite{Mehler1981-vi}. This finding was named the “crossover effect”. The crossover effect can be defined as significantly faster detection times where target syllable structure matches the initial syllable structure of the carrier word when compared to the detection times where the target syllable structure and word initial syllable structure of carrier words do not match.

Following the French results, \textcite{Cutler1986-zl} conducted a similar experiment with native English speakers. Interestingly, the crossover effect was not replicated by native English speakers who monitored real English words. In other words, English speakers did not show differences in the speed in which they identified the target syllable according to the syllable structure of the carrier item. Finding \emph{pa} in \emph{PA.LACE} was not easier than finding \emph{pal} in \emph{PA.LACE} nor was finding \emph{pal} in \emph{PAL.PI.TATE} easier than finding \emph{pa} in \emph{PAL.PI.TATE}. It is worth noting that one word in each English pairing had an unclear syllable boundary---an ambisyllabic [l]---which is a linguistic phenomenon not present in French. Researchers speculated that something in the auditory stimuli may have been the culprit of the inconsistent finding. They followed up on this hypothesis by having native English speakers monitor the same French nouns used by \textcite{Mehler1981-vi} where syllable boundary ambiguity was not present in the carrier items. Given that these were naïve listeners of French, only the segmentation processes rather than lexical access processes were being examined here because these listeners would have had no lexical entries for any of the French words that they heard. The English listeners again did not show the crossover effect. This suggested that the syllable based segmentation strategy used by the the monolingual French listeners was not a strategy used in speech segmentation by English monolinguals even when the language stimuli supported the use of a syllable based segmentation strategy \parencite{Cutler1986-zl}. Importantly, this finding suggested that language segmentation strategies are not universal, but are language specific. In order to give additional strength to their argument, the researchers used the English experimental items that did not produce the crossover effect with native English speakers, and ran the same experiment with native speakers of French who had not learned English. The French listeners continued to exhibit the crossover effect when listening to an unknown language. More importantly, the French speakers continued to implement a syllable based segmentation strategy when listening to English---a language shown by native speaker data to be unsupportive of a syllable based segmentation strategy.

Given the nature of the differences found between English and French monolingual speakers’ strategy for speech segmentation, the next logical step while remaining in the same of vein of research was to investigate the segmentation strategy used by bilinguals. In a series of experiments, for both English and French language modes of French–English simultaneous bilingual speakers were tested \parencite{Cutler1992-qq}. The French mode of the experiment used the same stimuli as \textcite{Mehler1981-vi} which had showed a strong syllabic effect with French monolinguals. However, it showed no such effect with the French--English bilingual population. Post-hoc analysis split the bilinguals into two groups according to language dominance. \textcite{Cutler1992-qq} used answers reported by the participants in response to the following question, “Suppose you developed a serious disease, and your life could only be saved by a brain operation which would unfortunately have the side effect of removing one of your languages. Which language would you choose to keep?”, in order to determine language dominance. In other words, those who chose French were consider French-dominant and those who chose English were considered English-dominant. This manner of determining language dominance was then used to analyze data from all remaining experiments in the study. Under this post-hoc analysis where language dominance was considered for the experiments conducted in French, French-dominant listeners patterned like French monolinguals. Likewise, English dominant listeners patterned like English monolinguals from previous studies for the experiments conducted in French. In the French versions of the experiments, French-dominant participants exhibited the syllable-based segmentation strategy while the English-dominant participants did not show evidence of a syllable-based segmentation. In the English versions of the experiments, French-dominant speakers patterned unlike the French monolinguals while the English-dominant speakers continued to pattern like the English monolinguals. Like previous studies with English monolinguals and the English-dominant bilinguals of the \textcite{Cutler1986-zl}, the French-dominant bilinguals were not able to find “pa” in PALACE easier than “pal” in PALACE nor were they able to find “pal” in PALPITATE faster than “pa” in PALPITATE. Where French was considered the dominant language of the speaker, it appeared that they had identified the ineffectiveness of the syllable based segmentation strategy and were able to inhibit its application while listening to English. When English was considered the dominant language of the speaker, it appeared that these speakers could not utilize a syllable based segmentation strategy despite the fact that one of their two languages could use a syllabic segmentation strategy.  This suggested that bilinguals—even in their most balanced form—are not two monolinguals within a bilingual mind.

English and French are quite different in their phonological structure: (1) French is syllable-timed while English is stressed-timed, (2) French has fixed stress while English has variable stress, (3) French has no vowel reduction while English has rampant vowel reduction and (4) French has clear syllable boundaries while English has ambiguous syllable boundaries. As a result of the phonological structures of French and English, in the previous experiments stressed syllables were always the carrier syllables for English speakers while unstressed syllables were always the carrier syllables for the French speakers. This stress factor was considered as a potential confound in that stressed syllables are known to carry more phonetic details and last longer than unstressed syllables. To overcome this difference, a different group of bilingual speakers were recruited—Catalan–Spanish bilinguals—because stress is variable in both languages and can therefore be controlled \parencite{Sebastian-Galles1992-xd}. Unlike French and English that varied on multiple factors, Catalan and Spanish only differ in vowel reduction—Catalan has vowel reduction while Spanish does not. With stress being controlled across both languages, vowel reduction can be isolated as it is allowed in Catalan, like in English, but it is not in French or Spanish. They found that Catalan-dominant speakers monitoring Catalan speech produced the crossover effect only when the initial syllable of the carrier item was unstressed. Spanish was also considered in the same study where the researchers found no crossover effect by Spanish-dominant speakers monitoring in Spanish. Given the similarities between Spanish and French, both have clear and unambiguous syllable boundaries without vowel reduction, it is surprising that they did not find a crossover effect with stressed or unstressed initial syllables of the carrier items as they did with Catalan speakers. \textcite{Sebastian-Galles1992-xd} attempted to force a post-lexical decision by the Spanish-dominant speakers with the incorporation of an additional semantic relatedness task. This succeeded in slowing the reaction time by an average of 250 milliseconds and found a syllabic effect in both initially stressed and unstressed Spanish words. The syllabic effect similar to the those found in \textcite{Sebastian-Galles1992-xd} was later replicated in Italian by \textcite{Tabossi2000-xn}.

In contrast to the findings of \textcite{Sebastian-Galles1992-xd} experiment 2, \textcite{Bradley1993-qq} found a crossover effect when Spanish speakers monitored Spanish carrier items. They also found no crossover effect for English speakers monitoring English carrier items. Similar to \textcite{Cutler1986-zl}, \textcite{Bradley1993-qq}  tested naïve listeners with the same material. They found no crossover effect for English monolinguals monitoring Spanish carrier items, which was comparable to the French findings. However, unlike the French findings, the Spanish monolinguals monitoring in English also showed no syllabic segmentation effect. This was a surprising result given that Spanish and French are very similar, but they differed in their processing of the same unknown language---English. \textcite{Bradley1993-qq} then turned to Spanish–English bilinguals where they again found no crossover effects when monitoring Spanish carrier items. This suggests that these native speakers of Spanish and English L2 speakers have abandoned their native segmentation strategy even when listening to one of their native languages (Spanish). This result again differs from the \textcite{Cutler1986-zl} French–English bilinguals because the French kept the native syllable-based segmentation strategy when listening to French and abandoned it only when listening to English where it was no longer effective.

There is not much in the way of studying speech segmentation using a visual paradigm at this point. Visual word recognition has mainly been utilized in studies that are concerned with lexical access. However, there is growing evidence that this may be a meaningful and efficient manner to investigate questions related to speech segmentation. There is also growing evidence that great caution needs to be taken into consideration when designing experiments and selecting items to be used. In an auditory design, orthography could only be available to participants if they were able to recall the visual image of the written word mentally, but most experimental designs would not allow sufficient processing time for participants to do this consistently throughout the study while completing it successfully. However, in the visual design, orthography is very salient to the participant and a poorly designed study may incorrectly draw conclusions based on different processes used by participants---orthography versus phonology based segmentation strategies.

\section{Present Study}
\label{sec-intro-present-study}
This dissertation utilizes several different methodologies as a means to investigate research questions that fall under \textcite{Mehler1981-wp} second level of research. The experiments are designed to answer research questions that are founded in the idea that the syllable is a linguistic unit that may aide in language comprehension and processing. There are two overarching questions that underlie this dissertation project as a whole:

\begin{singlespacing}
\begin{enumerate}
\item What differences if any, exist in Spanish syllable representations or intuitions between native Spanish speakers and native English speakers?
\item How do the syllabic representations of Spanish syllables affect the use of syllable based segmentation strategies for processing the Spanish language? 
\end{enumerate}
\end{singlespacing}

The three experimental chapters of this dissertation provide additional information about syllable structure and the representation of the syllable in Spanish to the knowledge base of the field. At the time of writing this dissertation, the majority of research studies have been conducted with monolingual speakers. When studies have investigated the role of the syllable in language processing by bilinguals, they have generally compared the bilinguals against monolingual speakers of the two respective languages. However, previous studies suggest that bilinguals are not simply the summation of two independent monolingual speakers. For example, \textcite{Cutler1992-qq} found that French--English bilinguals listening to French responded in the same manner as French monolinguals, but when listening to English, these speakers did not respond similarly to English monolinguals. The current project looks to a different language pairing---specifically Spanish and English.

Following this introductory chapter, the structure for the remainder of this dissertation consists of five additional chapters. Chapter \ref{ch-sampling} gives a detailed account of all sampling methods and participant populations. Chapter \ref{ch-intuition} explores the representation of the syllable in the minds of Spanish–English bilinguals with a two option forced-choice syllabic intuition task. Chapters \ref{ch-seg-lab} and \ref{ch-seg-online} utilize a visual word segmentation task to compare the efficiency of the processes employed by monolingual and bilingual speakers of Spanish. Finally, chapter \ref{ch-conclusion} shows how all three experimental chapters were necessary to draw the conclusions that were borne out through the various testing methodologies used to explore the role of the syllable in Spanish language processing of the current dissertation research.
