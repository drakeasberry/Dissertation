% Online Lemma Segmentation Chapter with LaTeX code only

%----------------------------------------------------------------------------------------
<<global_opts_online, echo=FALSE, cache=FALSE, include=FALSE>>=
library(knitr)
library(here)

knitr::opts_chunk$set(
  echo = FALSE
)
here::here()
set_parent(here('Asberry_Dissertation/Dissertation.Rnw'))
@
%----------------------------------------------------------------------------------------

%----------------------------------------------------------------------------------------
% Load statistics in memory from separate file
%contentOnlinesegMono, child='Statistics/Monolingual_lemma/target_syl_mono_viz.rnw'), include=FALSE>>=
%@

%contentOnlinesegL2, child='Statistics/L2_lemma/target_syl_l2_viz.rnw'), include=FALSE>>=
%@
%----------------------------------------------------------------------------------------

\chapter{Online Visual Word Segmentation} % Main chapter title
\label{ch-seg-online} % for referencing this chapter elsewhere, use \ref{ch-seg-online}

%\section{Abstract}
%Give Segmentation abstract here
%Keywords: (list all words necessary)

\section{Introduction}
This chapter and the experiments conducted to produce the data reported here were completed to further investigate the results found in chapter \ref{ch-seg-lab} for the visual letter sequence monitoring task. The results of went against the hypothesis that Spanish--English bilinguals would employ a syllable based segmentation strategy in Spanish. This finding was very surprising in terms of the Spanish dominant bilinguals because Spanish monolinguals had been shown to use this strategy. In English dominant bilinguals, there was also no effect of syllable segmentation. This finding was more expected given the amount of research that suggested that English speakers did not rely of syllable based segmentation strategies. However, the research on bilinguals of English and another language was scarce and chapter \ref{ch-seg-lab} sought to test whether or not this strategy was learnable by second language learners of Spanish.

In order to further investigate, the current chapter utilized Spanish monolinguals and a group of different participants recruited for the English dominant bilinguals. The design of the study was also modified in order to isolate particular aspects thought to be contributing to the null effect found for a syllable based word segementation strategy in chapter \ref{ch-seg-lab}. This chapter conducted a second visual letter sequence monitoring task in order to address the following research questions: 1) Is there support for a syallble based segmentation strategy when processing Spanish? and 2) How does the use of syllable based segmentation strategies for processing the Spanish language differ between native speakers of Spanish and native English speakers? 

The next section is the background of the project. Given that the background is the same as the background found in chapter \ref{ch-seg-lab}, only a small summary has been given of the previous literature. Readers interested in reading more detail on these topics should refer to chapter \ref{ch-intro} and chapter \ref{ch-seg-lab} section \ref{lab-seg-background}.


\section{Background}
Research studies looking for evidence of the use of a syllabic based word segmentation strategy has been studied extensively. A syllabic segmentation strategy has mostly been reported in terms of an interaction between the syllable structure of letter or sound sequence, the target, and the structure of the initial syllable in a word in which the participant was supposed to identify the target. One thing that is abundantly clear is that this strategy is used differently by speakers according to their language backgrounds.

There have been differences found within monolingual speakers of the language as well as between monolingual and bilinguals where a language is shared in common. In the monolingual French speakers were reported to use a syllable segmentation strategy consistently even when language input that have shown the lack of this strategy's efficacy by native speakers. On the complete opposite end of the spectrum, monolingual English speakers never employed a syllabic segmentation strategy even when the language input would promote it \parencite{Cutler1986-zl,Mehler1981-vi}. \textcite{Bradley1993-qq} results extended the previous French results found in \textcite{Mehler1981-vi} to Spanish monolinguals. Catalan speakers utilized a syllable segmentation strategy only when word initial syllables were unstressed. Spanish speakers seemed to be able to process items so fast that they could skip the use of the syllable segmentation strategy. However, if Spanish speaker are forced to slow down, then evidence of the syllable segmentation strategy emerges for words with an unstressed first syllable. \parencite{Sebastian-Galles1992-xd}. The results for Spanish study in \textcite{Bradley1993-qq} also found the syllabic effect when response times averaged between 556 ms and 609 ms. 

In terms of bilinguals, \textcite{Bradley1993-qq} investigated Spanish--English bilinguals using the same material where the syllabic segmentation effect had been found for Spanish monolinguals in an attempt to replicate the French--English bilinguals studied by \textcite{Cutler1992-qq}. While \textcite{Cutler1992-qq} found a syllabic segmentation effect for French dominant English bilinguals when monitoring in French, \textcite{Bradley1993-qq} was unsuccessful at finding a similar result with Spanish dominant English bilinguals when monitoring in Spanish. In chapter \ref{ch-seg-lab} of this dissertation, Spanish--English bilingauls, split between Spanish and English dominance, completed a a visual letter sequence monitoring task. Like \textcite{Bradley1993-qq}, these bilinguals from chapter \ref{ch-seg-lab} showed no evidence of a syllabic segmentation strategy.


\section{Present Study}
The current study conducted a Spanish visual letter sequence monitoring task with native Spanish and English speakers. This experiment is a follow-up to the letter sequence montioring experiment conducted in chapter \ref{ch-seg-lab}. In my previous findings, Spanish dominant bilinguals of English did not show the effects of a syllable based segmentation strategy, which were in line with previous Spanish--English bilinguals---experiment 5 of \textcite{Bradley1993-qq}. One possible explanation of this result is that the experimental items were somehow responsible for the null effect. In order to address the issue of experimental items, the current study ran a replication study of experiment 1 of \textcite{Bradley1993-qq}, which did find a syllabic effect in monolingual speakers of Spanish. Utilizing a subset of the same materials used in chapter \ref{ch-seg-lab}, the visual Spanish letter sequence monitoring task was given to monolingual speakers of Spanish. This allowed for the isolation of learning English to be controlled for in the native Spanish speaker control group. If the Spanish monolinguals also do not show evidence of the syllable based segmentation strategy, then it is likely due to some property of the experimental items or the mode of presentation. On the other hand, if the monolinguals of Spanish results support the use of the syllable based strategy, the effects of experimental item properties and presentation modality can be ruled out. In this case, additional support for the use of a visual paradigm to study these types of phonological effects will be provided. It would also provide stronger evidence that the learning of English is somehow affecting the ability of native Spanish speakers to continue using their native syllable based segmentation strategy even in their native language.

In addition to running a replication of \textcite{Bradley1993-qq}, the main goal of this dissertation was to extend findings to second language learners of Spanish who were native speakers of English. This target group, has only been tested in chapter \ref{ch-seg-lab} up to this point. In my previous findings, the ability to learn and employ a syllabic segmentation strategy  after acquiring a language that supports it was not supported. However, chapter \ref{ch-seg-lab} experiments suffered from a smaller than expected sample size because the in-person data collection was stopped due to the COVID-19 pandemic. Therefore, the current study conducted a power analysis prior to online data collection began to ensure a sufficient sample size was collected to support confident interpretations of the analyses that were to be conducted. As before, There were two possible outcomes for the native English--L2 Spanish experimental group. Previous research has shown that a syllable based segmentation strategy is not productive for L1 English speakers or when English is one of their known langauges \parencite{Bradley1993-qq,Cutler1986-zl,Cutler1992-qq,Mehler1981-vi}. Support for the ability to learn the syllable based segmentation strategy would be supported if the group of English--Spanish bilinguals showed a sensitivity to syllabic structure when processing Spanish. Evidence of this sensitivity would be revealed as a factor of the target structure for which they were monitoring in relation to whether or not it matched the word initial syllable structure of the word containing the target. The other possible outcome is that they do not show this sensitivity to Spanish syllabic structure. This finding would support numerous previous findings of an English speaker's ability to implement a syllabic segmentation strategy depsite the fact that the language they are processing supports it use.


\section{Methods}
In order to address these questions and possible outcomes, an online visual letter sequence monitoring task was conducted to analyze the word segmentation strategies used by the participants. During the online visual monitoring experiment, a two or three letter string that represented a CV or CVC syllable appeared on the participants computer screen. Once the target presentation occurred the words or nonwords were individually presented on to the participants. The instructions asked participants to respond as quickly as possible once they identified the matching letter string. Both the letter stings, i.e. targets, and the words were presented visually. Since this dissertation is the first study to my knowledge that has tested a syllable segmentation strategy in a completely visual manner, the assumption of reading language actually activates the phonology in the mind of the participant. As with chapter \ref{ch-seg-lab}, the online experimental design assumed that participants were actually activating the phonological representation of the sounds of the target, i.e. syllable, and the word they read on the screen. For a full discussion on this topic, refer to Chapter \ref{ch-intro} Section \ref{sec-phon-activation}. 

Running an online study also introduced another factor to be considered when preparing to collect data. In chapter \ref{ch-seg-lab}, all participants completed the experiments on the same computer where hardware and software configurations were consistent across all participants. All participant responses were collected with a usb button response box. However, the experiment in the current chapter was built using PsychoPy3 version 2020.1.2 and hosted online using Pavlovia \ttodo{citations pyschopy and pavlovia}. This resulted in the lack of control for hardware configurations, browser selection and input devices. Participants were recruited from Prolific, which did allow for restricting user devices to a laptop or desktop computer. Participants were not allowed to participate from mobile devices or tablets \ttodo{cite prolific}. However, several studies were published around the same time as the data being collected for the experiment in this chapter that showed online reaction time studies were viable options \ttodo{cite all three articles}. Visual studies conducted online were actually found to be comparable to laboratory based experiments in terms of reaction time collection and accuracy while auditory studies continued to lag behind in-person studies \ttodo{cite the one study that showed this}. Thus, continuing to use a visual paradigm to study word segmentation strategies in Spanish was a logical choice.


\subsection{Participants}
\ttodo{Give accurate descriptions of participant groups, how they were classified, number of participants, etc. Data references have been updated, but not surrounding text} All participants reported in this chapter were recruited for experiments that took place in an in-person laboratory setting. In this study, native Spanish speakers who were second language learners of English were used as the control group---LE group. The target group consisted of native English speakers who were second language learners of Spanish---LS group. All participants recruited continued to live in their L1 environment, or birth country, at the time of data collection. There were \Sexpr{online_completed["Monolingual Spanish", "n"]} participants in LE group recruited from the University of Sonora in Hermosillo, Mexico and \Sexpr{online_completed["L2 Learner", "n"]} participants in LS group recruited from the University of Arizona in Tucson, AZ. In total, \Sexpr{online_completed["L2 Learner", "n"] + online_completed["Monolingual Spanish", "n"]} participants completed the experiment. For a full description of each group see Chapter \ref{ch-sampling} Section \ref{sec-participants}.

%This section was removed because it was done with filters in Prolific. Those were double checked and people with inconsistent data were asked to update profiles, their data was deleted and did not receive compensation. 
%In total, there were \Sexpr{lab_stat_compare["English", "n"] + lab_stat_compare["Spanish", "n"]} participants that completed the study. Using responses to the BLP, \Sexpr{lab_part_removal_sum["fluency-English", "n"] + lab_part_removal_sum["location-Spanish", "n"] + lab_part_removal_sum["dominance-English", "n"] + lab_part_removal_sum["dominance-Spanish", "n"]} were removed because they did not accurately represent the groups for which they had been recruited. \Sexpr{lab_part_removal_sum["fluency-English", "n"]} native English speaker was removed because they reported fluency in languages other than Spanish and English. \Sexpr{lab_part_removal_sum["location-Spanish", "n"]} native Spanish speakers were removed because they reported being born and/or raised outside of Mexico. \Sexpr{lab_part_removal_sum["dominance-English", "n"] + lab_part_removal_sum["dominance-Spanish", "n"]} participants were removed because they were outliers in terms of language dominance scores calculated by the BLP. Lastly, using the scores from both the LexTALE and LexTALE-Esp, \Sexpr{lab_part_removal_sum["vocabulary-Spanish", "n"]} native Spanish speakers were removed because their scores indicated a larger L2 English vocabulary size than their L1 Spanish vocabulary size.

Additional data collected through the LexTALE, LexTALE-Esp and the Bilingual Language Profile (BLP) \ttodo{done with filters in Prolific. Those were double checked and people with inconsistent data were asked to update profiles, their data was deleted and did not receive compensation.} tasks completed during the same session as the letter sequence monitoring task were used to ensure that participants actually represented the intended group for which they were recruited. Using responses to the BLP, \Sexpr{lab_part_removal_sum["fluency-English", "n"] + lab_part_removal_sum["location-Spanish", "n"] + lab_part_removal_sum["dominance-English", "n"] + lab_part_removal_sum["dominance-Spanish", "n"]} were removed because they did not accurately represent the groups for which they had been recruited. \Sexpr{lab_part_removal_sum["fluency-English", "n"]} native English speaker was removed because they reported fluency in languages other than Spanish and English. \Sexpr{lab_part_removal_sum["location-Spanish", "n"]} native Spanish speakers were removed because they reported being born and/or raised outside of Mexico. \Sexpr{lab_part_removal_sum["dominance-English", "n"] + lab_part_removal_sum["dominance-Spanish", "n"]} participants were removed because they were outliers in terms of language dominance scores calculated by the BLP. Lastly, using the scores from both the LexTALE and LexTALE-Esp, \Sexpr{lab_part_removal_sum["vocabulary-Spanish", "n"]} native Spanish speakers were removed because their scores indicated a larger L2 English vocabulary size than their L1 Spanish vocabulary size.

Once the demographic removals had been completed, an accuracy response rate for the experiment was conducted on the remaining \Sexpr{nrow(online_completed)} participants. A predetermined accuracy rate of 90 percent was used as the cut-off and any participant responding incorrectly to filler or critical trials more than 10 percent of the time was removed from the analysis. All participants correctly responded to filler trials above the cut-off point; however, \Sexpr{online_stat_dropped["L2 Learner", "n"] + online_stat_dropped["Monolingual Spanish", "n"]} participants were removed for committing errors at rate greater than 10 percent to critical trials. After the removal of participants, \Sexpr{online_stat_dropped["L2 Learner", "n"]} participants from the LS group and \Sexpr{online_stat_dropped["Monolingual Spanish", "n"]} participants from the LE group were removed. This left a total of \Sexpr{online_eligible["L2 Learner", "n"] + online_eligible["Monolingual Spanish", "n"]} participants---\Sexpr{online_eligible["L2 Learner", "n"]} native English speakers and \Sexpr{online_eligible["Monolingual Spanish", "n"]} native Spanish speakers, that had data submitted to the analysis and only these participants are included in reported statistics and figures below. Table \ref{tab-lab-demo-part} gives age related data about participants, Table \ref{tab-lab-vocab-part} give data related to participant vocabulary sizes and Table \ref{tab-lab-lang-blp-part} shows language scores collected through the BLP.

\begin{table}
\centering
\begin{tabular}{l c c c c c c c c c}
\toprule
& & & & & &\multicolumn{4}{c}{Age of Acquisition}\\
\cmidrule(lr){7-10}
& & \multicolumn{4}{c}{Age} & \multicolumn{2}{c}{Spanish} & 
\multicolumn{2}{c}{English}\\
\cmidrule(lr){3-6}\cmidrule(lr){7-8}\cmidrule(lr){9-10}
& n & Min & Max & Mean & SD & Mean & SD & Mean & SD\\
\midrule
English
& \Sexpr{lab_grp_desc["English","n"]}
& \Sexpr{lab_grp_desc["English","age_Min"]} 
& \Sexpr{lab_grp_desc["English","age_Max"]} 
& \Sexpr{lab_grp_desc["English","age_Mean"]}
& \Sexpr{lab_grp_desc["English","age_SD"]}
& \Sexpr{lab_grp_desc["English","span_acq_age_Mean"]}
& \Sexpr{lab_grp_desc["English","span_acq_age_SD"]}
& \Sexpr{lab_grp_desc["English","eng_acq_age_Mean"]}
& \Sexpr{lab_grp_desc["English","eng_acq_age_SD"]}\\
Spanish
& \Sexpr{lab_grp_desc["Spanish","n"]}
& \Sexpr{lab_grp_desc["Spanish","age_Min"]} 
& \Sexpr{lab_grp_desc["Spanish","age_Max"]} 
& \Sexpr{lab_grp_desc["Spanish","age_Mean"]} 
& \Sexpr{lab_grp_desc["Spanish","age_SD"]}
& \Sexpr{lab_grp_desc["Spanish","span_acq_age_Mean"]}
& \Sexpr{lab_grp_desc["Spanish","span_acq_age_SD"]}
& \Sexpr{lab_grp_desc["Spanish","eng_acq_age_Mean"]}
& \Sexpr{lab_grp_desc["Spanish","eng_acq_age_SD"]}\\
\bottomrule
\multicolumn{6}{l}{Total participants: n = \Sexpr{lab_grp_desc["Spanish","n"] + lab_grp_desc["English","n"]}}\\
\end{tabular}
\caption{Attributes of all lab based segmentation participants.}
\label{tab-lab-demo-part-online}

\vspace{.4in}

\begin{tabular}{l c c c c c c c c c}
\toprule
& & \multicolumn{6}{c}{Vocabulary Size \% Correct}\\
\cmidrule(lr){3-8}
& & \multicolumn{2}{c}{English} & \multicolumn{2}{c}{Spanish} & 
\multicolumn{2}{c}{Difference} & \multicolumn{2}{c}{Izura Score}\\
\cmidrule(lr){3-4}\cmidrule(lr){5-6}\cmidrule(lr){7-8}\cmidrule(lr){9-10}
& n & Mean & SD & Mean & SD & Mean & SD & Mean & SD\\
\midrule
English
& \Sexpr{lab_grp_desc["English","n"]}
& \Sexpr{lab_grp_desc["English","lextale_eng_correct_Mean"]} 
& \Sexpr{lab_grp_desc["English","lextale_eng_correct_SD"]} 
& \Sexpr{lab_grp_desc["English","lextale_esp_correct_Mean"]}
& \Sexpr{lab_grp_desc["English","lextale_esp_correct_SD"]}
& \Sexpr{lab_grp_desc["English","vocab_diff_Mean"]}
& \Sexpr{lab_grp_desc["English","vocab_diff_SD"]}
& \Sexpr{lab_grp_desc["English","izura_score_Mean"]}
& \Sexpr{lab_grp_desc["English","izura_score_SD"]}\\
Spanish
& \Sexpr{lab_grp_desc["Spanish","n"]}
& \Sexpr{lab_grp_desc["Spanish","lextale_eng_correct_Mean"]} 
& \Sexpr{lab_grp_desc["Spanish","lextale_eng_correct_SD"]} 
& \Sexpr{lab_grp_desc["Spanish","lextale_esp_correct_Mean"]} 
& \Sexpr{lab_grp_desc["Spanish","lextale_esp_correct_SD"]}
& \Sexpr{lab_grp_desc["Spanish","vocab_diff_Mean"]}
& \Sexpr{lab_grp_desc["Spanish","vocab_diff_SD"]}
& \Sexpr{lab_grp_desc["Spanish","izura_score_Mean"]}
& \Sexpr{lab_grp_desc["Spanish","izura_score_SD"]}\\
\bottomrule
\multicolumn{6}{l}{Total participants: n = \Sexpr{lab_grp_desc["Spanish","n"] + lab_grp_desc["English","n"]}}\\
\end{tabular}
\caption{Vocabulary scores for participants in English and Spanish calculated as a percent correct score along with the differences in means. Spanish vocabulary size as calculated by \textcite{Izura2014-yw}.}
\label{tab-lab-vocab-part-online}

\vspace{.4in}

\begin{tabular}{l c c c c c c c}
\toprule
& & \multicolumn{4}{c}{Global Language Scores}\\
\cmidrule(lr){3-6}
& & \multicolumn{2}{c}{English} & \multicolumn{2}{c}{Spanish} & 
\multicolumn{2}{c}{Language Dominance}\\
\cmidrule(lr){3-4}\cmidrule(lr){5-6}\cmidrule(lr){7-8}
& n & Mean & SD & Mean & SD & Mean & SD\\
\midrule
English
& \Sexpr{lab_grp_desc["English","n"]}
& \Sexpr{lab_grp_desc["English","global_eng_score_Mean"]} 
& \Sexpr{lab_grp_desc["English","global_eng_score_SD"]} 
& \Sexpr{lab_grp_desc["English","global_esp_score_Mean"]}
& \Sexpr{lab_grp_desc["English","global_esp_score_SD"]}
& \Sexpr{lab_grp_desc["English","lang_dominance_Mean"]}
& \Sexpr{lab_grp_desc["English","lang_dominance_SD"]}\\
Spanish
& \Sexpr{lab_grp_desc["Spanish","n"]}
& \Sexpr{lab_grp_desc["Spanish","global_eng_score_Mean"]} 
& \Sexpr{lab_grp_desc["Spanish","global_eng_score_SD"]} 
& \Sexpr{lab_grp_desc["Spanish","global_esp_score_Mean"]} 
& \Sexpr{lab_grp_desc["Spanish","global_esp_score_SD"]}
& \Sexpr{lab_grp_desc["Spanish","lang_dominance_Mean"]}
& \Sexpr{lab_grp_desc["Spanish","lang_dominance_SD"]}\\
\bottomrule
\multicolumn{6}{l}{Total participants: n = \Sexpr{lab_grp_desc["Spanish","n"] + lab_grp_desc["English","n"]}}\\
\end{tabular}
\caption{Individual language based values and language dominance scores for participants. All values were calculated according to creators of the Basic Language Profile.}
\label{tab-lab-lang-blp-part-online}
\end{table}


\subsection{Materials \& Design}
\subsection{boiler plate copy 5}
There were 24 real word pairs and 24 nonword pairs selected as critical items where the initial syllable structure varied between a CV and a CVC structure while the first three phonemes were shared between the two. Example real word pairs included: \emph{ba.la.da--bal.do.sa} 'ballad--floor tile', \emph{cu.le.bra--cul.pa.ble} 'snake--culprit', \emph{mo.re.ra--mor.ci.llo} 'mulberry--beef shank' and \emph{jo.ro.ba--jor.na.da} 'hump--day'. Example nonword pairs included: \emph{ba.le.ga--bal.bu.sa, cu.li.tra--cul.se.ble, mo.ri.pa--mor.bo.llo,} and \emph{jo.ru.ma--jor.te.da}. In addition to the 24 critical real word pairs, another 294 real Spanish words were selected to use as fillers and are also balanced according to initial syllable structure---147 start with a CV syllable and 147 start with a CVC syllable. Likewise, in addition to the 24 critical nonword pairs, 294 nonwords were selected and counterbalanced for initial syllable structure. All critical items and fillers were trisyllabic and stressed on the penultimate syllable. In order to create the nonwords, the 48 real Spanish words were submitted to a nonword generator called Wuggy \parencite{Keuleers2010-vq}. Wuggy is a program that allows for nonword creation while adhering to standard orthographic rules of a language. See Appendix \ref{app-wuggy}) for all instructions and parameters used in creating the nonwords used in this experiment.

The experiment was run completely in Spanish and there were four different versions. The four versions of the experiment were necessary for counter-balancing purposes, which was accomplished by balancing across participants. In order to illustrate with an the example word-pair \emph{balada–baldosa}, participants in condition 1 searched for \emph{BA} in \emph{balada}, participants in condition 2 searched for \emph{BAL} in \emph{balada}, participants in condition 3 searched for \emph{BA} in \emph{baldosa} and participants in condition 4 searched for \emph{BAL} in \emph{baldosa}. Participants were assigned to only one condition resulting in no participant seeing both critical words from any single critical word pair during the experiment. For example, participant 1 was assigned to version A of the experiment where they monitored for the syllable \emph{BA} and should have responded when they saw the word \emph{balada} on the screen for the critical word pair \emph{balada–baldosa}. Therefore, participant 1 did not see conditions 2, 3 or 4 in their experiment for \emph{balada–baldosa}. Each participant was assigned to one of the four versions of the experiment based on the order in which they arrived to the experimental location. Rather than running the first set of participants in the same condition, a looping criteria was used to evenly spread out participants across the four versions. For example, participant 1 was assigned to version A, participant 2 was assigned to version B, participant 3 to version C, participant 4 to version D, participant 5 to version A and so on. 

Each version of the experiment presented 24 CV and 24 CVC critical trials where half of each type of syllable structure contained a match between the syllable structure of the target and initial syllable of the word containing the target while the other half are mismatched. Each block presented to the participant contained 1 critical trial and 9 filler trials which were also balanced for CV and CVC syllable structures. Half the blocks presented were real words and half the blocks were nonwords. In no instance did a single block of 10 trials contain both real words and nonwords. All versions of the experiment utilized the same block presentation order, which was randomized using the \emph{=Rand()} function in Excel to obtain the order used in the experiment prior to beginning data collection. While the block order was consistent across all participants, the trial order was randomized for each participant individually. There were 8 practice blocks designed in the same manner that were presented to the participants before the actual experimental blocks were presented.


\subsection{Procedure}
\ttodo{explain the actual task at hand, then explain the whole exxperience so that the most important informaiton is presented first and the whole experience will be understandable by the reader because they will have been introduced to all the concepts by that point.}
All participants will first take the LexTale-ESP (Spanish language proficiency test) on their personal computer using their preferred internet browser. Then participants will begin the experimental task, segmentation (assigned to either real word experimental condition OR nonword experimental condition), where they will see visual stimuli on the computer screen and will press a single key on their keyboard to respond to each test stimuli. At this point the experiment will end for monolingual speakers of Spanish, but for bilingual participants a third task will be given—LexTale-EN (English language proficiency test).

\subsection{boiler plate copy 6}
For the syllable monitoring task, participants were instructed that they would be presented with a sequence of letters for which they were to find in a list of words that would appear on the screen one by one. They were instructed to respond only if they had identified the sequence of letters in the word on the screen by pressing the green button on the response box and to do nothing if they did not find the target. The participants were also instructed to respond as fast and accurately as possible. This message was reiterated with feedback screens staggered throughout the experiment encouraging them to respond faster. All feedback messages occurred between blocks of trials and never within a set of trials in a single block. These feedback messages occurred after blocks 6, 13, 18, 27, 32, 36, 41, and 44. These messages were hard coded and always appeared in the same order regardless of how participants were responding. The feedback was meant to be a reminder that the task was to be completed as fast and accurately as possible. Therefore, some examples were asking the participant to speed up---\emph{¡Rápido!; ¡Responda lo más rápido posible!} 'Faster!; Respond as fast as possible!'---while others simply praised the participant and encouraged continued behavior---\emph{¡Bien hecho!; '¡Genial!} 'Good job!; Great!'. 

The participants were first presented with 8 practice blocks that followed the same criteria and procedure as the 48 blocks of experimental trials. Participants were offered a 2-minute break following block 23, which was the midway point of the experimental task. Each trial began with text \emph{Encuentre} followed by the sequence of letters, henceforth referred to as the target. The target was presented in all capital letters in the center of the screen. The initial screen of each new block contained the target for 4 seconds before returning to a blank screen for 500 milliseconds. Following the blank screen, a list of ten words was presented randomly one at a time for 2000 milliseconds each with a 150 millisecond interstimulus interval (ISI). Only one word, the carrier item, in each list of ten words contained the target while the other nine words were simply filler items. The target was always found at the beginning of the carrier item. None of the filler items shared any of its first three letters with the target. The search target remained in the upper right hand portion of the screen to serve as a reminder for the entire duration of the 10 individually presented words from the current block. When a response was made, only the first response was recorded, but the experiment did not progress until the 2000 millisecond presentation time had passed. This was done intentionally to avoid the difference of pacing when a response was received. Although this lack of feedback that a response had been made did cause confusion for some participants, no participant appeared to remain confused by this behavior in the experiment by the end of the practice blocks. Once all ten words from the block had been presented, the next block of trials began with a new target for participants to find. This continued until the participant had completed all 48 experimental blocks. In order to illustrate the block and trial system of the experimental design, an example block from the experiment is used. On the first screen, the participants are instructed to find a visually presented fragment \emph{Encuntre BA}, which was shown to them centered on the screen. Then the target is moved to the top right corner of the screen and the first word of the set of 10 were visually presented: \emph{sotana, sonido, picota, torpeza, balada, semilla, rendija, renombre, sordera, tortuga, tersura} and \emph{sortija} 'cassock, sound, cherry, clumsiness, ballad, seed, crevice, renown, deafness, turtle, treasure and ring.' Each word remained on the screen for two seconds before being replaced by the next word in the list. The participants were instructed to press the green button on a button response box using their preferred or dominant hand as soon as they had identified the target in one of the carrier items. They were instructed to do nothing when the fragment was not present. Only one response was expected from the participant during any single block.

The syllable monitoring experiment was conducted at the same time as other experimental tasks to reduce the number of required trips to the experimental location. When participants arrived at the experimental location, they were seated in front of a laptop computer with a USB connected button box in order to complete all experimental tasks in PsychoPy. At the beginning of the experiment, participants entered in basic demographic information as asked in the Basic Language Profile (BLP). Once they had entered their demographic information, they were asked if they had any questions about the procedure and equipment setup. They were also informed that each section of the experimental process would have its own set of instructions that would always reference the color of the button or buttons needed to complete the upcoming section.

All participants began the experimental session with the Spanish vocabulary task---LexTALE-Esp. Starting with this Spanish vocabulary test was an intentional design measure that ensured participants were in Spanish mode by the time they reached experimental tasks where reaction times were being collected. Immediately following the completion of the LexTALE-Esp, participants were given instructions for the practice portion of the visual word segmentation experiment---the syllable monitoring task. Following the practice portion, participants were given a new screen with instructions that indicated they had completed the practice portion, reminded about the controls needed to complete the section, and were allowed to ask any remaining question about the process. When the participant was ready to begin the actual experiment, they pressed the white button on the response box to begin. Once the participants had finished the entire syllable monitoring task, they were presented with instructions for the practice trials of the syllabic intuition experiment, which was reported in Chapter \ref{ch-intuition} of this dissertation. Similar to the visual word segmentation experiment, a new set of instructions came on the screen indicating that the practice trials were finished and that they were about to start the actual experiment. Following the syllable intuition experiment, participants completed the LexTALE-Eng task. Once they had completed the English vocabulary test, the Bilingual Language Profile (BLP) was also administered in PyschoPy. For the BLP survey, participants were given access to the keyboard and mouse for easier input of information during survey responses.


\subsection{Analysis}
The second addition will not use Latin-Square design, where participants only see a subset of the items, but will have all participants see all experimental items.
\subsection{boiler plate copy 7}
Due to the method used in data collection several pre-analysis steps were conducted to ensure that participants actually represented the intended group for which they were recruited. This was completed by using the additional data collected through the LexTALE, LexTALE-Esp and the Bilingual Language Profile (BLP) tasks that were completed during the same visit as the syllable monitoring experiment. Since these tasks were completed at the same time as the syllable monitoring experiment, it was not always possible to determine whether or not all participants were representative of the group until after all information had been collected and additional linguistic measures and background were thoroughly reviewed.

Before the data could be submitted for analysis, some data preparation was still required. The first step in preparing the data for analysis was to remove all the filler trials from the dataset. This left 2160 data points for critical trials by participant. Due to a typo in one of the stimuli, \emph{permiso} 'permission' was typed as \emph{permsio}. This created a nonword critical item inside of a real word block of filler items. As a result, this item was removed from the analysis resulting in the removal of 10 critical items. Since incorrect responses to critical items were a non-response by the participant, the \Sexpr{length(lab_critical_incorrect$word)} missed items were removed. The last pass removed any individual participant responses under 200 milliseconds---\Sexpr{length(lab_under_200$word)} items---following the lower criteria range used by \textcite{Bradley1993-qq}. The upper cut-off limit was set at 1500 milliseconds, which removed an additional \Sexpr{length(lab_over_1500$word)} items. In total, \Sexpr{length(lab_critical_incorrect$word) + length(lab_under_200$word) + length(lab_over_1500$word) + 10} trials, or \Sexpr{round((length(lab_critical_incorrect$word) + length(lab_under_200$word) + length(lab_over_1500$word))/length(lab_critical$word)*100,2)}\% of the data, were removed leaving \Sexpr{length(lab_my_data$word)} critical data points to be submitted for analysis.

The reaction time data was recorded in milliseconds during the experiment. However, to account for individual difference between participants in terms of reaction times, the reaction time data was log transformed. This accounts for the fact that some participants are generally faster or slower than other participants in general regardless of experimental conditions. The median for these log transformed reactions times were then calculated for each experimental condition by participant. This was done to prevent large skewing of the mean in cases where participants responded may have responded correctly but slower than usual when compared to their own responses. Using the median also allowed for the retention of all data points submitted within the range of 200--1500ms. 

Finally, the data was subset into two separate datasets. One dataset was for the control group containing all data points by native Spanish speakers and the other was for the target group containing all points given by native English speakers. This allowed each dataset to be analyzed individually by group allowing for the comparison of reaction times to experimental conditions between native Spanish and native English speakers. The datasets were comprised of reaction times by-participant as a function of three experimental conditions: \emph{Target} (CV or CVC syllable structure), \emph{Matching} ("matching" target and word initial syllable matched, "mismatching" target and word initial syllable did not match) and \emph{Lexicality} ("word" a real word in Spanish, "nonword" a nonce word that followed Spanish orthographic rules). The control group dataset of L1 Spanish speakers consisted of 
\Sexpr{nrow(lab_natives)} 
observations---
\Sexpr{length(unique(lab_natives$target_syl_structure))} 
\emph{Target} conditions x 
\Sexpr{length(unique(lab_natives$matching))} 
\emph{Matching} conditions x 
\Sexpr{length(unique(lab_natives$word_status))} 
\emph{Lexicality} conditions x 
\Sexpr{length(unique(lab_natives$partNum))} 
participants, while the target group dataset of L2 Spanish speakers consisted of 
\Sexpr{nrow(lab_learners)} 
observations---
\Sexpr{length(unique(lab_learners$target_syl_structure))} 
\emph{Target} conditions x 
\Sexpr{length(unique(lab_learners$matching))} 
\emph{Matching} conditions x 
\Sexpr{length(unique(lab_learners$word_status))} 
\emph{Lexicality} conditions x 
\Sexpr{length(unique(lab_learners$partNum))} 
participants. Reaction times that were recorded in milliseconds have been used in the descriptive statistics, but they underwent the log transformation prior to running inferential statistics. However, both millisecond and log transformed values were computed by-participant per each condition and were retained in the datasets.


\section{Results}
These results indicated that it was possible to see evidence of the syllabic segmentation strategy in a L1 Spanish, L2 English bilingual group and that this effect could be captured through a completely visual word segmentation design.

\subsection{boiler plate copy 8}
Table \ref{tab-lab-grp-rt-wd} reports the reaction time data for real words and Table \ref{tab-lab-grp-rt-nonwd} reports the reaction time data for nonwords. In both tables the reaction times are reported as a function of group---native Spanish controls and L2 learners of Spanish---and the four experimental conditions: CV target--matching, CV target--mismatching, CVC target--matching and CVC target--mismatching. Reaction times in these table are reported in both terms of raw milliseconds recorded during the experiment and log transformed times. 

\begin{table}
\centering
% Word Table
\begin{tabular}{l c l l l c c c c}
\toprule
& & & & & \multicolumn{2}{c}{RT ms} & \multicolumn{2}{c}{RT log}\\
\cmidrule(lr){6-7}\cmidrule(lr){8-9}
L1 & n & Target & Carrier & Matching & Median & SD & Median & SD\\
\midrule
\multirow{4}{*}{English}
% CV Target CV Carrier Condition
& \Sexpr{lab_grp_sum["English-CV-CV-word","n"]}
& \Sexpr{lab_grp_sum["English-CV-CV-word","target_syl_structure"]}
& \Sexpr{lab_grp_sum["English-CV-CV-word","word_initial_syl"]} 
& \Sexpr{lab_grp_sum["English-CV-CV-word","matching"]}
& \Sexpr{lab_grp_sum["English-CV-CV-word","segRespRTmsec_Median"]}
& \Sexpr{lab_grp_sum["English-CV-CV-word","segRespRTmsec_SD"]}
& \Sexpr{lab_grp_sum["English-CV-CV-word","log_RT_Median"]}
& \Sexpr{lab_grp_sum["English-CV-CV-word","log_RT_SD"]}\\
% CV Target CVC Carrier Condition
& \Sexpr{lab_grp_sum["English-CV-CVC-word","n"]}
& \Sexpr{lab_grp_sum["English-CV-CVC-word","target_syl_structure"]} 
& \Sexpr{lab_grp_sum["English-CV-CVC-word","word_initial_syl"]} 
& \Sexpr{lab_grp_sum["English-CV-CVC-word","matching"]}
& \Sexpr{lab_grp_sum["English-CV-CVC-word","segRespRTmsec_Median"]}
& \Sexpr{lab_grp_sum["English-CV-CVC-word","segRespRTmsec_SD"]}
& \Sexpr{lab_grp_sum["English-CV-CVC-word","log_RT_Median"]}
& \Sexpr{lab_grp_sum["English-CV-CVC-word","log_RT_SD"]}\\
% CVC Target CV Carrier Condition
& \Sexpr{lab_grp_sum["English-CVC-CV-word","n"]}
& \Sexpr{lab_grp_sum["English-CVC-CV-word","target_syl_structure"]} 
& \Sexpr{lab_grp_sum["English-CVC-CV-word","word_initial_syl"]} 
& \Sexpr{lab_grp_sum["English-CVC-CV-word","matching"]}
& \Sexpr{lab_grp_sum["English-CVC-CV-word","segRespRTmsec_Median"]}
& \Sexpr{lab_grp_sum["English-CVC-CV-word","segRespRTmsec_SD"]}
& \Sexpr{lab_grp_sum["English-CVC-CV-word","log_RT_Median"]}
& \Sexpr{lab_grp_sum["English-CVC-CV-word","log_RT_SD"]}\\
% CVC Target CVC Carrier Condition
& \Sexpr{lab_grp_sum["English-CVC-CVC-word","n"]}
& \Sexpr{lab_grp_sum["English-CVC-CVC-word","target_syl_structure"]} 
& \Sexpr{lab_grp_sum["English-CVC-CVC-word","word_initial_syl"]} 
& \Sexpr{lab_grp_sum["English-CVC-CVC-word","matching"]}
& \Sexpr{lab_grp_sum["English-CVC-CVC-word","segRespRTmsec_Median"]}
& \Sexpr{lab_grp_sum["English-CVC-CVC-word","segRespRTmsec_SD"]}
& \Sexpr{lab_grp_sum["English-CVC-CVC-word","log_RT_Median"]}
& \Sexpr{lab_grp_sum["English-CVC-CVC-word","log_RT_SD"]}\\
\midrule
\multirow{4}{*}{Spanish}
% CV Target CV Carrier Condition
& \Sexpr{lab_grp_sum["Spanish-CV-CV-word","n"]}
& \Sexpr{lab_grp_sum["Spanish-CV-CV-word","target_syl_structure"]} 
& \Sexpr{lab_grp_sum["Spanish-CV-CV-word","word_initial_syl"]} 
& \Sexpr{lab_grp_sum["Spanish-CV-CV-word","matching"]}
& \Sexpr{lab_grp_sum["Spanish-CV-CV-word","segRespRTmsec_Median"]}
& \Sexpr{lab_grp_sum["Spanish-CV-CV-word","segRespRTmsec_SD"]}
& \Sexpr{lab_grp_sum["Spanish-CV-CV-word","log_RT_Median"]}
& \Sexpr{lab_grp_sum["Spanish-CV-CV-word","log_RT_SD"]}\\
% CV Target CVC Carrier Condition
& \Sexpr{lab_grp_sum["Spanish-CV-CVC-word","n"]}
& \Sexpr{lab_grp_sum["Spanish-CV-CVC-word","target_syl_structure"]} 
& \Sexpr{lab_grp_sum["Spanish-CV-CVC-word","word_initial_syl"]} 
& \Sexpr{lab_grp_sum["Spanish-CV-CVC-word","matching"]}
& \Sexpr{lab_grp_sum["Spanish-CV-CVC-word","segRespRTmsec_Median"]}
& \Sexpr{lab_grp_sum["Spanish-CV-CVC-word","segRespRTmsec_SD"]}
& \Sexpr{lab_grp_sum["Spanish-CV-CVC-word","log_RT_Median"]}
& \Sexpr{lab_grp_sum["Spanish-CV-CVC-word","log_RT_SD"]}\\
% CVC Target CV Carrier Condition
& \Sexpr{lab_grp_sum["Spanish-CVC-CV-word","n"]}
& \Sexpr{lab_grp_sum["Spanish-CVC-CV-word","target_syl_structure"]} 
& \Sexpr{lab_grp_sum["Spanish-CVC-CV-word","word_initial_syl"]} 
& \Sexpr{lab_grp_sum["Spanish-CVC-CV-word","matching"]}
& \Sexpr{lab_grp_sum["Spanish-CVC-CV-word","segRespRTmsec_Median"]}
& \Sexpr{lab_grp_sum["Spanish-CVC-CV-word","segRespRTmsec_SD"]}
& \Sexpr{lab_grp_sum["Spanish-CVC-CV-word","log_RT_Median"]}
& \Sexpr{lab_grp_sum["Spanish-CVC-CV-word","log_RT_SD"]}\\
% CVC Target CVC Carrier Condition
& \Sexpr{lab_grp_sum["Spanish-CVC-CVC-word","n"]}
& \Sexpr{lab_grp_sum["Spanish-CVC-CVC-word","target_syl_structure"]} 
& \Sexpr{lab_grp_sum["Spanish-CVC-CVC-word","word_initial_syl"]} 
& \Sexpr{lab_grp_sum["Spanish-CVC-CVC-word","matching"]}
& \Sexpr{lab_grp_sum["Spanish-CVC-CVC-word","segRespRTmsec_Median"]}
& \Sexpr{lab_grp_sum["Spanish-CVC-CVC-word","segRespRTmsec_SD"]}
& \Sexpr{lab_grp_sum["Spanish-CVC-CVC-word","log_RT_Median"]}
& \Sexpr{lab_grp_sum["Spanish-CVC-CVC-word","log_RT_SD"]}\\
\bottomrule
\multicolumn{6}{l}{Total data points: n = \Sexpr{
lab_grp_sum["English-CV-CV-word","n"] +
lab_grp_sum["English-CV-CVC-word","n"] +
lab_grp_sum["English-CVC-CV-word","n"] +
lab_grp_sum["English-CVC-CVC-word","n"] +
lab_grp_sum["Spanish-CV-CV-word","n"] +
lab_grp_sum["Spanish-CV-CVC-word","n"] +
lab_grp_sum["Spanish-CVC-CV-word","n"] +
lab_grp_sum["Spanish-CVC-CVC-word","n"]}}\\
\end{tabular}
\caption{Reaction times to words for each condition given in milliseconds and log transformed values.}
\label{tab-lab-grp-rt-wd-online}

\vspace{.4in}

% Nonword Table
\begin{tabular}{l c l l l c c c c}
\toprule
& & & & & \multicolumn{2}{c}{RT ms} & \multicolumn{2}{c}{RT log}\\ 
\cmidrule(lr){6-7}\cmidrule(lr){8-9}
L1 & n & Target & Carrier & Matching & Median & SD & Median & SD\\
\midrule
\multirow{4}{*}{English}
% CV Target CV Carrier Condition
& \Sexpr{lab_grp_sum["English-CV-CV-nonword","n"]}
& \Sexpr{lab_grp_sum["English-CV-CV-nonword","target_syl_structure"]} 
& \Sexpr{lab_grp_sum["English-CV-CV-nonword","word_initial_syl"]} 
& \Sexpr{lab_grp_sum["English-CV-CV-nonword","matching"]}
& \Sexpr{lab_grp_sum["English-CV-CV-nonword","segRespRTmsec_Median"]}
& \Sexpr{lab_grp_sum["English-CV-CV-nonword","segRespRTmsec_SD"]}
& \Sexpr{lab_grp_sum["English-CV-CV-nonword","log_RT_Median"]}
& \Sexpr{lab_grp_sum["English-CV-CV-nonword","log_RT_SD"]}\\
% CV Target CVC Carrier Condition
& \Sexpr{lab_grp_sum["English-CV-CVC-nonword","n"]}
& \Sexpr{lab_grp_sum["English-CV-CVC-nonword","target_syl_structure"]} 
& \Sexpr{lab_grp_sum["English-CV-CVC-nonword","word_initial_syl"]} 
& \Sexpr{lab_grp_sum["English-CV-CVC-nonword","matching"]}
& \Sexpr{lab_grp_sum["English-CV-CVC-nonword","segRespRTmsec_Median"]}
& \Sexpr{lab_grp_sum["English-CV-CVC-nonword","segRespRTmsec_SD"]}
& \Sexpr{lab_grp_sum["English-CV-CVC-nonword","log_RT_Median"]}
& \Sexpr{lab_grp_sum["English-CV-CVC-nonword","log_RT_SD"]}\\
% CVC Target CV Carrier Condition
& \Sexpr{lab_grp_sum["English-CVC-CV-nonword","n"]}
& \Sexpr{lab_grp_sum["English-CVC-CV-nonword","target_syl_structure"]} 
& \Sexpr{lab_grp_sum["English-CVC-CV-nonword","word_initial_syl"]} 
& \Sexpr{lab_grp_sum["English-CVC-CV-nonword","matching"]}
& \Sexpr{lab_grp_sum["English-CVC-CV-nonword","segRespRTmsec_Median"]}
& \Sexpr{lab_grp_sum["English-CVC-CV-nonword","segRespRTmsec_SD"]}
& \Sexpr{lab_grp_sum["English-CVC-CV-nonword","log_RT_Median"]}
& \Sexpr{lab_grp_sum["English-CVC-CV-nonword","log_RT_SD"]}\\
% CVC Target CVC Carrier Condition
& \Sexpr{lab_grp_sum["English-CVC-CVC-nonword","n"]}
& \Sexpr{lab_grp_sum["English-CVC-CVC-nonword","target_syl_structure"]} 
& \Sexpr{lab_grp_sum["English-CVC-CVC-nonword","word_initial_syl"]} 
& \Sexpr{lab_grp_sum["English-CVC-CVC-nonword","matching"]}
& \Sexpr{lab_grp_sum["English-CVC-CVC-nonword","segRespRTmsec_Median"]}
& \Sexpr{lab_grp_sum["English-CVC-CVC-nonword","segRespRTmsec_SD"]}
& \Sexpr{lab_grp_sum["English-CVC-CVC-nonword","log_RT_Median"]}
& \Sexpr{lab_grp_sum["English-CVC-CVC-nonword","log_RT_SD"]}\\
\midrule
\multirow{4}{*}{Spanish}
% CV Target CV Carrier Condition
& \Sexpr{lab_grp_sum["Spanish-CV-CV-nonword","n"]}
& \Sexpr{lab_grp_sum["Spanish-CV-CV-nonword","target_syl_structure"]} 
& \Sexpr{lab_grp_sum["Spanish-CV-CV-nonword","word_initial_syl"]} 
& \Sexpr{lab_grp_sum["Spanish-CV-CV-nonword","matching"]}
& \Sexpr{lab_grp_sum["Spanish-CV-CV-nonword","segRespRTmsec_Median"]}
& \Sexpr{lab_grp_sum["Spanish-CV-CV-nonword","segRespRTmsec_SD"]}
& \Sexpr{lab_grp_sum["Spanish-CV-CV-nonword","log_RT_Median"]}
& \Sexpr{lab_grp_sum["Spanish-CV-CV-nonword","log_RT_SD"]}\\
% CV Target CVC Carrier Condition
& \Sexpr{lab_grp_sum["Spanish-CV-CVC-nonword","n"]}
& \Sexpr{lab_grp_sum["Spanish-CV-CVC-nonword","target_syl_structure"]} 
& \Sexpr{lab_grp_sum["Spanish-CV-CVC-nonword","word_initial_syl"]} 
& \Sexpr{lab_grp_sum["Spanish-CV-CVC-nonword","matching"]}
& \Sexpr{lab_grp_sum["Spanish-CV-CVC-nonword","segRespRTmsec_Median"]}
& \Sexpr{lab_grp_sum["Spanish-CV-CVC-nonword","segRespRTmsec_SD"]}
& \Sexpr{lab_grp_sum["Spanish-CV-CVC-nonword","log_RT_Median"]}
& \Sexpr{lab_grp_sum["Spanish-CV-CVC-nonword","log_RT_SD"]}\\
% CVC Target CV Carrier Condition
& \Sexpr{lab_grp_sum["Spanish-CVC-CV-nonword","n"]}
& \Sexpr{lab_grp_sum["Spanish-CVC-CV-nonword","target_syl_structure"]} 
& \Sexpr{lab_grp_sum["Spanish-CVC-CV-nonword","word_initial_syl"]} 
& \Sexpr{lab_grp_sum["Spanish-CVC-CV-nonword","matching"]}
& \Sexpr{lab_grp_sum["Spanish-CVC-CV-nonword","segRespRTmsec_Median"]}
& \Sexpr{lab_grp_sum["Spanish-CVC-CV-nonword","segRespRTmsec_SD"]}
& \Sexpr{lab_grp_sum["Spanish-CVC-CV-nonword","log_RT_Median"]}
& \Sexpr{lab_grp_sum["Spanish-CVC-CV-nonword","log_RT_SD"]}\\
% CVC Target CVC Carrier Condition
& \Sexpr{lab_grp_sum["Spanish-CVC-CVC-nonword","n"]}
& \Sexpr{lab_grp_sum["Spanish-CVC-CVC-nonword","target_syl_structure"]} 
& \Sexpr{lab_grp_sum["Spanish-CVC-CVC-nonword","word_initial_syl"]} 
& \Sexpr{lab_grp_sum["Spanish-CVC-CVC-nonword","matching"]}
& \Sexpr{lab_grp_sum["Spanish-CVC-CVC-nonword","segRespRTmsec_Median"]}
& \Sexpr{lab_grp_sum["Spanish-CVC-CVC-nonword","segRespRTmsec_SD"]}
& \Sexpr{lab_grp_sum["Spanish-CVC-CVC-nonword","log_RT_Median"]}
& \Sexpr{lab_grp_sum["Spanish-CVC-CVC-nonword","log_RT_SD"]}\\
\bottomrule
\multicolumn{6}{l}{Total data points: n = \Sexpr{
lab_grp_sum["English-CV-CV-nonword","n"] +
lab_grp_sum["English-CV-CVC-nonword","n"] +
lab_grp_sum["English-CVC-CV-nonword","n"] +
lab_grp_sum["English-CVC-CVC-nonword","n"] +
lab_grp_sum["Spanish-CV-CV-nonword","n"] +
lab_grp_sum["Spanish-CV-CVC-nonword","n"] +
lab_grp_sum["Spanish-CVC-CV-nonword","n"] +
lab_grp_sum["Spanish-CVC-CVC-nonword","n"]}}\\
\end{tabular}
\caption{Reaction times to nonwords for each condition given in milliseconds and log transformed values.}
\label{tab-lab-grp-rt-nonwd-online}
\end{table}

\subsection{Native Spanish Controls}
\subsubsection{boiler plate copy 9}
Figure \ref{plt-lab-l1-rtms-desc} plots the general tendencies, or descriptive statistics, for response times in milliseconds by target syllable, matching and lexicality conditions for the \Sexpr{length(unique(lab_natives$partNum))} native controls. The log transformed values were submitted to a (3) x (2) repeated measures ANOVA with \emph{Lexicality, Target} and \emph{Matching} as factors. The ANOVA revealed no statistically significant main effects or interactions, in all cases p > 0.05. There was a possible trend in main effect of \emph{Lexicality}, but it failed to reach significance 
\emph{F}(
\Sexpr{lab_aov_natives$anova_table["word_status", "num Df"]},
\Sexpr{lab_aov_natives$anova_table["word_status", "den Df"]}) = 
\Sexpr{round(lab_aov_natives$anova_table["word_status", "F"],2)}, 
p > .05 
[\Sexpr{round(lab_aov_natives$anova_table["word_status", "Pr(>F)"],4)}]. 

\begin{figure}
\begin{center}
<<online_desc_l1_rtms, fig.width= 6, fig.height= 3>>=
lab_bxp_natives
@      
\caption[Descriptive RTs: Lab Experiment Control Group]{Reaction times reported in milliseconds given as a factor of target syllable structure, matching and lexicality conditions.}
\label{plt-lab-l1-rtms-desc-online}
\end{center}
\end{figure}

Figure \ref{plt-lab-l1-tar-mat-ns-int} shows the data plotted by lexicality with each panel showing the interaction between target syllable structure and matching condition. Note that the parallel lines shown in the word panel of the plot reveals the type of pattern expected to be seen given the way the data was analyzed. The difference between our analysis and previous literature is capturing the same difference but displayed in a different manner. The previous literature showed the crossover effect because they analyzed their data over target syllable structure and carrier syllable structure. Our parallel pattern tells the same story but simply analyzed over target syllable structure and matching condition. In both cases the conditions analyzed included CV target--CV carrier and CVC target--CVC carrier (matching conditions), CV target--CVC carrier and CVC target--CV carrier (mismatching conditions).

\begin{figure}
\begin{center}
<<online_l1_tar_mat_ns_int, fig.width= 6, fig.height= 3>>=
lab_l1_tar_mat_int
@      
\caption[Estimated Marginal Means: Lab Experiment Control Group]{Log transformed reaction times reported given as a factor of target syllable structure, matching and lexicality conditions.}
\label{plt-lab-l1-tar-mat-ns-int-online}
\end{center}
\end{figure}

\subsection{L2 Spanish Learners}
\subsubsection{boiler plate copy 10}
Figure \ref{plt-lab-l2-rtms-desc} plots the general descriptive statistics for response times in milliseconds by target syllable, matching and lexicality conditions for the \Sexpr{length(unique(lab_learners$partNum))} L2 learners of Spanish. The log transformed values were submitted to a (3) x (2) repeated measures ANOVA with \emph{Lexicality, Target} and \emph{Matching} as factors. The ANOVA revealed statistically significant main effects of \emph{Target}, 
\emph{F}(
\Sexpr{lab_aov_learners$anova_table["target_syl_structure", "num Df"]},
\Sexpr{lab_aov_learners$anova_table["target_syl_structure", "den Df"]}) =
\Sexpr{round(lab_aov_learners$anova_table["target_syl_structure", "F"],2)}, 
p < .05 
[\Sexpr{round(lab_aov_learners$anova_table["target_syl_structure", "Pr(>F)"],4)}] 
and a statistically significant interaction between \emph{Matching} and \emph{Lexicality}, 
\emph{F}(
\Sexpr{lab_aov_learners$anova_table["matching:word_status", "num Df"]},
\Sexpr{lab_aov_learners$anova_table["matching:word_status", "den Df"]}) =
\Sexpr{round(lab_aov_learners$anova_table["matching:word_status", "F"],2)}, 
p < .05 
[\Sexpr{round(lab_aov_learners$anova_table["matching:word_status", "Pr(>F)"],4)}]. 

\begin{figure}
\begin{center}
<<online_desc_l2_rtms, fig.width= 6, fig.height= 3>>=
lab_bxp_learners
@      
\caption[Descriptive RTs: Lab Experiment Target Group]{Reaction times reported in milliseconds given as a factor of target syllable structure, matching and lexicality conditions.}
\label{plt-lab-l2-rtms-desc-online}
\end{center}
\end{figure}

In order to look at main effect of target syllable, post-hoc analyses were conducted. The dataset was regrouped so that each participant's reaction times were computed based on whether the target syllable they were monitoring for was CV or CVC. The dataset consisted of 
\Sexpr{nrow(lab_data_tarsyl_ag)} 
observations---
\Sexpr{length(unique(lab_learners$target_syl_structure))} 
\emph{Target} conditions x 
\Sexpr{length(unique(lab_learners$partNum))}.
This dataset was then submitted to a t-test, which revealed that the L2 Spanish group generally detected CVC syllables, 
M= \Sexpr{round(lab_tar_compare["CVC", "Mean"],2)}, 
SD= \Sexpr{round(lab_tar_compare["CVC", "SD"],2)} 
at 95\% CI 
[\Sexpr{round(lab_tar_compare["CVC", "LL"],3)}, 
\Sexpr{round(lab_tar_compare["CVC", "UL"],3)}], 
faster than CV syllables, 
M= \Sexpr{round(lab_tar_compare["CV", "Mean"],2)}, 
SD= \Sexpr{round(lab_tar_compare["CV", "SD"],2)} 
[\Sexpr{round(lab_tar_compare["CV", "LL"],3)}, 
\Sexpr{round(lab_tar_compare["CV", "UL"],3)}]. 
The mean difference, 
M= \Sexpr{round(abs(lab_tar_compare["CVC", "Mean"] - 
lab_tar_compare["CV", "Mean"]),2)}, 
reveals a statistical difference in detection times between the two target syllable structures, 
\emph{t}(\Sexpr{round(t_lab_tar_syl_main$parameter,2)}) = 
\Sexpr{round(t_lab_tar_syl_main$statistic,4)}, 
p < \Sexpr{round(t_lab_tar_syl_main$p.value,4)}.
The main effect of target syllable was of a 
\Sexpr{lab_tar_efsize$magnitude} 
magnitude. This can be seen in the output of Cohen's \emph{d} for \emph{Target} \emph{d}= 
\Sexpr{round(lab_tar_efsize$estimate,2)}, 
\Sexpr{lab_tar_efsize$conf.level*100}\% CI 
[\Sexpr{round(lab_tar_efsize$conf.int[1],2)},
\Sexpr{round(lab_tar_efsize$conf.int[2],2)}].

In order to break down the interaction between \emph{Matching} and \emph{Lexicality} factors, a post-hoc analysis was run. The L2 Spanish dataset was was further subset into two dataframes: one for real words and one for nonwords. Each dataset consisted of 
\Sexpr{nrow(lab_nonwords_learners)} 
observations---
\Sexpr{length(unique(lab_nonwords_learners$matching))} 
\emph{Matching} conditions x 
\Sexpr{length(unique(lab_nonwords_learners$partNum))}
participants. Both datasets, words and nonwords, were then individually submitted to a one-tailed t-test. This revealed that the L2 Spanish group did not detect syllables faster in nonword for the matching condition, 
M= \Sexpr{round(lab_mat_lex_compare["nonword-matching", "Mean"],2)}, 
SD= \Sexpr{round(lab_mat_lex_compare["nonword-matching", "SD"],2)} 
at 95\% CI 
[\Sexpr{round(lab_mat_lex_compare["nonword-matching", "LL"],3)}, 
\Sexpr{round(lab_mat_lex_compare["nonword-matching", "UL"],3)}], 
than syllables detected in the mismatching condition, 
M= \Sexpr{round(lab_mat_lex_compare["nonword-mismatching", "Mean"],2)}, 
SD= \Sexpr{round(lab_mat_lex_compare["nonword-mismatching", "SD"],2)} 
[\Sexpr{round(lab_mat_lex_compare["nonword-mismatching", "LL"],3)}, 
\Sexpr{round(lab_mat_lex_compare["nonword-mismatching", "UL"],3)}]. 
The mean difference, 
M= \Sexpr{round(abs(lab_mat_lex_compare["nonword-matching", "Mean"] - 
lab_mat_lex_compare["nonword-mismatching", "Mean"]),2)}, 
reveals no statistical difference with regards to the target syllable matching the word initial syllable of the carrier item for nonword, 
\emph{t}(\Sexpr{round(t_lab_l2_nonwd_mat_int$parameter,2)}) = 
\Sexpr{round(t_lab_l2_nonwd_mat_int$statistic,4)}, 
p < \Sexpr{round(t_lab_l2_nonwd_mat_int$p.value,4)}.
In the real word dataset, it surprisingly revealed that the L2 Spanish group detected syllables significantly slower for the matching condition, 
M= \Sexpr{round(lab_mat_lex_compare["word-matching", "Mean"],2)}, 
SD= \Sexpr{round(lab_mat_lex_compare["word-matching", "SD"],2)} 
at 95\% CI 
[\Sexpr{round(lab_mat_lex_compare["word-matching", "LL"],3)}, 
\Sexpr{round(lab_mat_lex_compare["word-matching", "UL"],3)}], 
than syllables detected in the mismatching condition, 
M= \Sexpr{round(lab_mat_lex_compare["word-mismatching", "Mean"],2)}, 
SD= \Sexpr{round(lab_mat_lex_compare["word-mismatching", "SD"],2)} 
[\Sexpr{round(lab_mat_lex_compare["word-mismatching", "LL"],3)}, 
\Sexpr{round(lab_mat_lex_compare["word-mismatching", "UL"],3)}]. 
The mean difference, 
M= \Sexpr{round(abs(lab_mat_lex_compare["word-matching", "Mean"] - 
lab_mat_lex_compare["word-mismatching", "Mean"]),2)}, 
reveals a statistically significant difference with regards to the target syllable matching the word initial syllable of the carrier item for words, but opposite of the hypothesized direction, 
\emph{t}(\Sexpr{round(t_lab_l2_wd_mat_int$parameter,2)}) = 
\Sexpr{round(t_lab_l2_wd_mat_int$statistic,4)}, 
p < \Sexpr{round(t_lab_l2_wd_mat_int$p.value,4)}.
The effect size of matching condition in the word dataset was also 
\Sexpr{lab_l2_mat_efsize$magnitude} 
in magnitude, \emph{d}= 
\Sexpr{round(lab_l2_mat_efsize$estimate,2)}, 
\Sexpr{lab_l2_mat_efsize$conf.level*100}\% CI 
[\Sexpr{round(lab_l2_mat_efsize$conf.int[1],2)}, 
\Sexpr{round(lab_l2_mat_efsize$conf.int[2],2)}].
Figure \ref{plt-lab_l2_mat_lex_s_int} plots the estimated marginal means for the interaction between \emph{Matching} and \emph{Lexicality} for L2 learners of Spanish.
\ttodo{Checkthe Cohen.d scores as r variable pull.} 

\begin{figure}
\begin{center}
<<online_l2_mat_lex_s_int, fig.width= 5, fig.height= 3>>=
lab_l2_lex_mat_int
@      
\caption[Estimated Marginal Means: Lab Experiment Target Group]{Log transformed reaction times reported given as a factor of matching and lexicality conditions.}
\label{plt-lab_l2_mat_lex_s_int-online}
\end{center}
\end{figure}

Lastly, Figure \ref{plt-lab-l2-tar-mat-ns-int} again shows that the interaction between target syllable structure and the structure word initial syllable of carrier word was not significant. Although not significant, the patterns that emerged in the native speaker controls also emerged in the L2 learners of Spanish. That is the real word dataset reveals parallel lines which implies the same meaning as the crossover effect found in previous studies.

\begin{figure}
\begin{center}
<<online_l2_tar_mat_ns_int, fig.width= 6, fig.height= 3>>=
lab_l2_tar_mat_int
@      
\caption[Estimated Marginal Means: Lab Experiment Control Group]{Log transformed reaction times reported given as a factor of target syllable structure, matching and lexicality conditions.}
\label{plt-lab-l2-tar-mat-ns-int-online}
\end{center}
\end{figure}


\section{Discussion}
\subsection{boiler plate copy 11}
This chapter reported on the \Sexpr{length(unique(lab_my_data$partNum))} participants who completed a visual Spanish syllable monitoring experiment. Crucially, the experiment run in this chapter attempted to replicate the findings of previous research in terms of Spanish syllable monitoring as an indicator of the use of a syllabic segmentation strategy with its \Sexpr{length(unique(lab_natives$partNum))} native Spanish speaker controls. It sought to extend the use of the syllable monitoring experimental design to address the questions of whether or not the \Sexpr{length(unique(lab_learners$partNum))} native English speakers participants who were L2 learners of Spanish could utilize a syllabic segmentation strategy when processing Spanish. 

In terms of replication, the \textcite{Bradley1993-qq} results were replicated in the our native Spanish speaker control group. These L2 learners of English did not continue to exhibit behavior of syllabic segmentation. While this was portion of the experiment was not the main focus of the study, the results did confirm the findings of Spanish--English bilinguals \parencite{Bradley1993-qq}. \textcite{Bradley1993-qq} suggested that potential factor causing the absence of the syllabic segmentation strategy in the Spanish--English bilinguals was the fact that all their participants had immigrated and lived in an English speaking region for a minimum of three years. Their results combined with those of the current study would suggest that this factor was not the main reason for the abandonment of a syllabic segmentation strategy. All participants in the current study were born, raised and continued to reside in their L1 Spanish speaking region. \textcite{Bradley1993-qq} results combined with those of the current study would suggest that the dominant language of residing region was not the main factor for the abandonment of a syllabic segmentation strategy. The results of the Spanish--English bilinguals are the not the first time that bilinguals have been found to alter the use of a syllabic segmentation strategy. \textcite{Cutler1992-qq} initially found that French--English bilinguals appeared to have abandoned their syllabic segmentation strategy. However, once they considered language dominance, the French dominant bilinguals showed evidence of syllabic segmentation in a French monitoring experiment, but not in an English monitoring experiment. While \textcite{Bradley1993-qq} discussed language dominance in terms of questions answered to survey, they do not directly address this factor in their analysis of the monitoring experiment. Therefore, they mentioned participants under 30 years of age favored English while those over 30 favored Spanish, which led to a mixed group of language dominances for their analysis. Their results may have been similar to the pooled group of French-English bilinguals \textcite{Cutler1992-qq}. The current results reported in this study have taken language dominance into consideration before analysis of monitoring data to ensure that the bilingual control group was indeed Spanish dominant. Even in Spanish dominant bilinguals, the evidence of the syllabic segmentation strategy was not found in the Spanish monitoring experiment. While a conclusive claim cannot be made based on the results of the current study, it seems that some factor or combination of factors may be at play in terms of bilingual segmentation strategies, which extend beyond simplistic classifications of native language, residency geographic location and language dominance.

Now turning the attention to main group of interest in the current study, it was found that the L2 learners of Spanish also did not show any signs of a syllabic segmentation strategy. This finding is not overly surprising given that the control group of native Spanish speakers did not show evidence of the syllabic strategy with the same materials. Previous literature has shown that English speakers generally have not displayed evidence of syllabic segmentation strategies even when monitored languages would have supported it \parencite{Bradley1993-qq,Cutler1986-zl,Cutler1992-qq}. While there were no signs utilizing syllables to segment the Spanish words shown to participants, they did show a preference of monitoring for CVC syllables as they were detected faster than when monitoring for CV syllables. \ttodo{why would this main effect be there, be useful} They also showed sensitivity to the condition of matching, but only with real words. This finding was quite unexpected as it indicated the direction of this effect was in the opposite direction as the one hypothesized. In other words, participants were much faster at detecting the syllable for which they were monitoring when it did not match the syllable structure of the word initial syllable in which they found it. \ttodo{why could this be, is it related to CVC syllable faster detection times? nonwords are not the same is there lexical access involved?}

There are several reasons that could potentially cause the null results for target and carrier item syllable structures to be present in this current experiment. The first of which may be the sample size of the groups. For instance, there were no significant factors in the control group, which was only about two thirds of the learner of Spanish group. While the learner group did reveal some significant factors, although not where I had hypothesized, it was still a small sample size. Even though the learner group size was comparable to previous research group sizes, a problem with replication in linguistic studies is not uncommon \ttodo{cite article}. A suggestion for future researcher would be to conduct power analysis prior to beginning data collection. This needs to take into consideration the size of the expected effect based off of previous results or that of a pilot study in the event where novel research is taking place. Researcher should also carefully consider the level of confidence they would like to have when making claims based off their results. Considering these factors into future experimental designs will not only help researchers used data-driven decisions in determining sample sizes needed for their experiments, but may also help alleviate the replication crisis found in many language-based research designs.

%Another avenue to investigate would be the syllabic intuitions of participants, which could be a factor given that English and Spanish differ in ways similar to English and French participants of previous research studies. 

%It may be that the two groups do not agree on the syllabic structures of the speech they are segmenting as a result of L1 backgrounds. Syllabic intuitions from both groups were collected in a syllabic intuition experiment that was conducted and results are discussed in Chapter \ref{ch-intuition} of the current project.

From Meeting notes:
Result support phonological activation when reading (visual stimuli)

Activating representations of syllable at some level of processing.

Syllabic segmentation is learnable (L2 speakers did this) All previous studies showed using English as one of your languages screwed you on this strategy.