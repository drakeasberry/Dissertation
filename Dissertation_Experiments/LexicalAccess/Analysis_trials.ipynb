{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some directory paths needed for project\n",
    "parent_dir = os.getcwd()\n",
    "original_dir = 'Dissertation_Experiments/lexicalAccess/data/original_data/part_files/'\n",
    "temp_dir = 'Dissertation_Experiments/lexicalAccess/data/temp_data'\n",
    "processed_dir = 'Dissertation_Experiments/lexicalAccess/data/processed_data/part_files'\n",
    "stats_temp_dir = 'Dissertation_Stats/Syllable_Lexical_Access/analyze_data/temp_data'\n",
    "stats_out_dir = 'Dissertation_Stats/Syllable_Lexical_Access/analyze_data'\n",
    "directory_list = [original_dir, temp_dir, processed_dir, stats_temp_dir, stats_out_dir]\n",
    "\n",
    "# Create lists for separate file needed to analyze all experiments\n",
    "demCols = ['partNum', 'session', 'age', 'gender', 'birthCountry', 'placeResidence', 'education', 'preferLanguage',\n",
    "           'date', 'expName']\n",
    "lexDuplicates = ['word', 'translation']\n",
    "lexEsp = ['corrAnsEspV', 'lexRespEsp', 'lexRespEspCorr', 'lexRespEspRT']\n",
    "lexEng = ['corrAnsEngV', 'lexRespEng', 'lexRespEngCorr', 'lexRespEngRT']\n",
    "syl = ['syllabification', 'corrSyl', 'corrAns', 'leftKey', 'rightKey', 'condition', 'sylResp', 'sylRespCorr',\n",
    "       'sylRespRT', ]\n",
    "blp = ['questionNum', 'color', 'sectionEng', 'questionTextEng', 'languageEng', 'langHistResp1', 'langHistRT1',\n",
    "       'langHistResp2', 'langHistRT2', 'langHistResp3', 'langHistRT3', 'langUseResp', 'langUseRT', 'langProfResp',\n",
    "       'langProfRT', 'langAttResp', 'langAttRT']\n",
    "lexical = []\n",
    "lexEspCols = [*lexDuplicates, *lexEsp, *demCols]\n",
    "lexEngCols = [*lexDuplicates, *lexEng, *demCols]\n",
    "sylCols = [*syl, *demCols]\n",
    "blpCols = [*blp, *demCols]\n",
    "lexCols = [*lexical, *demCols]\n",
    "lexicalKeepCols = [*lexDuplicates, *lexEsp, *lexEng, *sylCols, *lexCols, *blpCols, *demCols]\n",
    "listOfLists = {'lexEngCols':lexEngCols, 'lexEspCols':lexEspCols, 'sylCols':sylCols, 'blpCols':blpCols, 'lexCols':lexCols}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/drakeasberry/github/Dissertation/Dissertation_Experiments/lexicalAccess'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dissertation_Experiments/lexicalAccess/data/original_data/part_files/',\n",
       " 'Dissertation_Experiments/lexicalAccess/data/temp_data',\n",
       " 'Dissertation_Experiments/lexicalAccess/data/processed_data/part_files',\n",
       " 'Dissertation_Stats/Syllable_Lexical_Access/analyze_data/temp_data',\n",
       " 'Dissertation_Stats/Syllable_Lexical_Access/analyze_data']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/drakeasberry/github/Dissertation/Dissertation_Experiments/lexicalAccess\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis_trials.ipynb\r\n",
      "Lexical_Access_Experimental_Item_Setup.xlsx\r\n",
      "Lexical_Access_Notebook.ipynb\r\n",
      "\u001b[34m\u001b[43mdata\u001b[m\u001b[m/\r\n",
      "\u001b[1m\u001b[31mlexicalAccess.psyexp\u001b[m\u001b[m*\r\n",
      "\u001b[1m\u001b[31mlexicalAccess_lastrun.py\u001b[m\u001b[m*\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_returning = pd.read_csv('/Users/drakeasberry/github/Dissertation/Dissertation_Experiments/lexicalAccess/data/temp_data/part040_inglés_A_No_Lexical_Access.csv')\n",
    "file_new_participant = pd.read_csv('/Users/drakeasberry/github/Dissertation/Dissertation_Experiments/lexicalAccess/data/temp_data/part062_español_C_Yes_Lexical_Access.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>corrAns</th>\n",
       "      <th>initialSylStress</th>\n",
       "      <th>sylStruc</th>\n",
       "      <th>wordStatus</th>\n",
       "      <th>source</th>\n",
       "      <th>freq_WPM</th>\n",
       "      <th>numRevealed</th>\n",
       "      <th>masking</th>\n",
       "      <th>Length</th>\n",
       "      <th>PrimeCalc</th>\n",
       "      <th>Prime</th>\n",
       "      <th>matching</th>\n",
       "      <th>transcription</th>\n",
       "      <th>DerivedWord</th>\n",
       "      <th>Condition</th>\n",
       "      <th>counter</th>\n",
       "      <th>pracTrialLoop.thisRepN</th>\n",
       "      <th>pracTrialLoop.thisTrialN</th>\n",
       "      <th>pracTrialLoop.thisN</th>\n",
       "      <th>pracTrialLoop.thisIndex</th>\n",
       "      <th>expTrialLoop.thisRepN</th>\n",
       "      <th>expTrialLoop.thisTrialN</th>\n",
       "      <th>expTrialLoop.thisN</th>\n",
       "      <th>expTrialLoop.thisIndex</th>\n",
       "      <th>syllabification.thisRepN</th>\n",
       "      <th>syllabification.thisTrialN</th>\n",
       "      <th>syllabification.thisN</th>\n",
       "      <th>syllabification.thisIndex</th>\n",
       "      <th>lexTaleSpanish.thisRepN</th>\n",
       "      <th>lexTaleSpanish.thisTrialN</th>\n",
       "      <th>lexTaleSpanish.thisN</th>\n",
       "      <th>lexTaleSpanish.thisIndex</th>\n",
       "      <th>lexTaleEnglish.thisRepN</th>\n",
       "      <th>lexTaleEnglish.thisTrialN</th>\n",
       "      <th>lexTaleEnglish.thisN</th>\n",
       "      <th>lexTaleEnglish.thisIndex</th>\n",
       "      <th>basicLangProfile.thisRepN</th>\n",
       "      <th>basicLangProfile.thisTrialN</th>\n",
       "      <th>basicLangProfile.thisN</th>\n",
       "      <th>basicLangProfile.thisIndex</th>\n",
       "      <th>lexPracResp.keys</th>\n",
       "      <th>lexPracResp.corr</th>\n",
       "      <th>lexPracResp.rt</th>\n",
       "      <th>lex_key_resp.keys</th>\n",
       "      <th>lex_key_resp.corr</th>\n",
       "      <th>lex_key_resp.rt</th>\n",
       "      <th>partNum</th>\n",
       "      <th>session</th>\n",
       "      <th>firstName</th>\n",
       "      <th>lastName</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>birthCountry</th>\n",
       "      <th>placeResidence</th>\n",
       "      <th>education</th>\n",
       "      <th>preferLanguage</th>\n",
       "      <th>00_Primera vez (First Time):</th>\n",
       "      <th>date</th>\n",
       "      <th>expName</th>\n",
       "      <th>psychopyVersion</th>\n",
       "      <th>frameRate</th>\n",
       "      <th>Unnamed: 62</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>varizo</td>\n",
       "      <td>4</td>\n",
       "      <td>no</td>\n",
       "      <td>CV</td>\n",
       "      <td>nonword</td>\n",
       "      <td>Wuggy</td>\n",
       "      <td>None</td>\n",
       "      <td>2.0</td>\n",
       "      <td>######</td>\n",
       "      <td>6.0</td>\n",
       "      <td>va####</td>\n",
       "      <td>va####</td>\n",
       "      <td>match</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.758897</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>part040</td>\n",
       "      <td>A</td>\n",
       "      <td>Mary Ann</td>\n",
       "      <td>Silva</td>\n",
       "      <td>60</td>\n",
       "      <td>Mujer</td>\n",
       "      <td>Estados Unidos</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>Un poco de universidad</td>\n",
       "      <td>inglés</td>\n",
       "      <td>No</td>\n",
       "      <td>2019_Oct_25_1105</td>\n",
       "      <td>Lexical_Access</td>\n",
       "      <td>3.0.7</td>\n",
       "      <td>60.131842</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cúcipo</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>CV</td>\n",
       "      <td>nonword</td>\n",
       "      <td>Wuggy</td>\n",
       "      <td>None</td>\n",
       "      <td>2.0</td>\n",
       "      <td>######</td>\n",
       "      <td>6.0</td>\n",
       "      <td>cú####</td>\n",
       "      <td>cú####</td>\n",
       "      <td>match</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.598440</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>part040</td>\n",
       "      <td>A</td>\n",
       "      <td>Mary Ann</td>\n",
       "      <td>Silva</td>\n",
       "      <td>60</td>\n",
       "      <td>Mujer</td>\n",
       "      <td>Estados Unidos</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>Un poco de universidad</td>\n",
       "      <td>inglés</td>\n",
       "      <td>No</td>\n",
       "      <td>2019_Oct_25_1105</td>\n",
       "      <td>Lexical_Access</td>\n",
       "      <td>3.0.7</td>\n",
       "      <td>60.131842</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>túcico</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>CV</td>\n",
       "      <td>nonword</td>\n",
       "      <td>Wuggy</td>\n",
       "      <td>None</td>\n",
       "      <td>3.0</td>\n",
       "      <td>######</td>\n",
       "      <td>6.0</td>\n",
       "      <td>túc###</td>\n",
       "      <td>túc###</td>\n",
       "      <td>mismatch</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.217797</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>part040</td>\n",
       "      <td>A</td>\n",
       "      <td>Mary Ann</td>\n",
       "      <td>Silva</td>\n",
       "      <td>60</td>\n",
       "      <td>Mujer</td>\n",
       "      <td>Estados Unidos</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>Un poco de universidad</td>\n",
       "      <td>inglés</td>\n",
       "      <td>No</td>\n",
       "      <td>2019_Oct_25_1105</td>\n",
       "      <td>Lexical_Access</td>\n",
       "      <td>3.0.7</td>\n",
       "      <td>60.131842</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Word  corrAns initialSylStress sylStruc wordStatus source freq_WPM  \\\n",
       "0  varizo        4               no       CV    nonword  Wuggy     None   \n",
       "1  cúcipo        4              yes       CV    nonword  Wuggy     None   \n",
       "2  túcico        4              yes       CV    nonword  Wuggy     None   \n",
       "\n",
       "   numRevealed masking  Length PrimeCalc   Prime  matching transcription  \\\n",
       "0          2.0  ######     6.0    va####  va####     match           NaN   \n",
       "1          2.0  ######     6.0    cú####  cú####     match           NaN   \n",
       "2          3.0  ######     6.0    túc###  túc###  mismatch           NaN   \n",
       "\n",
       "  DerivedWord Condition  counter  pracTrialLoop.thisRepN  \\\n",
       "0         NaN       NaN      NaN                     0.0   \n",
       "1         NaN       NaN      NaN                     0.0   \n",
       "2         NaN       NaN      NaN                     0.0   \n",
       "\n",
       "   pracTrialLoop.thisTrialN  pracTrialLoop.thisN  pracTrialLoop.thisIndex  \\\n",
       "0                       0.0                  0.0                     14.0   \n",
       "1                       1.0                  1.0                      9.0   \n",
       "2                       2.0                  2.0                      8.0   \n",
       "\n",
       "   expTrialLoop.thisRepN  expTrialLoop.thisTrialN  expTrialLoop.thisN  \\\n",
       "0                    NaN                      NaN                 NaN   \n",
       "1                    NaN                      NaN                 NaN   \n",
       "2                    NaN                      NaN                 NaN   \n",
       "\n",
       "   expTrialLoop.thisIndex  syllabification.thisRepN  \\\n",
       "0                     NaN                       NaN   \n",
       "1                     NaN                       NaN   \n",
       "2                     NaN                       NaN   \n",
       "\n",
       "   syllabification.thisTrialN  syllabification.thisN  \\\n",
       "0                         NaN                    NaN   \n",
       "1                         NaN                    NaN   \n",
       "2                         NaN                    NaN   \n",
       "\n",
       "   syllabification.thisIndex  lexTaleSpanish.thisRepN  \\\n",
       "0                        NaN                      NaN   \n",
       "1                        NaN                      NaN   \n",
       "2                        NaN                      NaN   \n",
       "\n",
       "   lexTaleSpanish.thisTrialN  lexTaleSpanish.thisN  lexTaleSpanish.thisIndex  \\\n",
       "0                        NaN                   NaN                       NaN   \n",
       "1                        NaN                   NaN                       NaN   \n",
       "2                        NaN                   NaN                       NaN   \n",
       "\n",
       "   lexTaleEnglish.thisRepN  lexTaleEnglish.thisTrialN  lexTaleEnglish.thisN  \\\n",
       "0                      NaN                        NaN                   NaN   \n",
       "1                      NaN                        NaN                   NaN   \n",
       "2                      NaN                        NaN                   NaN   \n",
       "\n",
       "   lexTaleEnglish.thisIndex  basicLangProfile.thisRepN  \\\n",
       "0                       NaN                        NaN   \n",
       "1                       NaN                        NaN   \n",
       "2                       NaN                        NaN   \n",
       "\n",
       "   basicLangProfile.thisTrialN  basicLangProfile.thisN  \\\n",
       "0                          NaN                     NaN   \n",
       "1                          NaN                     NaN   \n",
       "2                          NaN                     NaN   \n",
       "\n",
       "   basicLangProfile.thisIndex  lexPracResp.keys  lexPracResp.corr  \\\n",
       "0                         NaN               1.0               0.0   \n",
       "1                         NaN               4.0               1.0   \n",
       "2                         NaN               4.0               1.0   \n",
       "\n",
       "   lexPracResp.rt  lex_key_resp.keys  lex_key_resp.corr  lex_key_resp.rt  \\\n",
       "0        4.758897                NaN                NaN              NaN   \n",
       "1        2.598440                NaN                NaN              NaN   \n",
       "2        1.217797                NaN                NaN              NaN   \n",
       "\n",
       "   partNum session firstName lastName  age gender    birthCountry  \\\n",
       "0  part040       A  Mary Ann    Silva   60  Mujer  Estados Unidos   \n",
       "1  part040       A  Mary Ann    Silva   60  Mujer  Estados Unidos   \n",
       "2  part040       A  Mary Ann    Silva   60  Mujer  Estados Unidos   \n",
       "\n",
       "  placeResidence               education preferLanguage  \\\n",
       "0         Tucson  Un poco de universidad         inglés   \n",
       "1         Tucson  Un poco de universidad         inglés   \n",
       "2         Tucson  Un poco de universidad         inglés   \n",
       "\n",
       "  00_Primera vez (First Time):              date         expName  \\\n",
       "0                           No  2019_Oct_25_1105  Lexical_Access   \n",
       "1                           No  2019_Oct_25_1105  Lexical_Access   \n",
       "2                           No  2019_Oct_25_1105  Lexical_Access   \n",
       "\n",
       "  psychopyVersion  frameRate  Unnamed: 62  \n",
       "0           3.0.7  60.131842          NaN  \n",
       "1           3.0.7  60.131842          NaN  \n",
       "2           3.0.7  60.131842          NaN  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "file_returning.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_list = list(file_returning.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list = list(file_new_participant.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Diff(li1, li2): \n",
    "    li_dif = [i for i in li1 + li2 if i not in li1 or i not in li2] \n",
    "    return li_dif "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unnamed: 62', 'corrSyl', 'leftKey', 'rightKey', 'condition', 'Order', 'translation', 'realWord', 'questionNum', 'color', 'sectionEng', 'questionTextEng', 'languageEng', 'sectionEsp', 'questionTextEsp', 'languageEsp', 'sylPracLoop.thisRepN', 'sylPracLoop.thisTrialN', 'sylPracLoop.thisN', 'sylPracLoop.thisIndex', 'syllableLoop.thisRepN', 'syllableLoop.thisTrialN', 'syllableLoop.thisN', 'syllableLoop.thisIndex', 'lexEspLoop.thisRepN', 'lexEspLoop.thisTrialN', 'lexEspLoop.thisN', 'lexEspLoop.thisIndex', 'lexEngLoop.thisRepN', 'lexEngLoop.thisTrialN', 'lexEngLoop.thisN', 'lexEngLoop.thisIndex', 'trials_blp_hist.thisRepN', 'trials_blp_hist.thisTrialN', 'trials_blp_hist.thisN', 'trials_blp_hist.thisIndex', 'trials_blp_hist_2.thisRepN', 'trials_blp_hist_2.thisTrialN', 'trials_blp_hist_2.thisN', 'trials_blp_hist_2.thisIndex', 'trials_blp_hist_3.thisRepN', 'trials_blp_hist_3.thisTrialN', 'trials_blp_hist_3.thisN', 'trials_blp_hist_3.thisIndex', 'trials_blp_use.thisRepN', 'trials_blp_use.thisTrialN', 'trials_blp_use.thisN', 'trials_blp_use.thisIndex', 'trials_blp_prof.thisRepN', 'trials_blp_prof.thisTrialN', 'trials_blp_prof.thisN', 'trials_blp_prof.thisIndex', 'trials_blp_att.thisRepN', 'trials_blp_att.thisTrialN', 'trials_blp_att.thisN', 'trials_blp_att.thisIndex', 'sylResp', 'sylRespCorr', 'sylRespRT', 'lexRespEsp', 'lexRespEspCorr', 'lexRespEspRT', 'lexRespEng', 'lexRespEngCorr', 'lexRespEngRT', 'langHistResp1', 'langHistRT1', 'langHistResp2', 'langHistRT2', 'langHistResp3', 'langHistRT3', 'langUseResp', 'langUseRT', 'langProfResp', 'langProfRT', 'langAttResp', 'langAttRT', 'Unnamed: 138']\n"
     ]
    }
   ],
   "source": [
    "difference_list =Diff(return_list,new_list)\n",
    "print(difference_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
